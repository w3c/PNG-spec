<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Portable Network Graphics (PNG) Specification (Third Edition)</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!-- <link rel="stylesheet" href="./isostyle.css" type="text/css" /> -->
    <style type="text/css">
    /* remove annoying green colour from definition terms */
    dt {color: black}
    </style>
    <script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer></script>
    <script class="remove">
      var respecConfig = {
          specStatus: "ED",
	  shortName: "PNG",
	  copyrightStart: "1996",
	  previousPublishDate: "2003-11-10",
	  previousMaturity: "REC",
	  edDraftURI: "https://w3c.github.io/PNG-spec",
	  extraCSS: ["http://dev.w3.org/2009/dap/ReSpec.js/css/respec.css"],
	  editors: [
	      { name: "Chris Blume", url: "https://www.programmax.net", w3cid: 127631 },
	      { name: "Pierre-Anthony Lemieux", company: "MovieLabs", companyURL: "https://movielabs.com/", url: "mailto:pal@palemieux.com", w3cid: 57073 },
	      { name: "Chris Lilley", url: "https://svgees.us", company: "W3C", companyURL: "https://www.w3.org", w3cid: 1438 },
	      { name: "Leonard Rosenthol", company: "Adobe Inc.", companyURL: "https://www.adobe.com", w3cid: 42485 },
	      { name: "Chris Seeger", company: "NBCUniversal, LLC a subsidiary of Comcast Corporation", companyURL: "https://www.comcast.com", w3cid: 125833 }
	  ],
	  formerEditors: [
	      { name: "Thomas Boutell" },
	      { name: "Adam M. Costello" },
	      { name: "David Duce" },
	      { name: "Tom Lane" },
	      { name: "Glenn Randers-Pehrson" },
	  ],
	  authors: [
	      { name: "Mark Adler", url: "http://www.alumni.caltech.edu/~madler/" },
	      { name: "Thomas Boutell", url: "http://www.boutell.com/boutell/" },
	      { name: "John Bowler" },
	      { name: "Christian Brunschen", url: "http://www.df.lth.se/~cb/" },
	      { name: "Adam M. Costello", url: "http://www.nicemice.net/amc/" },
	      { name: "Lee Daniel Crocker", url: "http://www.piclab.com/" },
	      { name: "Andreas Dilger", url: "http://www-mddsp.enel.ucalgary.ca/People/adilger/" },
	      { name: "Oliver Fromme", url: "http://www.fromme.com/" },
	      { name: "Jean-loup Gailly", url: "http://www.teaser.fr/~jlgailly/" },
	      { name: "Chris Herborth" },
	      { name: "Alex Jakulin" },
	      { name: "Neal Kettler" },
	      { name: "Tom Lane" },
	      { name: "Alexander Lehmann" },
	      { name: "Chris Lilley", url: "https://svgees.us", company: "W3C", companyURL: "https://www.w3.org" },
	      { name: "Dave Martindale" },
	      { name: "Owen Mortensen" },
	      { name: "Keith S. Pickens" },
	      { name: "Robert P. Poole", url: "http://www.users.qwest.net/~lionlad/" },
	      { name: "Glenn Randers-Pehrson" },
	      { name: "Greg Roelofs", url: "http://pobox.com/~newt/" },
	      { name: "Willem van Schaik", url: "http://www.schaik.com/" },
	      { name: "Guy Schalnat" },
	      { name: "Paul Schmidt" },
	      { name: "Michael Stokes" },
	      { name: "Tim Wegner" },
	      { name: "Jeremy Wohl" }
	  ],
	  wg: "Portable Network Graphics (PNG) Working Group",
	  wgURI: "https://www.w3.org/groups/wg/png",
	  wgPublicList: "public-png",
	  wgPatentURI: "https://www.w3.org/groups/wg/png/ipr",
    localBiblio: {
      "CIPA DC-008": {
        title: "Exchangeable image file format for digital still cameras: Exif Version 2.32",
        href: "https://www.cipa.jp/std/documents/download_e.html?DC-008-Translation-2019-E",
        date: "2019-05-17",
        publisher: "Camera & Imaging Products Association",
      },
      "ICC-2": {
        title: "Specification ICC.2:2019 (Profile version 5.0.0 - iccMAX)",
        date: "2019",
        href: "https://www.color.org/specification/ICC.2-2019.pdf",
        publisher: "International Color Consortium"
      },
      "ISO 3309": {
        title: "ISO/IEC 3309:1993, Information Technology — Telecommunications and information exchange between systems — High-level data link control (HDLC) procedures — Frame structure.",
        date: "1993",
        publisher: "ISO"
      },
      "ISO 8859-1": {
        title: "ISO/IEC 8859-1:1998, Information technology — 8-bit single-byte coded graphic character sets — Part 1: Latin alphabet No. 1.",
        date: "1998"
      },
      "ISO 15076-1": {
        title: "ISO 15076-1:2010 Image technology colour management — Architecture, profile format and data structure — Part 1: Based on ICC.1:2010",
        href: "https://www.iso.org/standard/54754.html",
        date: "2010-12",
        publisher: "ISO"
      },
      "ISO 20677-1": {
        title: "ISO 20677:2019 Image technology colour management — Extensions to architecture, profile format and data structure",
        href: "https://www.iso.org/standard/68806.html",
        date: "2019-02",
        publisher: "ISO"
      },
      "ITU-R BT.709": {
        title: "ITU-R BT.709, SERIES H: AUDIOVISUAL AND MULTIMEDIA SYSTEMS Infrastructure of audiovisual services – Coding of moving video Coding-independent code points for video signal type identification",
        publisher: "ITU",
        href: "https://www.itu.int/rec/R-REC-BT.709"
      },
      "ITU-R BT.2100": {
        title: "ITU-R BT.2100, SERIES H: AUDIOVISUAL AND MULTIMEDIA SYSTEMS Infrastructure of audiovisual services – Coding of moving video Coding-independent code points for video signal type identification",
        publisher: "ITU",
        href: "https://www.itu.int/rec/R-REC-BT.2100"
      },
      "ITU-T H.273": {
        title: "ITU-T H.273, SERIES H: AUDIOVISUAL AND MULTIMEDIA SYSTEMS Infrastructure of audiovisual services – Coding of moving video Coding-independent code points for video signal type identification",
        publisher: "ITU",
        href: "https://www.itu.int/rec/T-REC-H.273"
      },
      "ITU-T V.42": {
        title: "ITU Recommendation V.42 : Error-correcting procedures for DCEs using asynchronous-to-synchronous conversion",
        href: "https://www.itu.int/rec/T-REC-V.42-200203-I/en",
        date: "2002-03-29",
        publisher: "ITU"
      },
      "Paeth": {
        author: "Paeth, A.W",
        title: "Image File Compression Made Easy, in Graphics Gems II, pp. 93-100",
        publisher: "Academic Press",
        date: "1991",
        isbn: "0-12-064481-9",
        href: "https://www.sciencedirect.com/science/article/pii/B9780080507545500293"
      },
      "PNG-EXTENSIONS": {
        title: "Extensions to the PNG Third Edition Specification, Version 1.6.0",
        publisher: "W3C",
        date: "2021",
        href: "https://w3c.github.io/PNG-spec/extensions/Overview.html"
      },
      "Ziv-Lempel": {
        authors: ["J. Ziv", "A. Lempel"],
        title: "A Universal Algorithm for Sequential Data Compression, IEEE Transactions on Information Theory, vol. IT-23, no. 3, pp. 337 - 343",
        date: "1977-05",
        publisher: "IEEE",
        href: "https://ieeexplore.ieee.org/document/1055714",
      }
    },
  };
  </script>
  </head>
  <body>
    <section id="abstract">
      <p>This document describes PNG (Portable Network Graphics), an extensible file format for the lossless, portable, well-compressed storage of raster images. PNG provides a patent-free replacement for GIF and can also replace many common uses of TIFF. Indexed-colour, greyscale, and truecolour images are supported, plus an optional alpha channel. Sample depths range from 1 to 16 bits.</p>
      <p>PNG is designed to work well in online viewing applications, such as the World Wide Web, so it is fully streamable with a progressive display option. PNG is robust, providing both full file integrity checking and simple detection of common transmission errors. Also, PNG can store gamma and chromaticity data for improved colour matching on heterogeneous platforms.</p>
      <p>This specification defines an Internet Media Type image/png.</p>

<!--
needs update, comment out for now

<p>The PNG specification enjoys a good level of <a href="http://www.libpng.org/pub/png/pngstatus.html">implementation</a>  with good interoperability. At the time of this publication more than 180 <a href="http://www.libpng.org/pub/png/pngapvw.html">image viewers</a> could display PNG images and over 100 <a href="http://www.libpng.org/pub/png/pngaped.html">image editors</a> could read and write valid PNG files. Full support of PNG is  required  for conforming <a href="/Graphics/SVG">SVG</a> viewers; at the time of publication all eighteen <a href="/Graphics/SVG/SVG-Implementations.htm8#viewer">SVG viewers</a> had PNG support. HTML has no required image formats, but over 60 <a href="http://www.libpng.org/pub/png/pngapbr.html">HTML browsers</a> had at least basic support of PNG images.</p> -->
    </section>
    <section id="sotd"></section>

<!-- *********************************************************************

FROM HERE ON THIS FILE IS IDENTICAL TO THE ISO VERSION
with these exceptions:

- id added to any headings that did not have one, to comply with pubrules and allow indexing into the document
- URL for this document updated in Annex E and the words " [to be completed when published]" removed

**************************************************************************  -->

<h2 id="Introduction">Introduction</h2>

<p></p>

<p>The design goals for this specification were:</p>

<ol>
<li>Portability: encoding, decoding, and transmission should be
software and hardware platform independent.</li>

<li>Completeness: it should be possible to represent truecolour,
indexed-colour, and greyscale images, in each case with the
option of transparency, colour space information, and ancillary
information such as textual comments.</li>

<li>Serial encode and decode: it should be possible for
datastreams to be generated serially and read serially, allowing
the datastream format to be used for on-the-fly generation and
display of images across a serial communication channel.</li>

<li>Progressive presentation: it should be possible to transmit
datastreams so that an approximation of the whole image can be
presented initially, and progressively enhanced as the datastream
is received.</li>

<li>Robustness to transmission errors: it should be possible to
detect datastream transmission errors reliably.</li>

<li>Losslessness: filtering and compression should preserve all
information.</li>

<li>Performance: any filtering, compression, and progressive
image presentation should be aimed at efficient decoding and
presentation. Fast encoding is a less important goal than fast
decoding. Decoding speed may be achieved at the expense of
encoding speed.</li>

<li>Compression: images should be compressed effectively,
consistent with the other design goals.</li>

<li>Simplicity: developers should be able to implement the
standard easily.</li>

<li>Interchangeability: any standard-conforming PNG decoder shall
be capable of reading all conforming PNG datastreams.</li>

<li>Flexibility: future extensions and private additions should
be allowed for without compromising the interchangeability of
standard PNG datastreams.</li>

<li>Freedom from legal restrictions: no algorithms should be used
that are not freely available.</li>
</ol>


<section>
<!-- Maintain a fragment named "1Scope" to preserve incoming links to it -->
<h2 id="1Scope">Scope</h2>


<p>This specification specifies a datastream and an
associated file format, Portable Network Graphics (PNG,
pronounced "ping"), for a lossless, portable, compressed
individual computer graphics image transmitted across the
Internet. Indexed-colour, greyscale, and truecolour images are
supported, with optional transparency. Sample depths range from 1
to 16 bits. PNG is fully streamable with a progressive display
option. It is robust, providing both full file integrity checking
and simple detection of common transmission errors. PNG can store
gamma and chromaticity data as well as a full ICC colour profile
for accurate colour matching on heterogenous platforms. This
Standard defines the Internet Media type "image/png". The
datastream and associated file format have value outside of the
main design goal.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<section>
<!-- Maintain a fragment named "2NormRefs" to preserve incoming links to it -->
<h2 id="2NormRefs">Normative references</h2>

<p>The following normative documents contain provisions which,
through reference in this text, constitute provisions of this
International Standard. For dated references, subsequent
amendments to, or revisions of, any of these publications do not
apply. However, parties to agreements based on this International
Standard are encouraged to investigate the possibility of
applying the most recent editions of the normative documents
indicated below. For undated references, the latest edition of
the normative document referred to applies. Members of ISO and
IEC maintain registers of currently valid International
Standards.</p>

<!-- Maintain a fragment named "2-ISO-639" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ISO-639">ISO 639:1988,
<i>Code for the representation of names of languages</i>.</p>

<!-- Maintain a fragment named "2-ISO-646" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ISO-646">ISO/IEC 646:1991,
<i>International Organization for Standardization, Information
technology &mdash; ISO 7-bit coded character set for information
interchange</i>.</p>

<!-- Maintain a fragment named "2-ISO-3309" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ISO-3309">ISO/IEC 3309:1993</a>,
<i>Information Technology &mdash; Telecommunications and
information exchange between systems &mdash; High-level data link
control (HDLC) procedures &mdash; Frame structure</i>.</p>

<!-- Maintain a fragment named "2-ISO-8859-1" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ISO-8859-1">ISO/IEC
8859-1:1998, <i>Information technology &mdash; 8-bit
single-byte coded graphic character sets &mdash; Part 1: Latin
alphabet No. 1</i>.<br class="xhtml" />
 For convenience, here is a non-normative  <a href="iso_8859-1.txt">sample text file</a>
 describing the codes and associated character names.</p>

<!-- Maintain a fragment named "2-ISO-9899" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ISO-9899">ISO/IEC
9899:1990(R1997), <i>Programming languages &mdash; C</i>.</p>

<!-- Maintain a fragment named "2-ISO-10656-1" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ISO-10646-1">ISO/IEC
10646-1:1993/AMD.2, <i>Information technology &mdash;
Universal Multiple-Octet Coded Character Sets (UCS) &mdash; Part
1: Architecture and Basic Multilingual Plane</i>.</p>

<!-- Maintain a fragment named "2-IEC-61966-2-1" to preserve incoming links to it -->
<p class="NormRefDef" id="2-IEC-61966-2-1">IEC
61966-2-1, <i>Multimedia systems and equipment &mdash; Colour
measurement and management &mdash; Part 2-1: Default RGB colour
space &mdash; sRGB,</i> available at <code><a href=
"http://www.iec.ch">http://www.iec.ch/</a></code>.</p>

<!-- Maintain a fragment named "2-CIE-15.2" to preserve incoming links to it -->
<p class="NormRefDef" id="2-CIE-15.2">CIE-15.2, CIE,
"Colorimetry, Second Edition". CIE Publication 15.2-1986. ISBN
3-900-734-00-3.</p>


<!-- Maintain a fragment named "2-ICC-1" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ICC-1">ICC-1, International
Color Consortium, "Specification ICC.1:2010-12 (Profile version 4.3.0.0)
Image technology colour management - Architecture, profile format, and data structure,
available at <code><a href=
"http://www.color.org/icc_specs2.xalter">http://www.color.org/icc_specs2.xalter</a></code>
also published as ISO 15076-1</p>

<!-- Maintain a fragment named "2-ICC-a" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ICC-a">ICC-2,
International Color Consortium, "Specification ICC.2:2019 (iccMAX)
Image technology colour management - Extensions to architecture, profile format, and data structure,
available at <code><a href=
"http://www.color.org/icc_specs2.xalter">http://www.color.org/icc_specs2.xalter</a></code>
also published as ISO 20677-1</p>

<!-- Maintain a fragment named "2-RFC-1123" to preserve incoming links to it -->
<p class="NormRefDef" id="2-RFC-1123">RFC-1123, Braden,
R., Editor, "Requirements for Internet Hosts &mdash; Application
and Support", STD 3, RFC 1123, USC/Information Sciences
Institute, October 1989.<br class="xhtml" />
 <code><a href=
"http://www.ietf.org/rfc/rfc1123.txt">http://www.ietf.org/rfc/rfc1123.txt</a></code>
</p>

<!-- Maintain a fragment named "2-RFC-1950" to preserve incoming links to it -->
<p class="NormRefDef" id="2-RFC-1950">RFC-1950, Deutsch,
P. and Gailly, J-L., "ZLIB Compressed Data Format Specification
version 3.3", RFC 1950, Aladdin Enterprises, May 1996.<br class="xhtml" />
 <code><a href=
"http://www.ietf.org/rfc/rfc1950.txt">http://www.ietf.org/rfc/rfc1950.txt</a></code></p>

<!-- Maintain a fragment named "2-RFC-1951" to preserve incoming links to it -->
<p class="NormRefDef" id="2-RFC-1951">RFC-1951, Deutsch,
P., "DEFLATE Compressed Data Format Specification version 1.3",
RFC 1951, Aladdin Enterprises, May 1996.<br class="xhtml" />
 <code><a href=
"http://www.ietf.org/rfc/rfc1951.txt">http://www.ietf.org/rfc/rfc1951.txt</a></code></p>

<!-- Maintain a fragment named "2-RFC-2045" to preserve incoming links to it -->
<p class="NormRefDef" id="2-RFC-2045">RFC-2045, Freed,
N. and Borenstein, N. , "MIME (Multipurpose Internet Mail
Extensions) Part One: Format of Internet Message Bodies", RFC
2045, Innosoft, First Virtual, November 1996.<br class="xhtml" />
 <code><a href=
"http://www.ietf.org/rfc/rfc2045.txt">http://www.ietf.org/rfc/rfc2045.txt</a></code></p>

<!-- Maintain a fragment named "2-RFC-2048" to preserve incoming links to it -->
<p class="NormRefDef" id="2-RFC-2048">RFC-2048, Freed,
N., Klensin, J. and Postel, J., "Multipurpose Internet Mail
Extensions (MIME) Part Four: Registration Procedures", RFC 2048,
Innosoft, MCI, ISI, November 1996.<br class="xhtml" />
 <code><a href=
"http://www.ietf.org/rfc/rfc2048.txt">http://www.ietf.org/rfc/rfc2048.txt</a></code></p>

<!-- Maintain a fragment named "2-RFC-3066" to preserve incoming links to it -->
<p class="NormRefDef" id="2-RFC-3066">RFC-3066,
Alvestrand, H., "Tags for the Identification of Languages", RFC
3066, Cisco Systems, January 2001. (Obsoletes RFC 1766.)<br class="xhtml" />
 <code><a href=
"http://www.ietf.org/rfc/rfc3066.txt">http://www.ietf.org/rfc/rfc3066.txt</a></code></p>

<!-- Maintain a fragment named "2-ITU-T-H.273" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ITU-T-H.273">ITU-T H.273,
SERIES H: AUDIOVISUAL AND MULTIMEDIA SYSTEMS
Infrastructure of audiovisual services – Coding of moving video
Coding-independent code points for video signal type identification<br class="xhtml" />
 <code><a href=
"https://www.itu.int/rec/T-REC-H.273">https://www.itu.int/rec/T-REC-H.273</a></code></p>

<!-- Maintain a fragment named "2-ITU-R-BT.2100" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ITU-R-BT.2100">ITU-R BT.2100,
SERIES H: AUDIOVISUAL AND MULTIMEDIA SYSTEMS
Infrastructure of audiovisual services – Coding of moving video
Coding-independent code points for video signal type identification<br class="xhtml" />
 <code><a href=
"https://www.itu.int/rec/R-REC-BT.2100">https://www.itu.int/rec/R-REC-BT.2100</a></code></p>

<!-- Maintain a fragment named "2-ITU-R-BT.709" to preserve incoming links to it -->
<p class="NormRefDef" id="2-ITU-R-BT.709">ITU-R BT.709,
SERIES H: AUDIOVISUAL AND MULTIMEDIA SYSTEMS
Infrastructure of audiovisual services – Coding of moving video
Coding-independent code points for video signal type identification<br class="xhtml" />
 <code><a href=
"https://www.itu.int/rec/R-REC-BT.709">https://www.itu.int/rec/R-REC-BT.709</a></code></p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<section>
<!-- Maintain a fragment named "3Defsandabbrevs" to preserve incoming links to it -->
<h2 id="3Defsandabbrevs">Terms, definitions, and
abbreviated terms</h2>

<section>
<!-- Maintain a fragment named "3Definitions" to preserve incoming links to it -->
<h2 id="3Definitions">Definitions</h2>

<p>For the purposes of this specification the following
definitions apply.</p>

<dl>
<!-- Maintain a fragment named "3alpha" to preserve incoming links to it -->
<dfn id="3alpha"><dt>alpha</dt></dfn>

<dd>a value representing a <a href="#3pixel"><span class=
"Definition">pixel's</span></a> degree of opacity. The more
opaque a pixel, the more it hides the background against which
the image is presented. Zero alpha represents a completely
transparent pixel, maximum alpha represents a completely opaque
pixel.</dd>
<!-- Maintain a fragment named "3alphaCompaction" to preserve incoming links to it -->
<dfn id="3alphaCompaction"><dt>alpha compaction</dt></dfn>

<dd>an implicit representation of transparent <a href=
"#3pixel"><span class="Definition">pixels</span></a>. If every
pixel with a specific colour or <a href="#3greyscale"><span
class="Definition">greyscale</span></a> value is fully
transparent and all other pixels are fully opaque, the <a href=
"#3alpha"><span class="Definition">alpha</span></a> <a href=
"#3channel"><span class="Definition">channel</span></a> may be
represented implicitly.</dd>

<!-- Maintain a fragment named "3alphaSeparation" to preserve incoming links to it -->
<dfn id="3alphaSeparation"><dt>alpha separation</dt></dfn>

<dd>separating an <a href="#3alpha"><span class=
"Definition">alpha</span></a> <a href="#3channel"><span class=
"Definition">channel</span></a> in which every <a href=
"#3pixel"><span class="Definition">pixel</span></a> is fully
opaque; all alpha values are the maximum value.
The fact that all pixels are fully opaque is represented implicitly.
</dd>

<!-- Maintain a fragment named "3alphaTable" to preserve incoming links to it -->
<dfn id="3alphaTable">
<dt>alpha table</dt></dfn>

<dd>indexed table of <a href="#3alpha"><span class=
"Definition">alpha</span></a> <a href="#3sample"><span class=
"Definition">sample</span></a> values, which in an <a href=
"#3indexedColour"><span class=
"Definition">indexed-colour</span></a> image defines the alpha
sample values of the <a href="#3referenceImage"><span class=
"Definition">reference image</span></a>. The alpha table has the
same number of entries as the <a href="#3palette"><span class=
"Definition">palette</span></a>.</dd>

<!-- Maintain a fragment named "3ancillaryChunk" to preserve incoming links to it -->
<dfn id="3ancillaryChunk">
<dt>ancillary chunk</dt></dfn>

<dd>class of <a href="#3chunk"><span class=
"Definition">chunk</span></a> that provides additional
information. A <a href="#3PNGdecoder"><span class=
"Definition">PNG decoder</span></a>, without processing an
ancillary chunk, can still produce a meaningful image, though not
necessarily the best possible image.
<!-- agreed: don't need to define a bit -->
</dd>

<!-- Maintain a fragment named "3bitDepth" to preserve incoming links to it -->
<dfn id="3bitDepth">
<dt>bit depth</dt></dfn>

<dd>for <a href="#3indexedColour"><span class=
"Definition">indexed-colour</span></a> images, the number of bits
per <a href="#3palette"><span class=
"Definition">palette</span></a> index. For other images, the
number of bits per <a href="#3sample"><span class=
"Definition">sample</span></a> in the image. This is the value
that appears in the <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> <a href="#3chunk"><span class=
"Definition">chunk</span></a>.</dd>

<!-- Maintain a fragment named "3byte" to preserve incoming links to it -->
<dfn id="3byte">
<dt>byte</dt></dfn>

<dd>8 bits; also called an octet. The highest bit (value 128) of
a byte is numbered bit 7; the lowest bit (value 1) is numbered
bit 0.</dd>

<!-- Maintain a fragment named "3byteOrder" to preserve incoming links to it -->
<dfn id="3byteOrder">
<dt>byte order</dt></dfn>

<dd>ordering of <a href="#3byte"><span class=
"Definition">bytes</span></a> for multi-byte data values within a
<a href="#3PNGfile"><span class="Definition">PNG file</span></a>
or <a href="#PNG-datastream"><span class="Definition">PNG
datastream</span></a>. PNG uses <a href=
"#3networkByteOrder"><span class="Definition">network byte
order</span></a>.</dd>

<!-- Maintain a fragment named "3channel" to preserve incoming links to it -->
<dt id="3channel">
<dt>channel</dt></dfn>

<dd>array of all per-<a href="#3pixel"><span class=
"Definition">pixel</span></a> information of a particular kind
within a <a href="#3referenceImage"><span class=
"Definition">reference image</span></a>. There are five kinds of
information: red, green, blue, <a href="#3greyscale"><span class=
"Definition">greyscale</span></a>, and <a href="#3alpha"><span
class="Definition">alpha</span></a>. For example the alpha
channel is the array of alpha values within a reference
image.</dd>

<!-- Maintain a fragment named "3chromaticity" to preserve incoming links to it -->
<dfn id="3chromaticity">
<dt>chromaticity (CIE)</dt></dfn>

<dd>pair of values <i>x,y</i> that precisely specify a colour,
except for the brightness information.</dd>

<!-- Maintain a fragment named "3chunk" to preserve incoming links to it -->
<dfn id="3chunk">
<dt>chunk</dt></dfn>

<dd>section of a <a href="#PNG-datastream"><span class=
"Definition">PNG datastream</span></a>. Each chunk has a chunk
type. Most chunks also include data. The format and meaning of
the data within the chunk are determined by the chunk type.
Each chunk is either a
<a href="#3criticalChunk"><span class=
"Definition">critical chunk</span></a> or an <a href=
"#3ancillaryChunk"><span class=
"Definition">ancillary chunk</span></a>.
</dd>

<!-- Maintain a fragment named "3colourType" to preserve incoming links to it -->
<dfn id="3colourType">
<dt>colour type</dt></dfn>

<dd>value denoting how colour and <a href="#3alpha"><span class=
"Definition">alpha</span></a> are specified in the <a href=
"#3PNGimage"><span class="Definition">PNG image</span></a>.
Colour types are sums of the following values: 1 (<a href=
"#3palette"><span class="Definition">palette</span></a> used), 2
(<a href="#3truecolour"><span class=
"Definition">truecolour</span></a> used), 4 (alpha used). The
permitted values of colour type are 0, 2, 3, 4, and 6.</dd>

<!-- Maintain a fragment named "3composite" to preserve incoming links to it -->
<dfn id="3composite">
<dt>composite (verb)</dt></dfn>

<dd>to form an image by merging a foreground image and a
background image, using transparency information to determine
where and to what extent the background should be visible. The
foreground image is said to be "composited against" the
background.</dd>

<!-- Maintain a fragment named "3criticalChunk" to preserve incoming links to it -->
<dfn id="3criticalChunk">
<dt>critical chunk</dt></dfn>

<dd><a href="#3chunk"><span class="Definition">chunk</span></a>
that <!--must be understood and processed by the decoder-->
 shall be understood and processed by the decoder in order to
produce a meaningful image from a <a href="#PNG-datastream"><span
class="Definition">PNG datastream</span></a>.</dd>

<!-- Maintain a fragment named "3datastream" to preserve incoming links to it -->
<dfn id="3datastream">
<dt>datastream</dt></dfn>

<dd>sequence of <a href="#3byte"><span class=
"Definition">bytes</span></a>. This term is used rather than
"file" to describe a byte sequence that may be only a portion of
a file. It is also used to emphasize that the sequence of bytes
might be generated and consumed "on the fly", never appearing in
a stored file at all.</dd>

<!-- Maintain a fragment named "3deflate" to preserve incoming links to it -->
<dfn id="3deflate">
<dt>deflate</dt></dfn>

<dd>name of a particular compression algorithm. This algorithm is
used, in compression mode 0, in conforming <a href=
"#PNG-datastream"><span class="Definition">PNG
datastreams</span></a>. Deflate is a member of the <a href=
"#3LZ77"><span class="Definition">LZ77</span></a> family of
compression methods. It is defined in [[rfc1951]].</dd>


<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->

<!-- Maintain a fragment named "3deliveredImage" to preserve incoming links to it -->
<dfn id="3deliveredImage">
<dt>delivered image</dt></dfn>

<dd>image constructed from a decoded <a href=
"#PNG-datastream"><span class="Definition">PNG
datastream</span></a>.</dd>

<!-- Maintain a fragment named "3filter" to preserve incoming links to it -->
<dfn id="3filter">
<dt>filter</dt></dfn>

<dd>transformation applied to an array of <a href=
"#3scanline"><span class="Definition">scanlines</span></a> with
the aim of improving their compressibility. PNG uses only
lossless (reversible) filter algorithms.</dd>

<!-- Maintain a fragment named "3frameBuffer" to preserve incoming links to it -->
<dfn id="3frameBuffer">
<dt>frame buffer</dt></dfn>

<dd>the final digital storage area for the image shown by most
types of computer display. Software causes an image to appear on
screen by loading the image into the frame buffer.</dd>

<!-- Maintain a fragment named "3gamma" to preserve incoming links to it -->
<dfn id="3gamma">
<dt>gamma</dt></dfn>

<dd>exponent that describes approximations to certain non-linear
transfer functions encountered in image capture and reproduction.
Within this specification, gamma is the exponent in the
transfer function from <tt>display_output</tt> to
<tt>image_sample</tt>
<pre>
<tt>image_sample = display_output<sup>gamma</sup></tt>
</pre>
where both <tt>display_output</tt> and <tt>image_sample</tt>
are scaled to the range 0 to 1.
</dd>

<!-- Maintain a fragment named "3greyscale" to preserve incoming links to it -->
<dfn id="3greyscale">
<dt>greyscale</dt></dfn>

<dd>image representation in which each <a href="#3pixel"><span
class="Definition">pixel</span></a> is defined by a single <a
href="#3sample"><span class="Definition">sample</span></a> of
colour information, representing overall <a href=
"#3luminance"><span class="Definition">luminance</span></a> (on a
scale from black to white), and optionally an <a href=
"#3alpha"><span class="Definition">alpha</span></a> sample (in
which case it is called greyscale with alpha).</dd>

<!-- Maintain a fragment named "3imageData" to preserve incoming links to it -->
<dfn id="3imageData">
<dt>image data</dt></dfn>

<dd>1-dimensional array of <a href="#3scanline"><span class=
"Definition">scanlines</span></a> within an image.</dd>

<!-- Maintain a fragment named "3imageColour" to preserve incoming links to it -->
<dfn id="3imageColour">
<dt>indexed-colour</dt></dfn>

<dd>image representation in which each <a href="#3pixel"><span
class="Definition">pixel</span></a> of the original image is
represented by a single index into a <a href="#3palette"><span
class="Definition">palette</span></a>. The selected palette entry
defines the actual colour of the pixel.</dd>

<!-- Maintain a fragment named "3indexing" to preserve incoming links to it -->
<dfn id="3indexing">
<dt>indexing</dt></dfn>

<dd>representing an image by a <a href="#3palette"><span class=
"Definition">palette</span></a>, an <a href="#3alphaTable"><span
class="Definition">alpha table</span></a>, and an array of
indices pointing to entries in the palette and alpha table.</dd>

<!-- Maintain a fragment named "3interlacedPNGimage" to preserve incoming links to it -->
<dfn id="3interlacedPNGimage">
<dt>interlaced PNG
image</dt></dfn>

<dd>sequence of <a href="#3reducedImage"><span class=
"Definition">reduced images</span></a> generated from the <a
href="#3PNGimage"><span class="Definition">PNG image</span></a>
by <a href="#3passExtraction"><span class="Definition">pass
extraction</span></a>.</dd>

<!-- Maintain a fragment named "3losslessCompression" to preserve incoming links to it -->
<dfn id="3losslessCompression">
<dt>lossless
compression</dt></dfn>

<dd>method of data compression that permits reconstruction of the
original data exactly, bit-for-bit.</dd>

<!-- Maintain a fragment named "3lossyCompression" to preserve incoming links to it -->
<dfn id="3lossyCompression">
<dt>lossy compression</dt></dfn>

<dd>method of data compression that permits reconstruction of the
original data approximately, rather than exactly.</dd>

<!-- Maintain a fragment named "3luminance" to preserve incoming links to it -->
<dfn id="3luminance">
<dt>luminance</dt></dfn>

<dd>formal definition of luminance is in [[COLORIMETRY]].
Informally it is the perceived brightness, or <a href=
"#3greyscale"><span class="Definition">greyscale</span></a>
level, of a colour. Luminance and <a href="#3chromaticity"><span
class="Definition">chromaticity</span></a> together fully define
a perceived colour.</dd>

<!-- Maintain a fragment named "3LZ77" to preserve incoming links to it -->
<dfn id="3LZ77">
<dt>LZ77</dt></dfn>

<dd>data compression algorithm described by Ziv and Lempel in
their 1977 paper [[Ziv-Lempel]].</dd>

<!-- Maintain a fragment named "3networkByteOrder" to preserve incoming links to it -->
<dfn id="3networkByteOrder">
<dt>network byte
order</dt></dfn>

<dd><a href="#3byteOrder"><span class="Definition">byte
order</span></a> in which the most significant byte comes first,
then the less significant bytes in descending order of
significance (<a href="#3MSB"><span class=
"Definition">MSB</span></a> <a href="#3LSB"><span class=
"Definition">LSB</span></a> for two-byte integers, <a href=
"#3MSB"><span class="Definition">MSB</span></a> B2 B1 <a href=
"#3LSB"><span class="Definition">LSB</span></a> for four-byte
integers).</dd>

<!-- Maintain a fragment named "3palette" to preserve incoming links to it -->
<dfn id="3palette">
<dt>palette</dt></dfn>

<dd>indexed table of three 8-bit <a href="#3sample"><span class=
"Definition">sample</span></a> values, red, green, and blue,
which with an <a href="#3indexedColour"><span class=
"Definition">indexed-colour</span></a> image defines the red,
green, and blue sample values of the <a href=
"#3referenceImage"><span class="Definition">reference
image</span></a>. In other cases, the palette may be a suggested
palette that viewers may use to present the image on
indexed-colour display hardware. <a href="#3alpha"><span class=
"Definition">Alpha</span></a> samples may be defined for palette
entries via the <a href="#3alphaTable"><span class=
"Definition">alpha table</span></a> and may be used to
reconstruct the alpha sample values of the reference image.</dd>

<!-- Maintain a fragment named "3passExtraction" to preserve incoming links to it -->
<dfn id="3passExtraction">
<dt>pass extraction</dt></dfn>

<dd>organizing a <a href="#3PNGimage"><span class=
"Definition">PNG image</span></a> as a sequence of <a href=
"#3reducedImage"><span class="Definition">reduced
images</span></a> to change the order of transmission and enable
progressive display.</dd>

<!-- Maintain a fragment named "3pixel" to preserve incoming links to it -->
<dfn id="3pixel">
<dt>pixel</dt></dfn>

<dd>information stored for a single grid point in an image. A
pixel consists of (or points to) a sequence of <a href="#3sample"><span class=
"Definition">samples</span></a> from all <a href=
"#3channel"><span class="Definition">channels</span></a>. The
complete image is a rectangular array of pixels.</dd>


<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->

<!-- Maintain a fragment named "3PNGdatastream" to preserve incoming links to it -->
<dfn id="3PNGdatastream">
<dt>PNG datastream</dt></dfn>

<dd>result of encoding a <a href="#3PNGimage"><span class=
"Definition">PNG image</span></a>. A PNG <a href=
"#3datastream"><span class="Definition">datastream</span></a>
consists of a <a href="#3PNGsignature"><span class=
"Definition">PNG signature</span></a> followed by a sequence of
<a href="#3chunk"><span class=
"Definition">chunks</span></a>.</dd>

<!-- Maintain a fragment named "3PNGdecoder" to preserve incoming links to it -->
<dfn id="3PNGdecoder">
<dt>PNG decoder</dt></dfn>

<dd>process or device which reconstructs the <a href=
"#3referenceImage"><span class="Definition">reference
image</span></a> from a <a href="#PNG-datastream"><span class=
"Definition">PNG datastream</span></a> and generates a
corresponding delivered image.</dd>

<!-- Maintain a fragment named "3PNGeditor" to preserve incoming links to it -->
<dfn id="3PNGeditor">
<dt>PNG editor</dt></dfn>

<dd>process or device which creates a modification of an existing
<a href="#PNG-datastream"><span class="Definition">PNG
datastream</span></a>, preserving unmodified ancillary
information wherever possible, and obeying the <a href=
"#3chunk"><span class="Definition">chunk</span></a> ordering
rules, even for unknown chunk types.</dd>

<!-- Maintain a fragment named "3PNGencoder" to preserve incoming links to it -->
<dfn id="3PNGencoder">
<dt>PNG encoder</dt></dfn>

<dd>process or device which constructs a <a href=
"#3referenceImage"><span class="Definition">reference
image</span></a> from a <a href="#3sourceImage"><span class=
"Definition">source image</span></a>, and generates a <a href=
"#PNG-datastream"><span class="Definition">PNG
datastream</span></a> representing the reference image.</dd>

<!-- Maintain a fragment named "3PNGfile" to preserve incoming links to it -->
<dfn id="3PNGfile">
<dt>PNG file</dt></dfn>

<dd><a href="#PNG-datastream"><span class="Definition">PNG
datastream</span></a> stored as a file.</dd>

<!-- Maintain a fragment named "3PNGfourByteSignedInteger" to preserve incoming links to it -->
<dfn id="3PNGfourByteSignedInteger">
<dt>PNG four-byte
signed integer</dt></dfn>

<dd>a four-byte signed integer limited to the range
-(2<sup>31</sup>-1) to 2<sup>31</sup>-1. The restriction is
imposed in order to accommodate languages that have difficulty
with the value -2<sup>31</sup>.</dd>

<!-- Maintain a fragment named "3PNGfourByteUnSignedInteger" to preserve incoming links to it -->
<dfn id="3PNGfourByteUnSignedInteger">
<dt>PNG four-byte
unsigned integer</dt></dfn>

<dd>a four-byte unsigned integer limited to the range 0 to
2<sup>31</sup>-1. The restriction is imposed in order to
accommodate languages that have difficulty with unsigned
four-byte values.</dd>

<!-- Maintain a fragment named "3PNGimage" to preserve incoming links to it -->
<dfn id="3PNGimage">
<dt>PNG image</dt></dfn>

<dd>result of transformations applied by a <a href=
"#3PNGencoder"><span class="Definition">PNG encoder</span></a> to
a <a href="#3referenceImage"><span class="Definition">reference
image</span></a>, in preparation for encoding as a <a href=
"#PNG-datastream"><span class="Definition">PNG
datastream</span></a>, and the result of decoding a PNG
datastream.</dd>

<!-- Maintain a fragment named "3PNGsignature" to preserve incoming links to it -->
<dfn id="3PNGsignature">
<dt>PNG signature</dt></dfn>

<dd>sequence of <a href="#3byte"><span class=
"Definition">bytes</span></a> appearing at the start of every <a
href="#PNG-datastream"><span class="Definition">PNG
datastream</span></a>. It differentiates a PNG datastream from
other types of <a href="#3datastream"><span class=
"Definition">datastream</span></a> and allows early detection of
some transmission errors.</dd>

<!-- Maintain a fragment named "3reducedImage" to preserve incoming links to it -->
<dfn id="3reducedImage">
<dt>reduced image</dt></dfn>

<dd>pass of the <a href="#3interlacedPNGimage"><span class=
"Definition">interlaced PNG image</span></a> extracted from the
<a href="#3PNGimage"><span class="Definition">PNG
image</span></a> by <a href="#3passExtraction"><span class=
"Definition">pass extraction</span></a>.</dd>

<!-- Maintain a fragment named "3referenceImage" to preserve incoming links to it -->
<dfn id="3referenceImage">
<dt>reference image</dt></dfn>

<dd>rectangular array of rectangular <a href="#3pixel"><span
class="Definition">pixels</span></a>, each having the same number
of <a href="#3sample"><span class=
"Definition">samples</span></a>, either three (red, green, blue)
or four (red, green, blue, <a href="#3alpha"><span class=
"Definition">alpha</span></a>). Every reference image can be
represented exactly by a <a href="#PNG-datastream"><span class=
"Definition">PNG datastream</span></a> and every PNG datastream
can be converted into a reference image. Each <a href=
"#3channel"><span class="Definition">channel</span></a> has a <a
href="#3sampleDepth"><span class="Definition">sample
depth</span></a> in the range 1 to 16. All samples in the same
channel have the same sample depth. Different channels may have
different sample depths.</dd>

<!-- Maintain a fragment named "3RGBmerging" to preserve incoming links to it -->
<dfn id="3RGBmerging">
<dt>RGB merging</dt></dfn>

<dd>converting an image in which the red, green, and blue <a
href="#3sample"><span class="Definition">samples</span></a> for
each <a href="#3pixel"><span class="Definition">pixel</span></a>
have the same value, and the same <a href="#3sampleDepth"><span
class="Definition">sample depth</span></a>, into an image with a
single <a href="#3greyscale"><span class=
"Definition">greyscale</span></a> <a href="#3channel"><span
class="Definition">channel</span></a>.</dd>

<!-- Maintain a fragment named "3sample" to preserve incoming links to it -->
<dfn id="3sample">
<dt>sample</dt></dfn>

<dd>intersection of a <a href="#3channel"><span class=
"Definition">channel</span></a> and a <a href="#3pixel"><span
class="Definition">pixel</span></a> in an image.</dd>

<!-- Maintain a fragment named "3sampleDepth" to preserve incoming links to it -->
<dfn id="3sampleDepth">
<dt>sample depth</dt></dfn>

<dd>number of bits used to represent a <a href="#3sample"><span
class="Definition">sample</span></a> value. In an <a href=
"#3indexedColour"><span class=
"Definition">indexed-colour</span></a> <a href="#3PNGimage"><span
class="Definition">PNG image</span></a>, samples are stored in
the <a href="#3palette"><span class=
"Definition">palette</span></a> and thus the sample depth is
always 8 by definition of the palette. In other types of PNG
image it is the same as the <a href="#3bitDepth"><span class=
"Definition">bit depth</span></a>.</dd>

<!-- Maintain a fragment named "3sampleDepthScaling" to preserve incoming links to it -->
<dfn id="3sampleDepthScaling">
<dt>sample depth
scaling</dt></dfn>

<dd>mapping of a range of <a href="#3sample"><span class=
"Definition">sample</span></a> values onto the full range of a <a
href="#3sampleDepth"><span class="Definition">sample
depth</span></a> allowed in a <a href="#3PNGimage"><span class=
"Definition">PNG image</span></a>.</dd>

<!-- Maintain a fragment named "3scanline" to preserve incoming links to it -->
<dfn id="3scanline">
<dt>scanline</dt></dfn>

<dd>row of <a href="#3pixel"><span class=
"Definition">pixels</span></a> within an image or <a href=
"#3interlacedPNGimage"><span class="Definition">interlaced PNG
image</span></a>.</dd>

<!-- Maintain a fragment named "3sourceImage" to preserve incoming links to it -->
<dfn id="3sourceImage">
<dt>source image</dt></dfn>

<dd>image which is presented to a <a href="#3PNGencoder"><span
class="Definition">PNG encoder</span></a>.</dd>

<!-- Maintain a fragment named "3truecolour" to preserve incoming links to it -->
<dfn id="3truecolour">
<dt>truecolour</dt></dfn>

<dd>image representation in which each <a href="#3pixel"><span
class="Definition">pixel</span></a> is defined by <a href=
"#3sample"><span class="Definition">samples</span></a>,
representing red, green, and blue intensities and optionally an
<a href="#3alpha"><span class="Definition">alpha</span></a>
sample (in which case it is referred to as truecolour with
alpha).</dd>

<!-- Maintain a fragment named "3whitePoint" to preserve incoming links to it -->
<dfn id="3whitePoint">
<dt>white point</dt></dfnn>

<dd><a href="#3chromaticity"><span class=
"Definition">chromaticity</span></a> of a computer display's
nominal white value.</dd>

<!-- Maintain a fragment named "3zlib" to preserve incoming links to it -->
<dfn id="3zlib">
<dt>zlib</dt></dfn>

<dd>particular format for data that have been compressed using <a
href="#3deflate"><span class=
"Definition">deflate</span></a>-style compression. Also the name
of a library containing a sample implementation of this method.
The format is defined in [[rfc1950]].</dd>
</dl>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<section>
<!-- Maintain a fragment named "3Abbreviations" to preserve incoming links to it -->
<h2 name="3Abbreviations"><a name="abbreviated-terms">Abbreviated terms</a></h2>

<dl>
<!-- Maintain a fragment named "3CRC" to preserve incoming links to it -->
<dfn id="3CRC">
<dt>CRC</dt></dfn>

<dd>Cyclic Redundancy Code. A CRC is a type of check value
designed to detect most transmission errors. A decoder calculates
the CRC for the received data and checks by comparing it to the
CRC calculated by the encoder and appended to the data.
A mismatch
indicates that the data or the CRC were corrupted in
transit.</dd>

<!-- Maintain a fragment named "3CRT" to preserve incoming links to it -->
<dfn id="3CRT">
<dt>CRT</dt></dfn>

<dd>Cathode Ray Tube: a common type of computer display
hardware.</dd>

<!-- Maintain a fragment named "3LSB" to preserve incoming links to it -->
<dfn id="3LSB">
<dt>LSB</dt></dfn>

<dd>Least Significant Byte of a multi-<a href="#3byte"><span
class="Definition">byte</span></a> value.</dd>

<!-- Maintain a fragment named "3LUT" to preserve incoming links to it -->
<dfn id="3LUT">
<dt>LUT</dt></dfn>

<dd>Look Up Table. In <a href="#3frameBuffer"><span class=
"Definition">frame buffer</span></a> hardware, a LUT can be used
to map <a href="#3indexedColour"><span class=
"Definition">indexed-colour</span></a> <a href="#3pixel"><span
class="Definition">pixels</span></a> into a selected set of <a
href="#3truecolour"><span class=
"Definition">truecolour</span></a> values, or to perform <a href=
"#3gamma"><span class="Definition">gamma</span></a> correction.
In software, a LUT can often be used as a fast way of
implementing any mathematical function of a single integer
variable.</dd>

<!-- Maintain a fragment named "3MSB" to preserve incoming links to it -->
<dfn id="3MSB">
<dt>MSB</dt></dfn>

<dd>Most Significant Byte of a multi-<a href="#3byte"><span
class="Definition">byte</span></a> value.</dd>
</dl>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<section>
<!-- Maintain a fragment named "4Concepts" to preserve incoming links to it -->
<h2 name="4Concepts">Concepts</h2>

<section>
<!-- Maintain a fragment named "4Concepts.Sourceimage" to preserve incoming links to it -->
<h2 name="4Concepts.Sourceimage">Images</h2>

<p>This specification specifies the PNG datastream, and
places some requirements on PNG encoders, which generate PNG
datastreams, PNG decoders, which interpret PNG datastreams, and
PNG editors, which transform one PNG datastream into another. It
does not specify the interface between an application and either
a PNG encoder, decoder, or editor. The precise form in which an
image is presented to an encoder or delivered by a decoder is not
specified. Four kinds of image are distinguished.</p>

<ol>
<li>The <i>source image</i> is the image presented to a PNG
encoder.</li>

<li>The <i>reference image</i>, which only exists conceptually,
is a rectangular array of rectangular pixels, all having the same
width and height, and all containing the same number of unsigned
integer samples, either three (red, green, blue) or four (red,
green, blue, alpha). The array of all samples of a particular
kind (red, green, blue, or alpha) is called a channel. Each
channel has a sample depth in the range 1 to 16, which is the
number of bits used by every sample in the channel. Different
channels may have different sample depths. The red, green, and
blue samples determine the intensities of the red, green, and
blue components of the pixel's colour; if they are all zero, the
pixel is black, and if they all have their maximum values
(2<sup>sampledepth</sup>-1), the pixel is white. The alpha sample
determines a pixel's degree of opacity, where zero means fully
transparent and the maximum value means fully opaque. In a
three-channel reference image all pixels are fully opaque. (It is
also possible for a four-channel reference image to have all
pixels fully opaque; the difference is that the latter has a
specific alpha sample depth, whereas the former does not.) Each
horizontal row of pixels is called a scanline. Pixels are ordered
from left to right within each scanline, and scanlines are
ordered from top to bottom. A PNG encoder may transform the source
image directly into a PNG image, but conceptually it first
transforms the source image into a reference image, then
transforms the reference image into a PNG image. Depending on the
type of source image, the transformation from the source image to
a reference image may require the loss of information. That
transformation is beyond the scope of this International
Standard. The reference image, however, can always be recovered
exactly from a PNG datastream.</li>

<li>The <i>PNG image</i> is obtained from the reference image by
a series of transformations: alpha separation, indexing, RGB
merging, alpha compaction, and sample depth scaling. Five types
of PNG image are defined (see 6.1: <a href=
"#colour-types-and-values"><span class="xref">Colour types and
values</span></a>). (If the PNG encoder actually transforms the
source image directly into the PNG image, and the source image
format is already similar to the PNG image format, the encoder
may be able to avoid doing some of these transformations.)
Although not all sample depths in the range 1 to 16 bits are
explicitly supported in the PNG image, the number of significant
bits in each channel of the reference image may be recorded. All
channels in the PNG image have the same sample depth. A PNG
encoder generates a PNG datastream from the PNG image. A PNG
decoder takes the PNG datastream and recreates the PNG
image.</li>

<li>The <i>delivered image</i> is constructed from the PNG image
obtained by decoding a PNG datastream. No specific format is
specified for the delivered image. A viewer presents an image to
the user as close to the appearance of the original source image
as it can achieve.</li>
</ol>

<p>The relationships between the four kinds of image are
illustrated in <a href="#image-relationship"></a>.</p>

<figure id="image-relationship">
<!-- Maintain a fragment named "figure41" to preserve incoming links to it -->
<a name="figure41"></a>
<object data="figures/image-relationship.svg" type="image/svg+xml" width="640" height="290">
   <img height="280" width="640" src="png-figures/image-relationship.png" alt="Relationships between
source, reference, PNG, and display images" />
</object>
<figcaption>Relationships between source, reference, PNG, and display images</figcaption>
</figure>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<p>The relationships between samples, channels, pixels, and
sample depth are illustrated in <a href="#sample-pixel-channel-relationship"></a>.</p>

<figure id="sample-pixel-channel-relationship">
<!-- Maintain a fragment named "figure42" to preserve incoming links to it -->
<a name="figure42"></a>
<object data="figures/sample-pixel-channel-relationship.svg" type="image/svg+xml" width="640" height="290">
  <img height="290" width="640" src="png-figures/sample-pixel-channel-relationship.png" alt="Relationships between
sample, sample depth, pixel, and channel" />
</object>
<figcaption>Relationships between sample, sample depth, pixel, and channel</figcaption>
</figure>

</section>

<!-- Maintain a fragment named "4Concepts.ColourSpaces" to preserve incoming links to it -->
<section id="4Concepts.ColourSpaces">
<h2>Colour spaces</h2>

<p>The RGB colour space in which colour samples are situated may
be specified in one of four ways:</p>

<!-- <ol start="1"> --><ol>

<li>by CICP metadata;</li>

<li>by an ICC profile;</li>

<li>by specifying explicitly that the colour space is sRGB when
the samples conform to this colour space;</li>

<li>by specifying the value of gamma and the 1931 CIE <i>x,y</i>
chromaticities of the red, green, and blue primaries used in the
image and the reference white point.</li>
</ol>

<p>For high-end applications the first two methods provides the most
flexibility and control. The third method enables one particular
colour space to be indicated. The fourth method enables the exact
chromaticities of the RGB data to be specified, along with the
gamma correction (the power function relating the desired display
output with the image samples) to be applied (see Annex C: <a
href="#C-GammaAppendix"><span class="xref">Gamma and
chromaticity</span></a>). It is recommended that explicit gamma
information also be provided when either the first, second or third
method is used, for use by PNG decoders that do not support
CICP metadata, full
ICC profiles or the sRGB colour space. Such PNG decoders can
still make sensible use of gamma information. PNG decoders are
strongly encouraged to use this information, plus information
about the display system, in order to present the image to the
viewer in a way that reproduces as closely as possible what the image's original author
saw.</p>

<p>Gamma correction is not applied to the alpha channel, if
present. Alpha samples always represent a linear fraction of full
opacity.</p>
</section>

<!-- Maintain a fragment named "4Concepts.PNGImageTransformation" to preserve incoming links to it -->
<section id="4Concepts.PNGImageTransformation">
<h2>Reference
image to PNG image transformation</h2>

<!-- Maintain a fragment named "4Concepts.Introduction" to preserve incoming links to it -->
<section class="introductory" id="4Concepts.Introduction">
<p>A number of transformations are applied to the reference image
to create the PNG image to be encoded (see <a href=
"#reference-to-png-transformation"></a>). The
transformations are applied in the following sequence, where
square brackets mean the transformation is optional:</p>

<pre>
        [alpha separation]
        indexing or ( [RGB merging] [alpha compaction] )
        sample depth scaling
</pre>

<p>When every pixel is either fully transparent or fully opaque,
the alpha separation, alpha compaction, and indexing
transformations can cause the recovered reference image to have
an alpha sample depth different from the original reference
image, or to have no alpha channel. This has no effect on the
degree of opacity of any pixel. The two reference images are
considered equivalent, and the transformations are considered
lossless. Encoders that nevertheless wish to preserve the alpha
sample depth may elect not to perform transformations that would
alter the alpha sample depth.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<figure id="reference-to-png-transformation">
<!-- Maintain a fragment named "figure43" to preserve incoming links to it -->
<a name="figure43"></a>
<object data="figures/reference-to-png-transformation.svg" type="image/svg+xml" height="525" width="640">
<img height="525" width="640" src="png-figures/reference-to-png-transformation.png" alt="Reference image to PNG
image transformation" />
</object>
<figcaption>Reference image to PNG image transformation</figcaption>
</figure>

</section>

<!-- Maintain a fragment named "4Concepts.Implied-alpha" to preserve incoming links to it -->
<section id="4Concepts.Implied-alpha">
<h2>Alpha
separation</h2>

<p>If all alpha samples in a reference image have the maximum
value, then the alpha channel may be omitted, resulting in an
equivalent image that can be encoded more compactly.</p>
</section>

<!-- Maintain a fragment named "4Concepts.Indexing" to preserve incoming links to it -->
<section id="4Concepts.Indexing">
<h2><a name="indexing">Indexing</a></h2>

<p>If the number of distinct pixel values is 256 or less, and the
RGB sample depths are not greater than 8, and the alpha channel
is absent or exactly 8 bits deep or every pixel is either fully
transparent or fully opaque, then an alternative representation
called indexed-colour may be more efficient for encoding.
Each pixel is replaced by an index into a palette.
The palette is a list of entries each containing
three 8-bit samples (red, green, blue). If an alpha channel is
present, there is also a parallel table of 8-bit alpha
samples.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<figure id="indexed-colour-image">
<!-- Maintain a fragment named "figure44" to preserve incoming links to it -->
<a name="figure44"></a>
<object height="450" width="660" data="figures/indexed-colour-image.svg" type="image/svg+xml">
  <img height="450" width="660" src="png-figures/indexed-colour-image.png" alt="Indexed-colour
image" />
</object>
<figcaption>Indexed-colour image</figcaption>
</figure>


<p>A suggested palette or palettes may be constructed even when
the PNG image is not indexed-colour in order to assist viewers
that are capable of displaying only a limited number of
colours.</p>

<p>For indexed-colour images, encoders can rearrange the palette
so that the table entries with the maximum alpha value are
grouped at the end. In this case the table can be encoded in a
shortened form that does not include these entries.</p>
</section>

<!-- Maintain a fragment named "4Concepts.RGBMerging" to preserve incoming links to it -->
<section id="4Concepts.RGBMerging">
<h2>RGB merging</h2>

<p>If the red, green, and blue channels have the same sample
depth, and for each pixel the values of the red, green, and blue
samples are equal, then these three channels may be merged into a
single greyscale channel.</p>
</section>

<section>
<!-- Maintain a fragment named "4Concepts.Alpha-indexing" to preserve incoming links to it -->
<h2 id="4Concepts.Alpha-indexing">Alpha
compaction</h2>

<p>For non-indexed images, if there exists an RGB (or greyscale)
value such that all pixels with that value are fully transparent
while all other pixels are fully opaque, then the alpha channel
can be represented more compactly by merely identifying the RGB
(or greyscale) value that is transparent.</p>
</section>

<!-- Maintain a fragment named "4Concepts.Scaling" to preserve incoming links to it -->
<section id="4Concepts.Scaling">
<h2>Sample depth
scaling</h2>

<p>In the PNG image, not all sample depths are supported (see
6.1: <a href="#colour-types-and-values"><span class="xref">Colour types
and values</span></a>), and all channels shall have the same
sample depth. All channels of the PNG image use the smallest
allowable sample depth that is not less than any sample depth in
the reference image, and the possible sample values in the
reference image are linearly mapped into the next allowable range
for the PNG image. <a href="#scaling-sample-values"></a> shows how samples of depth 3 might
be mapped into samples of depth 4.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<figure id="scaling-sample-values">
<!-- Maintain a fragment named "figure45" to preserve incoming links to it -->
<a name="figure45"></a>
<object height="320" width="640" data="figures/scaling-sample-values.svg" type="image/svg+xml">
  <img height="320" width="640" src="png-figures/scaling-sample-values.png" alt="Scaling sample
values" />
</object>
<figcaption class="Figuretitle">Scaling sample values</figcaption>
</figure>

<p>Allowing only a few sample depths reduces the number of cases
that decoders have to cope with. Sample depth scaling is
reversible with no loss of data, because the reference image
sample depths can be recorded in the PNG datastream. In the
absence of recorded sample depths, the reference image sample
depth equals the PNG image sample depth. See 12.5: <a href=
"#sample-depth-scaling-1"><span class="xref">Sample depth
scaling</span></a> and 13.12: <a href=
"#sample-depth-rescaling"><span class="xref">Sample depth
rescaling</span></a>.</p>

<figure id="possible-pixel-types">
<!-- Maintain a fragment named "figure46" to preserve incoming links to it -->
<a name="figure46"></a>
<object height="450" width="660" data="figures/possible-pixel-types.svg" type="image/svg+xml">
  <img  height="450" width="660" src= "png-figures/possible-pixel-types.png" alt="Possible PNG image
pixel types" />
</object>
<figcaption>Possible PNG image pixel types</figcaption>
</figure>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "4Concepts.PNGImage" to preserve incoming links to it -->
<section id="4Concepts.PNGImage">
<h2>PNG image</h2>

<p>The transformation of the reference image results in one of
five types of PNG image (see <a href="#possible-pixel-types"></a>) :</p>

<!-- <ol start="1"> --><ol>
<li>Truecolour with alpha: each pixel consists of four samples:
red, green, blue, and alpha.</li>

<li>Greyscale with alpha: each pixel consists of two samples:
grey and alpha.</li>

<li>Truecolour: each pixel consists of three samples: red, green,
and blue. The alpha channel may be represented by a single RGB pixel
value. Matching pixels are fully transparent, and all others are
fully opaque. If the alpha channel is not represented in this
way, all pixels are fully opaque.</li>

<li>Greyscale: each pixel consists of a single sample: grey. The
alpha channel may be represented by a single greyscale pixel value,
 similar to
the previous case. If the alpha channel is not represented in
this way, all pixels are fully opaque.</li>

<li>Indexed-colour: each pixel consists of an index into a palette (and into an associated table of alpha values, if present).</li>
</ol>

<p>The format of each pixel depends on the PNG image type and the
bit depth. For PNG image types other than indexed-colour,
the bit depth specifies the number of bits per sample, not the
total number of bits per pixel.
For indexed-colour images, the bit depth specifies the
number of bits in each palette index, not the sample depth of the
colours in the palette or alpha table. Within the pixel the
samples appear in the following order, depending on the PNG image
type.</p>

<!-- <ol start="6"> --><ol>
<li>Truecolour with alpha: red, green, blue, alpha.</li>

<li>Greyscale with alpha: grey, alpha.</li>

<li>Truecolour: red, green, blue.</li>

<li>Greyscale: grey.</li>

<li>Indexed-colour: palette index.</li>
</ol>
</section>

<!-- Maintain a fragment named "4Concepts.Encoding" to preserve incoming links to it -->
<section id="4Concepts.Encoding">
<h2>Encoding the PNG
image</h2>

<!-- Maintain a fragment named "4Concepts.EncodingIntro" to preserve incoming links to it -->
<section class="introductory" id="4Concepts.EncodingIntro">
<p>A conceptual model of the process of encoding a PNG image is
given in <a href="#encoding-png-image"><span class="figref"></a>.
The steps refer to the operations on the array of
pixels or indices in the PNG image. The palette and alpha table
are not encoded in this way.</p>

<!-- <ol start="1"> --><ol>
<li>Pass extraction: to allow for progressive display, the PNG
image pixels can be rearranged to form several smaller images
called reduced images or passes.</li>

<li>Scanline serialization: the image is serialized a scanline at
a time. Pixels are ordered left to right in a scanline and
scanlines are ordered top to bottom.</li>

<li>Filtering: each scanline is transformed into a filtered
scanline using one of the defined filter types to prepare the
scanline for image compression.</li>

<li>Compression: occurs on all the filtered scanlines in the
image.</li>

<li>Chunking: the compressed image is divided into conveniently
sized chunks. An error detection code is added to each
chunk.</li>

<li>Datastream construction: the chunks are inserted into the
datastream.</li>
</ol>
</section>

<!-- Maintain a fragment named "4Concepts.EncodingPassAbs" to preserve incoming links to it -->
<section id="4Concepts.EncodingPassAbs">
<h2>Pass
extraction</h2>

<p>Pass extraction (see <a href="#3passExtraction"></a>) splits a PNG image into a
sequence of reduced images where the first image defines a coarse
view and subsequent images enhance this coarse view until the
last image completes the PNG image. The set of reduced images is
also called an interlaced PNG image. Two interlace methods are
defined in this specification. The first method is a
null method; pixels are stored sequentially from left to right
and scanlines from top to bottom. The second method makes
multiple scans over the image to produce a sequence of seven
reduced images. The seven passes for a sample image are
illustrated in <a href="#3passExtraction"></a>. See clause&#160;8: <a href="#interlacing-and-pass-extraction"><span class=
"xref">Interlacing and pass extraction</span></a>.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<figure id="encoding-png-image">
<!-- Maintain a fragment named "figure47" to preserve incoming links to it -->
<a name="figure47"></a>
<object height="575" width="645" data="figures/encoding-png-image.svg" type="image/svg+xml">
	<img height="575" width="645" src="png-figures/encoding-png-image.png" alt="Encoding the PNG
image" />
</object>
<figcaption>Encoding the PNG image</figcaption>
</figure>


<figure id="pass-extraction">
<!-- Maintain a fragment named "figure48" to preserve incoming links to it -->
<a name="figure48"></a>
<object height="450" width="645" data="figures/pass-extraction.svg" type="image/svg+xml">
	<img height="450" width="645" src="png-figures/pass-extraction.png" alt="Pass extraction" />
</object>
<figcaption>Pass extraction</figcaption>
</figure>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "4Concepts.EncodingScanlineAbs" to preserve incoming links to it -->
<section id="4Concepts.EncodingScanlineAbs">
<h2>Scanline
serialization</h2>

<p>Each row of pixels, called a scanline, is represented as a
sequence of bytes.</p>
</section>

<!-- Maintain a fragment named "4Concepts.EncodingFiltering" to preserve incoming links to it -->
<section id="4Concepts.EncodingFiltering">
<h2>Filtering</h2>

<p>PNG standardizes one filter method and several filter types
that may be used to prepare image data for compression. It
transforms the byte sequence in a scanline to an equal length
sequence of bytes preceded by a filter type byte (see <a href=
"#serializing-and-filtering-scanline"></a> for an
example). The filter type byte defines
the specific filtering to be applied to a specific
scanline. The encoder shall use only a single filter method for
an interlaced PNG image, but may use different filter types for
each scanline in a reduced image. See clause&#160;9: <a href=
"#filtering-2"><span class="xref">Filtering</span></a>.</p>

<figure id="serializing-and-filtering-scanline">
<!-- Maintain a fragment named "figure49" to preserve incoming links to it -->
<a name="figure49"></a>
<object height="340" width="710" data="figures/serializing-and-filtering-scanline.svg" type="image/svg+xml">
  <img height="340" width="710" src="png-figures/serializing-and-filtering-scanline.png" alt="Serializing and
filtering a scanline" />
</object>
<figcaption>Serializing and filtering a scanline</figcaption>
</figure>
</section>

<!-- Maintain a fragment named "4Concepts.EncodingCompression" to preserve incoming links to it -->
<section id="4Concepts.EncodingCompression">
<h2>Compression</h2>

<p>The sequence of filtered scanlines in the pass or passes of
the PNG image is compressed (see <a href="#compression"></a>) by one of the defined
compression methods. The concatenated filtered scanlines form the
input to the compression stage. The output from the compression
stage is a single compressed datastream. See clause&#160;10: <a href=
"#compression-1"><span class="xref">Compression</span></a>.</p>
</section>

<!-- Maintain a fragment named "4Concepts.EncodingChunking" to preserve incoming links to it -->
<section id="4Concepts.EncodingChunking">
<h2>Chunking</h2>

<p>Chunking provides a convenient breakdown of the compressed
datastream into manageable chunks (see <a href="#compression"></a>). Each chunk has its own
redundancy check. See clause&#160;11: <a href="#chunk-specifications"><span class=
"xref">Chunk specifications</span></a>.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<figure id="compression">
<!-- Maintain a fragment named "figure410" to preserve incoming links to it -->
<a name="figure410"></a>
<object height="450" width="700" data="figures/compression.svg" type="image/svg+xml">
 <img height="450" width="700" src="png-figures/compression.png" alt="Compression" />
</object>
<figcaption>Compression</figcaption>
</figure>
</section>
</section>

<!-- Maintain a fragment named "4Concepts.AncillInfo" to preserve incoming links to it -->
<section id="4Concepts.AncillInfo">
<h2>Additional
information</h2>

<p>Ancillary information may be associated with an image.
Decoders may ignore all or some of the ancillary information. The
types of ancillary information provided are described in <a href=
"#table41"><span class="tabref">Table 4.1</span></a>.</p>

<table class="Regular" summary=
"This table lists the types of ancillary information that may be associated with an image">
<caption><a name="table41"><b>Table 4.1 &mdash; Types of
ancillary information</b></a></caption>

<tr>
<th>Type of information</th>
<th>Description</th>
</tr>

<tr>
<td class="Regular">Background colour</td>
<td class="Regular">Solid background colour to be used when presenting the image
if no better option is available.</td>
</tr>

<tr>
<td class="Regular">Gamma and chromaticity</td>
<td class="Regular">Gamma characteristic of the image with respect to the desired
output intensity, and chromaticity characteristics of the RGB
values used in the image.</td>
</tr>

<tr>
<td class="Regular">ICC profile</td>
<td class="Regular">Description of the colour space (in the form of an
International Color Consortium (ICC) profile) to which the
samples in the image conform.</td>
</tr>

<tr>
<td class="Regular">Image histogram</td>
<td class="Regular">Estimates of how frequently the image uses each palette entry.</td>
</tr>

<tr>
<td class="Regular">Physical pixel dimensions</td>
<td class="Regular">Intended pixel size and aspect ratio to be used in presenting
the PNG image.</td>
</tr>

<tr>
<td class="Regular">Significant bits</td>
<td class="Regular">The number of bits that are significant in the samples.</td>
</tr>

<tr>
<td class="Regular">sRGB colour space</td>
<td class="Regular">A rendering intent (as defined by the International Color
Consortium) and an indication that the image samples conform to
this colour space.</td>
</tr>

<tr>
<td class="Regular">Suggested palette</td>
<td class="Regular">A reduced palette that may be used when the display device is
not capable of displaying the full range of colours in the
image.</td>
</tr>

<tr>
<td class="Regular">Textual data</td>
<td class="Regular">Textual information (which may be compressed) associated with
the image.</td>
</tr>

<tr>
<td class="Regular">Time</td>
<td class="Regular">The time when the PNG image was last modified.</td>
</tr>

<tr>
<td class="Regular">Transparency</td>
<td class="Regular">Alpha information that allows the reference image to be
reconstructed when the alpha channel is not retained in the PNG
image.</td>
</tr>
</table>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "4Concepts.Format" to preserve incoming links to it -->
<section id="4Concepts.Format">
<h2>PNG datastream</h2>

<!-- Maintain a fragment named "4Concepts.FormatChunks" to preserve incoming links to it -->
<section id="4Concepts.FormatChunks">
<h2>Chunks</h2>

<p>The PNG datastream consists of a PNG signature (see 5.2: <a
href="#png-signature"><span class="xref">PNG
signature</span></a>) followed by a sequence of chunks (see
clause&#160;11: <a href="#chunk-specifications"><span class="xref">Chunk
specifications</span></a>). Each chunk has a chunk type which
specifies its function.</p>
</section>

<!-- Maintain a fragment named "4Concepts.FormatTypes" to preserve incoming links to it -->
<section id="4Concepts.FormatTypes">
<h2>Chunk types</h2>

<p>There are 19 chunk types defined in this International
Standard. Chunk types are four-byte sequences chosen so that they
correspond to readable labels when interpreted in the ISO 646.IRV:1991
character set. The first four are termed critical chunks, which
shall be understood and correctly interpreted according to the
provisions of this specification. These are:</p>

<!-- <ol start="1"> --><ol>
<li><a href="#ihdr-image-header"><span class="chunk">IHDR</span></a>: image
header, which is the first chunk in a PNG datastream.</li>

<li><a href="#plte-palette"><span class="chunk">PLTE</span></a>:
palette table associated with indexed PNG images.</li>

<li><a href="#idat-image-data"><span class="chunk">IDAT</span></a>: image
data chunks.</li>

<li><a href="#iend-image-trailer"><span class="chunk">IEND</span></a>: image
trailer, which is the last chunk in a PNG datastream.</li>
</ol>

<p>The remaining 14 chunk types are termed ancillary chunk types,
which encoders may generate and decoders may interpret.</p>

<!-- <ol start="5"> --><ol>
<li>Transparency information: <a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> (see 11.3.2: <a class='Href' href=
'#transparency-information'>Transparency information</a>).</li>

<li>Colour space information: <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a>, <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a>, <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a>, <a href="#sbit-significant-bits"><span class=
"chunk">sBIT</span></a>, <a href="#srgb-standard-rgb-colour-space"><span class=
"chunk">sRGB</span></a> (see 11.3.3: <a class='Href' href=
'#colour-space-information'>Colour space information</a>).</li>

<li>Textual information: <a href="#itxt-international-textual-data"><span class=
"chunk">iTXt</span></a>, <a href="#text-textual-data"><span class=
"chunk">tEXt</span></a>, <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a> (see 11.3.4: <a class='Href' href=
'#textual-information'>Textual information</a>).</li>

<li>Miscellaneous information: <a href="#bkgd-background-colour"><span class=
"chunk">bKGD</span></a>, <a href="#hist-image-histogram"><span class=
"chunk">hIST</span></a>, <a href="#phys-physical-pixel-dimensions"><span class=
"chunk">pHYs</span></a>, <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a>, <a href="#exif"><span class=
"chunk">eXIf</span></a>
(see 11.3.5: <a class='Href' href=
'#miscellaneous-information'>Miscellaneous information</a>).</li>

<li>Time information: <a href="#time-image-last-modification-time"><span class=
"chunk">tIME</span></a> (see 11.3.6: <a class='Href' href=
'#time-stamp-information'>Time stamp information</a>).</li>
</ol>
</section>
</section>

<!-- Maintain a fragment named "4Concepts.Errors" to preserve incoming links to it -->
<section id="4Concepts.Errors">
<h2>Error handling</h2>

<p>Errors in a PNG datastream fall into two general classes:</p>

<!-- <ol start="1"> --><ol>
<li>transmission errors or damage to a computer file system,
which tend to corrupt much or all of the datastream;</li>

<li>syntax errors, which appear as invalid values in chunks, or
as missing or misplaced chunks. Syntax errors can be caused not
only by encoding mistakes, but also by the use of registered or
private values, if those values are unknown to the decoder.</li>
</ol>

<p>PNG decoders should detect errors as early as possible,
recover from errors whenever possible, and fail gracefully
otherwise. The error handling philosophy is described in detail
in 13.2: <a href="#error-handling-1"><span class="xref">Error
handling</span></a>.</p>
</section>

<!-- Maintain a fragment named "4Concepts.Registration" to preserve incoming links to it -->
<section id="4Concepts.Registration">
<h2>Extension and
registration</h2>

<p>
  For some facilities in PNG, there are a number of alternatives
  defined, and this specification allows other
  alternatives to be defined by registration.
</p>

<p>The following entities may be registered:</p>

<!-- <ol start="1"> --><ol>
<li>chunk type;</li>

<li>text keyword.</li>
</ol>

<p>The following entities are reserved for future
standardization:</p>

<!-- <ol start="4"> --><ol>
<li>undefined field values less than 128;</li>

<li>filter method;</li>

<li>filter type;</li>

<li>interlace method;</li>

<li>compression method.</li>
</ol>

<p>
  Registration requests should be made by
  <a href="https://github.com/w3c/PNG-spec/issues">raising an issue on GitHub</a>.
</p>
</section>
</section>

<!-- Maintain a fragment named "5DataRep" to preserve incoming links to it -->
<section id="5DataRep">
<h2>Datastream structure</h2>

<!-- Maintain a fragment named "5Introduction" to preserve incoming links to it -->
<section class="introductory" id="5Introduction">
<p>This clause defines the PNG signature and the basic properties
of chunks. Individual chunk types are discussed in clause&#160;11: <a
href="#chunk-specifications"><span class="xref">Chunk
specifications</span></a>.</p>
</section>

<!-- Maintain a fragment named "5PNG-file-signature" to preserve incoming links to it -->
<section id="5PNG-file-signature">
<h2>PNG signature</h2>

<p>The first eight bytes of a PNG datastream always contain the
following (decimal) values:</p>

<pre>
   137 80 78 71 13 10 26 10
</pre>

<p>which are (in hexadecimal):</p>

<pre>
  89 50 4E 47 0D 0A 1A 0A
</pre>

<p>This signature indicates that the remainder of the datastream
contains a single PNG image, consisting of a series of chunks
beginning with an <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> chunk and ending with an <a href=
"#iend-image-trailer"><span class="chunk">IEND</span></a> chunk.</p>
</section>

<!-- Maintain a fragment named "5Chunk-layout" to preserve incoming links to it -->
<section id="5Chunk-layout">
<h2>Chunk layout</h2>

<p>Each chunk consists of three or four fields (see figure 5.1).
The meaning of the fields is described in
<a href="#table51"><span class="tabref">Table 5.1</span></a>.
The chunk data field may be empty.</p>

<figure id="chunk-parts">
<!-- Maintain a fragment named "figure411" to preserve incoming links to it -->
<a name="figure411"></a>
<object height="160" width="480" data="figures/chunk-parts.svg" type="image/svg+xml">
 <img height="160" width="480" src="png-figures/chunk-parts.png" alt="Chunk parts" />
</object>
<figcaption>Chunk parts</figcaption>
</figure>


<table class="Regular" summary=
"This table defines the chunk fields">
<caption><a name="table51"><b>Table 5.1 &mdash; Chunk fields</b></a></caption>
<tr>
<td class="Regular">Length</td>
<td class="Regular">A four-byte unsigned integer giving the number of bytes in
the chunk's data field. The length counts <strong>only</strong>
the data field, <strong>not</strong> itself, the chunk type, or
the CRC. Zero is a valid length. Although encoders and decoders
should treat the length as unsigned, its value shall not exceed
2<sup>31</sup>-1 bytes.</td>
</tr>

<tr>
<td class="Regular">Chunk Type</td>
<td class="Regular">A sequence of four bytes defining the chunk type. Each byte
of a chunk type is restricted to the decimal values 65 to 90 and
97 to 122. These correspond to the uppercase and lowercase ISO
646 letters (<tt>A</tt>-<tt>Z</tt> and <tt>a</tt>-<tt>z</tt>)
respectively for convenience in description and examination of
PNG datastreams. Encoders and decoders shall treat the chunk
types as fixed binary values, not character strings. For example,
it would not be correct to represent the chunk type <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a> by the equivalents
of those letters in the UCS 2 character set. Additional naming
conventions for chunk types are discussed in 5.4: <a href=
"#chunk-naming-conventions"><span class="xref">Chunk naming
conventions</span></a>.</td>
</tr>

<tr>
<td class="Regular">Chunk Data</td>
<td class="Regular">The data bytes appropriate to the chunk type, if any. This
field can be of zero length.</td>
</tr>

<tr>
<td class="Regular">CRC</td>
<td class="Regular">A four-byte CRC (Cyclic Redundancy Code) calculated on the
preceding bytes in the chunk, including the chunk type field and
chunk data fields, but <strong>not</strong> including the length
field. The CRC can be used to check for corruption of the data.
The CRC is always present, even for chunks containing no data.
See 5.5: <a href="#cycling-redundancy-code-algorithm"><span class="xref">Cyclic
Redundancy Code algorithm</span></a>.</td>
</tr>
</table>

<p>The chunk data length may be any number of bytes up to the
maximum; therefore, implementors cannot assume that chunks are
aligned on any boundaries larger than bytes.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "5Chunk-naming-conventions" to preserve incoming links to it -->
<section id="5Chunk-naming-conventions">
<h2>Chunk naming
conventions</h2>

<p>Chunk types are chosen to be meaningful names when the bytes
of the chunk type are interpreted as ISO 646 letters. Chunk types
are assigned so that a decoder can determine some properties of a
chunk even when the type is not recognized. These rules allow
safe, flexible extension of the PNG format, by allowing a PNG
decoder to decide what to do when it encounters an unknown chunk.
(The chunk types standardized in this specification are
defined in clause&#160;11: <a href="#chunk-specifications"><span class=
"xref">Chunk specifications</span></a>, and the way to add
non-standard chunks is defined in clause&#160;14: <a href=
"#editors-and-extensions"><span class="xref">Editors and
extensions</span></a>.) The naming rules are normally of interest
only when the decoder does not recognize the chunk's type.</p>

<p>Four bits of the chunk type, the property bits, namely bit 5
(value 32) of each byte, are used to convey chunk properties.
This choice means that a human can read off the assigned
properties according to whether the letter corresponding to each
byte of the chunk type is uppercase (bit 5 is 0) or lowercase
(bit 5 is 1). However, decoders should test the properties of an
unknown chunk type by numerically testing the specified bits;
testing whether a character is uppercase or lowercase is
inefficient, and even incorrect if a locale-specific case
definition is used.</p>

<p>The property bits are an inherent part of the chunk type, and
hence are fixed for any chunk type. Thus, <span class=
"chunk">CHNK</span> and <span class="chunk">cHNk</span> would be
unrelated chunk types, not the same chunk with different
properties.</p>

<p>The semantics of the property bits are
defined in
<a href="#table52"><span class="tabref">Table 5.2</span></a>.
</p>

<table class="Regular" summary=
"This table defines the semantics of the property bits">
<caption><a name="table52"><b>Table 5.2 &mdash; Semantics of property bits</b></a></caption>
<tr>
<td class="Regular">Ancillary bit: first byte</td>
<td class="Regular">0 (uppercase) = critical,<br class="xhtml" />
 1 (lowercase) = ancillary.</td>
<td class="Regular">Critical chunks are necessary for successful display of the
contents of the datastream, for example the image header chunk
(<a href="#ihdr-image-header"><span class="chunk">IHDR</span></a>). A
decoder trying to extract the image, upon encountering an unknown
chunk type in which the ancillary bit is 0, shall indicate to the
user that the image contains information it cannot safely
interpret.<br class="xhtml" />
 Ancillary chunks are not strictly necessary in order to
meaningfully display the contents of the datastream, for example
the time chunk (<a href="#time-image-last-modification-time"><span class=
"chunk">tIME</span></a>). A decoder encountering an unknown chunk
type in which the ancillary bit is 1 can safely ignore the chunk
and proceed to display the image.</td>
</tr>

<tr>
<td class="Regular">Private bit: second byte</td>
<td class="Regular">0 (uppercase) = public,<br class="xhtml" />
 1 (lowercase) = private.</td>
<td class="Regular">A public chunk is one that is defined in this International
Standard or is registered in the list of PNG special-purpose
public chunk types maintained by the Registration Authority (see
4.9 <a href="extension-and-registration"><span class=
"xref">Extension and registration</span></a>). Applications can
also define private (unregistered) chunk types for their own
purposes. The names of private chunks have a lowercase second
letter, while public chunks will always be assigned names with
uppercase second letters. Decoders do not need to test the
private-chunk property bit, since it has no functional
significance; it is simply an administrative convenience to
ensure that public and private chunk names will not conflict. See
clause&#160;14: <a href="#editors-and-extensions"><span class="xref">Editors and
extensions</span></a> and 12.10.2: <a href=
"#use-of-private-chunks"><span class="xref">Use of private
chunks</span></a>.</td>
</tr>

<tr>
<td class="Regular">Reserved bit: third byte</td>
<td class="Regular">0 (uppercase) in this version of PNG.<br class="xhtml" />
 If the reserved bit is 1, the datastream does not conform to
this version of PNG.</td>
<td class="Regular">The significance of the case of the third letter of the chunk
name is reserved for possible future extension. In this
International Standard, all chunk names shall have uppercase
third letters.</td>
</tr>

<tr>
<td class="Regular">Safe-to-copy bit: fourth byte</td>
<td class="Regular">0 (uppercase) = unsafe to copy,<br class="xhtml" />
1 (lowercase) = safe to copy.</td>
<td class="Regular">This property bit is not of interest to pure decoders, but it
is needed by PNG editors. This bit defines the proper handling of
unrecognized chunks in a datastream that is being modified. Rules
for PNG editors are discussed further in 14.2: <a href=
"#behaviour-of-png-editors"><span class="xref">Behaviour of PNG
editors</span></a>.</td>
</tr>
</table>

<p>EXAMPLE The hypothetical chunk type "<span class=
"chunk">cHNk</span>" has the property bits:</p>

<pre>
   cHNk  &lt;-- 32 bit chunk type represented in text form
   ||||
   |||+- Safe-to-copy bit is 1 (lower case letter; bit 5 is 1)
   ||+-- Reserved bit is 0     (upper case letter; bit 5 is 0)
   |+--- Private bit is 0      (upper case letter; bit 5 is 0)
   +---- Ancillary bit is 1    (lower case letter; bit 5 is 1)
</pre>

<p>Therefore, this name represents an ancillary, public,
safe-to-copy chunk.</p>
</section>

<!-- Maintain a fragment named "5CRC-algorithm" to preserve incoming links to it -->
<section id="5CRC-algorithm">
<h2>Cyclic Redundancy Code
algorithm</h2>

<p>CRC fields are calculated using standardized CRC methods with
pre and post conditioning, as defined by [[ISO 3309]]
and [[ITU-T V.42]].
The CRC polynomial employed
is</p>

<p>x<sup>32</sup> + x<sup>26</sup> + x<sup>23</sup> +
x<sup>22</sup> + x<sup>16</sup> + x<sup>12</sup> + x<sup>11</sup>
+ x<sup>10</sup> + x<sup>8</sup> + x<sup>7</sup> + x<sup>5</sup>
+ x<sup>4</sup> + x<sup>2</sup> + x + 1</p>

<p>In PNG, the 32-bit CRC is initialized to all 1's, and then the
data from each byte is processed from the least significant bit
(1) to the most significant bit (128). After all the data bytes
are processed, the CRC is inverted (its ones complement is
taken). This value is transmitted (stored in the datastream) MSB
first. For the purpose of separating into bytes and ordering, the
least significant bit of the 32-bit CRC is defined to be the
coefficient of the <tt>x<sup>31</sup></tt> term.</p>

<p>Practical calculation of the CRC often employs a precalculated
table to accelerate the computation. See Annex D: <a href=
"#D-CRCAppendix"><span class="xref">Sample Cyclic Redundancy Code
implementation</span></a>.</p>
</section>

<!-- Maintain a fragment 5ChunkOrderingg" to preserve incoming links to it -->
<section id="5ChunkOrdering">
<h2>Chunk ordering</h2>

<p>The constraints on the positioning of the individual chunks
are listed in <a href="#table53"><span class="tabref">Table
5.3</span></a> and illustrated diagrammatically in <a href=
"#lattice-diagram-with-plte"></a> and <a
href="#lattice-diagram-without-plte"></a>.
These lattice diagrams represent the constraints on positioning
imposed by this specification. The lines in the diagrams
define partial ordering relationships. Chunks higher up shall
appear before chunks lower down. Chunks which are horizontally
aligned and appear between two other chunk types (higher and
lower than the horizontally aligned chunks) may appear in any
order between the two higher and lower chunk types to which they
are connected. The superscript associated with the chunk type is
defined in <a href="#table54"><span class="tabref">Table
5.4</span></a>. It indicates whether the chunk is mandatory,
optional, or may appear more than once. A vertical bar between
two chunk types indicates alternatives.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<table class="Regular" summary=
"This table lists the chunk ordering rules">
<caption><a name="table53"><b>Table 5.3 &mdash; Chunk ordering
rules</b></a></caption>

<tr>
<th colspan="3">Critical chunks<br class="xhtml" />
 (shall appear in this order, except <a href="#plte-palette"><span
class="chunk">PLTE</span></a> is optional)</th>
</tr>

<tr>
<th>Chunk name</th>
<th>Multiple allowed</th>
<th>Ordering constraints</th>
</tr>

<tr>
<td class="Regular"><a href="#ihdr-image-header"><span class="chunk">IHDR</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Shall be first</td>
</tr>

<tr>
<td class="Regular"><a href="#plte-palette"><span class="chunk">PLTE</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Before first <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> </td>
</tr>

<tr>
<td class="Regular"><a href="#idat-image-data"><span class="chunk">IDAT</span></a> </td>
<td class="Regular">Yes</td>
<td class="Regular">Multiple <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks shall be consecutive</td>
</tr>

<tr>
<td class="Regular"><a href="#iend-image-trailer"><span class="chunk">IEND</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Shall be last</td>
</tr>

<tr>
<th colspan="3">Ancillary chunks<br class="xhtml" />
 (need not appear in this order)</th>
</tr>

<tr>
<th>Chunk name</th>
<th>Multiple allowed</th>
<th>Ordering constraints</th>
</tr>

<tr>
<td class="Regular"><a href="#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Before <a href="#plte-palette"><span class="chunk">PLTE</span></a>
and <a href="#idat-image-data"><span class="chunk">IDAT</span></a> </td>
</tr>

<tr>
<td class="Regular"><a href="#gama-image-gamma"><span class="chunk">gAMA</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Before <a href="#plte-palette"><span class="chunk">PLTE</span></a>
and <a href="#idat-image-data"><span class="chunk">IDAT</span></a> </td>
</tr>

<tr>
<td class="Regular"><a href="#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Before <a href="#plte-palette"><span class="chunk">PLTE</span></a>
and <a href="#idat-image-data"><span class="chunk">IDAT</span></a>. If the
<a href="#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> chunk is
present, the <a href="#srgb-standard-rgb-colour-space"><span class=
"chunk">sRGB</span></a> chunk should not be present.</td>
</tr>

<tr>
<td class="Regular"><a href="#sbit-significant-bits"><span class="chunk">sBIT</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Before <a href="#plte-palette"><span class="chunk">PLTE</span></a>
and <a href="#idat-image-data"><span class="chunk">IDAT</span></a> </td>
</tr>

<tr>
<td class="Regular"><a href="#srgb-standard-rgb-colour-space"><span class="chunk">sRGB</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Before <a href="#plte-palette"><span class="chunk">PLTE</span></a>
and <a href="#idat-image-data"><span class="chunk">IDAT</span></a>. If the
<a href="#srgb-standard-rgb-colour-space"><span class="chunk">sRGB</span></a> chunk is
present, the <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a> chunk should not be present.</td>
</tr>

<tr>
<td class="Regular"><a href="#bkgd-background-colour"><span class="chunk">bKGD</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">After <a href="#plte-palette"><span class="chunk">PLTE</span></a>;
before <a href="#idat-image-data"><span class="chunk">IDAT</span></a>
</td>
</tr>

<tr>
<td class="Regular"><a href="#hist-image-histogram"><span class="chunk">hIST</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">After <a href="#plte-palette"><span class="chunk">PLTE</span></a>;
before <a href="#idat-image-data"><span class="chunk">IDAT</span></a>
</td>
</tr>

<tr>
<td class="Regular"><a href="#trns-transparency"><span class="chunk">tRNS</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">After <a href="#plte-palette"><span class="chunk">PLTE</span></a>;
before <a href="#idat-image-data"><span class="chunk">IDAT</span></a>
</td>
</tr>

<tr>
<td class="Regular"><a href="#phys-physical-pixel-dimensions"><span class="chunk">pHYs</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">Before <a href="#idat-image-data"><span class="chunk">IDAT</span></a>
</td>
</tr>

<tr>
<td class="Regular"><a href="#splt-suggested-palette"><span class="chunk">sPLT</span></a> </td>
<td class="Regular">Yes</td>
<td class="Regular">Before <a href="#idat-image-data"><span class="chunk">IDAT</span></a>
</td>
</tr>

<tr>
<td class="Regular"><a href="#time-image-last-modification-time"><span class="chunk">tIME</span></a> </td>
<td class="Regular">No</td>
<td class="Regular">None</td>
</tr>

<tr>
<td class="Regular"><a href="#itxt-international-textual-data"><span class="chunk">iTXt</span></a> </td>
<td class="Regular">Yes</td>
<td class="Regular">None</td>
</tr>

<tr>
<td class="Regular"><a href="#text-textual-data"><span class="chunk">tEXt</span></a> </td>
<td class="Regular">Yes</td>
<td class="Regular">None</td>
</tr>

<tr>
<td class="Regular"><a href="#ztxt-compressed-textual-data"><span class="chunk">zTXt</span></a> </td>
<td class="Regular">Yes</td>
<td class="Regular">None</td>
</tr>
</table>

<table class="Regular"  summary=
"This table lists the symbols used in lattice diagrams">
<caption><a name="table54"><b>Table 5.4 &mdash; Meaning of
symbols used in lattice diagrams</b></a></caption>

<tr>
<th>Symbol</th>
<th>Meaning</th>
</tr>

<tr>
<td class="Regular">+</td>
<td class="Regular">One or more</td>
</tr>

<tr>
<td class="Regular">1</td>
<td class="Regular">Only one</td>
</tr>

<tr>
<td class="Regular">?</td>
<td class="Regular">Zero or one</td>
</tr>

<tr>
<td class="Regular">*</td>
<td class="Regular">Zero or more</td>
</tr>
<tr>
<td class="Regular">|</td>
<td class="Regular">Alternative</td>
</tr>
</table>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<figure id="lattice-diagram-with-plte">
<!-- Maintain a fragment named "figure52" to preserve incoming links to it -->
<a name="figure52"></a>
<object height="540" width="800" data="figures/lattice-diagram-with-plte.svg" type="image/svg+xml">
 <img height="540" width="800" src="png-figures/lattice-diagram-with-plte.png" alt="Lattice diagram: PNG images with PLTE in datastream" />
</object>
<figcaption>Lattice diagram: PNG images with <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> in datastream</figcaption>
</figure>


<figure id="lattice-diagram-without-plte">
<!-- Maintain a fragment named "figure53" to preserve incoming links to it -->
<a name="figure53"></a>
<object height="540" width="900" data="figures/lattice-diagram-without-plte.svg"
type="image/svg+xml">
 <img height="540" width="900" src="png-figures/lattice-diagram-without-plte.png" alt="Lattice diagram: PNG images without PLTE in datastream" />
</object>
<figcaption>Lattice diagram: PNG images without <a href="#plte-palette"><span
class="chunk">PLTE</span></a> in datastream</figcaption>
</figure>

</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "6Transformation" to preserve incoming links to it -->
<section id="6Transformation">
<h2>Reference image to PNG image
transformation</h2>

<!-- Maintain a fragment named "6Colour-values" to preserve incoming links to it -->
<section id="6Colour-values">
<h2>Colour types and values</h2>

<p>As explained in 4.4: <a href="#png-image"><span
class="xref">PNG image</span></a> there are five types of PNG
image. Corresponding to each type is a colour type, which is the
sum of the following values: 1 (palette used), 2 (truecolour
used) and 4 (alpha used). Greyscale and truecolour images may
have an explicit alpha channel. The PNG image types and
corresponding colour types are listed in <a href=
"#table6.1"><span class="tabref">Table 6.1</span></a>.</p>

<table class="Regular"  summary=
"This table lists the PNG image and colour types">
<caption><a name="table6.1"><b>Table 6.1 &mdash; PNG image types
and colour types</b></a></caption>

<tr>
<th>PNG image type</th>
<th>Colour type</th>
</tr>

<tr>
<td class="Regular">Greyscale</td>
<td class="Regular">0</td>
</tr>

<tr>
<td class="Regular">Truecolour</td>
<td class="Regular">2</td>
</tr>

<tr>
<td class="Regular">Indexed-colour</td>
<td class="Regular">3</td>
</tr>

<tr>
<td class="Regular">Greyscale with alpha</td>
<td class="Regular">4</td>
</tr>

<tr>
<td class="Regular">Truecolour with alpha</td>
<td class="Regular">6</td>
</tr>
</table>

<p>The allowed bit depths and sample depths for each PNG image
type are listed in 11.2.2: <a href="#ihdr-image-header"><span class=
"xref"><span class="chunk">IHDR</span> Image
header</span></a>.</p>

<p>Greyscale samples represent luminance if the transfer curve is
indicated (by <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a>, <a href="#srgb-standard-rgb-colour-space"><span class=
"chunk">sRGB</span></a>, or <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a>) or device-dependent greyscale if not.
RGB samples represent calibrated colour information if the colour
space is indicated (by <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> and <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a>, or <a href="#srgb-standard-rgb-colour-space"><span class=
"chunk">sRGB</span></a>, or <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a>) or uncalibrated device-dependent colour
if not.</p>

<p>Sample values are not necessarily proportional to light
intensity; the <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunk specifies the relationship between
sample values and display output intensity. Viewers are strongly
encouraged to compensate properly. See 4.2: <a href=
"#colour-spaces"><span class="xref">Colour
spaces</span></a>, 13.13: <a href=
"#decoder-gamma-handling"><span class="xref">Decoder gamma
handling</span></a> and Annex C: <a href="#C-GammaAppendix"><span
class="xref">Gamma and chromaticity</span></a>.</p>
</section>

<!-- Maintain a fragment named "6AlphaRepresentation" to preserve incoming links to it -->
<section id="6AlphaRepresentation">
<h2>Alpha
representation</h2>

<p>In a PNG datastream transparency may be represented in one of
four ways, depending on the PNG image type (see 4.3.2: <a href=
"#3alphaSeparation"><span class="xref">Alpha
separation</span></a> and 4.3.5: <a href=
"#3alphaCompaction"><span class="xref">Alpha
compaction</span></a>).</p>

<!-- <ol start="1"> --><ol>
<li>Truecolour with alpha, greyscale with alpha: an alpha channel
is part of the image array.</li>

<li>Truecolour, greyscale: A <a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> chunk contains a single pixel value
distinguishing the fully transparent pixels from the fully opaque
pixels.</li>

<li>Indexed-colour: A <a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> chunk contains the alpha table that
associates an alpha sample with each palette entry.</li>

<li>Truecolour, greyscale, indexed-colour: there is no <a href=
"#trns-transparency"><span class="chunk">tRNS</span></a> chunk present and
all pixels are fully opaque.</li>
</ol>

<p>An alpha channel included in the image array has 8-bit or
16-bit samples, the same size as the other samples. The alpha
sample for each pixel is stored immediately following the
greyscale or RGB samples of the pixel. An alpha value of zero
represents full transparency, and a value of
2<sup>sampledepth</sup> - 1 represents full opacity. Intermediate
values indicate partially transparent pixels that can be
composited against a background image to yield the delivered
image.</p>

<p>The colour values in a pixel are not premultiplied by the
alpha value assigned to the pixel. This rule is sometimes called
"unassociated" or "non-premultiplied" alpha. (Another common
technique is to store sample values premultiplied by the alpha
value; in effect, such an image is already composited against a
black background. PNG does <strong>not</strong> use premultiplied alpha.
In consequence an image editor can take a PNG image and easily
change its transparency.) See 12.4: <a href=
"#alpha-channel-creation"><span class="xref">Alpha channel
creation</span></a> and 13.16: <a href=
"#alpha-channel-processing"><span class="xref">Alpha channel
processing</span></a>.</p>
</section>
</section>


<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "7Transformation" to preserve incoming links to it -->
<section id="7Transformation">
<h2>Encoding the PNG image as a PNG
datastream</h2>

<!-- Maintain a fragment named "7Integers-and-byte-order" to preserve incoming links to it -->
<section id="7Integers-and-byte-order">
<h2>Integers and byte
order</h2>

<p>All integers that require more than one byte shall be in
network byte order (as illustrated in <a href="#integer-representation-in-png"></a>
): the most significant byte
comes first, then the less significant bytes in descending order
of significance (MSB LSB for two-byte integers, MSB B2 B1 LSB for
four-byte integers). The highest bit (value 128) of a byte is
numbered bit 7; the lowest bit (value 1) is numbered bit 0.
Values are unsigned unless otherwise noted. Values explicitly
noted as signed are represented in two's complement notation.</p>

<p>PNG four-byte unsigned integers are limited to the range 0 to
2<sup>31</sup>-1 to accommodate languages that have difficulty
with unsigned four-byte values. Similarly PNG four-byte signed
integers are limited to the range -(2<sup>31</sup>-1) to
2<sup>31</sup>-1 to accommodate languages that have difficulty
with the value -2<sup>31</sup>.</p>

<figure id="integer-representation-in-png">
<!-- Maintain a fragment named "figure71" to preserve incoming links to it -->
<a name="figure71"></a>
<object height="310" width="810" data="figures/integer-representation-in-png.svg" type="image/svg+xml">
  <img height="310" width="810" src="png-figures/integer-representation-in-png.png" alt="Integer representation in PNG" />
</object>
<figcaption>Integer representation in PNG</figcaption>
</figure>

</section>

<!-- Maintain a fragment named "7Scanline" to preserve incoming links to it -->
<section id="7Scanline">
<h2>Scanlines</h2>

<p>A PNG image (or pass, see clause&#160;8: <a href=
"#interlacing-and-pass-extraction"><span class="xref">Interlacing and pass
extraction</span></a>) is a rectangular pixel array, with pixels
appearing left-to-right within each scanline, and scanlines
appearing top-to-bottom. The size of each pixel is determined by
the number of bits per pixel.</p>

<p>Pixels within a scanline are always packed into a sequence of
bytes with no wasted bits between pixels. Scanlines always begin
on byte boundaries. Permitted bit depths and colour types are
restricted so that in all cases the packing is simple and
efficient.</p>

<p>
In PNG images of colour type 0 (greyscale) each pixel is a single sample, which may have precision less than a byte (1, 2, or 4 bits). These samples are packed into bytes with the leftmost sample in the high-order bits of a byte followed by the other samples for the scanline.
</p>
<p>
In PNG images of colour type 3 (indexed-colour) each pixel is a single palette index. These indices are packed into bytes in the same way as the samples for colour type 0.</p>
<p>When there are multiple pixels per byte, some low-order bits
of the last byte of a scanline may go unused. The contents of
these unused bits are not specified.</p>

<p>PNG images that are not indexed-colour images may have sample
values with a bit depth of 16. Such sample values are in network
byte order (MSB first, LSB second). PNG permits multi-sample
pixels only with 8 and 16-bit samples, so multiple samples of a
single pixel are never packed into one byte.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "7Filtering" to preserve incoming links to it -->
<section id="7Filtering">
<h2>Filtering</h2>

<p>PNG allows the scanline data to be <strong>filtered</strong> before it
is compressed. Filtering can improve the compressibility of the
data. The filter step itself results in a sequence of bytes of
the same size as the incoming sequence, but in a different
representation, preceded by a filter type byte. Filtering does
not reduce the size of the actual scanline data. All PNG filters
are strictly lossless.</p>

<p>Different filter types can be used for different scanlines,
and the filter algorithm is specified for each scanline by a
filter type byte. The filter type byte is not considered part of
the image data, but it is included in the datastream sent to the
compression step. An intelligent encoder can switch filters from
one scanline to the next. The method for choosing which filter to
employ is left to the encoder.</p>

<p>See clause&#160;9: <a href="#filtering-2"><span class=
"xref">Filtering</span></a>.</p>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "8Interlace" to preserve incoming links to it -->
<section id="8Interlace">
<h2>Interlacing and pass
extraction</h2>

<!-- Maintain a fragment named "8InterlaceIntro" to preserve incoming links to it -->
<section class="introductory" id="8InterlaceIntro">
<p>Pass extraction (see <a href="#figure48"><span class=
"figref">figure 4.8</span></a>) splits a PNG image into a
sequence of reduced images (the interlaced PNG image) where the
first image defines a coarse view and subsequent images enhance
this coarse view until the last image completes the PNG image.
This allows progressive display of the interlaced PNG image by
the decoder and allows images to "fade in" when they are being
displayed on-the-fly. On average, interlacing slightly expands
the datastream size, but it can give the user a meaningful
display much more rapidly.</p>
</section>

<!-- Maintain a fragment named "8InterlaceMethods" to preserve incoming links to it -->
<section id="8InterlaceMethods">
<h2>Interlace methods</h2>

<p>Two interlace methods are defined in this International
Standard, methods 0 and 1. Other values of interlace method are
reserved for future standardization (see 4.9: <a href=
"#extension-and-registration"><span class="xref">Extension and
registration</span></a>).</p>

<p>With interlace method 0, the null method, pixels are extracted
sequentially from left to right, and scanlines sequentially from
top to bottom. The interlaced PNG image is a single reduced
image.</p>

<p>Interlace method 1, known as Adam7, defines seven distinct
passes over the image. Each pass transmits a subset of the pixels
in the reference image. The pass in which each pixel is
transmitted (numbered from 1 to 7) is defined by replicating the
following 8-by-8 pattern over the entire image, starting at the
upper left corner:</p>

<pre>
   1 6 4 6 2 6 4 6
   7 7 7 7 7 7 7 7
   5 6 5 6 5 6 5 6
   7 7 7 7 7 7 7 7
   3 6 4 6 3 6 4 6
   7 7 7 7 7 7 7 7
   5 6 5 6 5 6 5 6
   7 7 7 7 7 7 7 7
</pre>

<p><a href="#figure48"><span class="figref">Figure 4.8</span></a>
shows the seven passes of interlace method 1. Within each pass,
the selected pixels are transmitted left to right within a
scanline, and selected scanlines sequentially from top to bottom.
For example, pass 2 contains pixels 4, 12, 20, etc. of scanlines
0, 8, 16, etc. (where scanline 0, pixel 0 is the upper left
corner). The last pass contains all of scanlines 1, 3, 5, etc.
The transmission order is defined so that all the scanlines
transmitted in a pass will have the same number of pixels; this
is necessary for proper application of some of the filters. The
interlaced PNG image consists of a sequence of seven reduced
images. For example, if the PNG image is 16 by 16 pixels, then
the third pass will be a reduced image of two scanlines, each
containing four pixels (see <a href="#figure48"><span class=
"figref">figure 4.8</span></a>).</p>

<p>Scanlines that do not completely fill an integral number of
bytes are padded as defined in 7.2: <a href="#scanlines"><span
class="xref">Scanlines</span></a>.</p>

<p class="Note">NOTE If the reference image contains fewer than
five columns or fewer than five rows, some passes will be
empty.</p>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "9Filters" to preserve incoming links to it -->
<section id="9Filters">
<h2>Filtering</h2>

<!-- Maintain a fragment named "9FtIntro" to preserve incoming links to it -->
<section id="9FtIntro">
<h2>Filter methods and filter
types</h2>

<p>Filtering transforms the PNG image with the goal of
improving compression. PNG allows for a number of filter methods.
All the reduced
images in an interlaced image shall use a single filter method.
Only filter method 0
is defined by this specification. Other filter methods
are reserved for future standardization (see 4.9 <a href=
"#extension-and-registration"><span class="xref">Extension and
registration</span></a>).
Filter method 0 provides a set of five filter types,
and individual scanlines in each reduced image may use
different filter types.</p>

<p>PNG imposes no additional restriction on which filter types
can be applied to an interlaced PNG image. However, the filter
types are not equally effective on all types of data. See 12.8:
<a href="#filter-selection"><span class="xref">Filter
selection</span></a>.</p>

<p>Filtering transforms the byte sequence in a scanline to an
equal length sequence of bytes preceded by the filter type.
Filter type bytes are associated only with non-empty scanlines.
No filter type bytes are present in an empty pass. See 13.8: <a
href="#interlacing-and-progressive-display"><span class="xref">Interlacing and
progressive display</span></a>.</p>
</section>

<!-- Maintain a fragment named "9Filter-types" to preserve incoming links to it -->
<section id="9Filter-types">
<h2>Filter types for filter method
0</h2>

<p>Filters are applied to <strong>bytes</strong>, not to pixels,
regardless of the bit depth or colour type of the image. The
filters operate on the byte sequence formed by a scanline that
has been represented as described in 7.2: <a href=
"#scanlines"><span class="xref">Scanlines</span></a>. If the image
includes an alpha channel, the alpha data is filtered in the same
way as the image data.</p>

<p>Filters may use the original values of the following bytes to
generate the new byte value:</p>

<table class="Regular" summary=
"This table defines the variables usedin table 9.1">
<tr>
<td class="Regular"><tt>x</tt> </td>
<td class="Regular">the byte being filtered;</td>
</tr>

<tr>
<td class="Regular"><tt>a</tt> </td>
<td class="Regular">the byte corresponding to x in the pixel immediately before the pixel containing x (or the byte immediately before x, when the bit depth is less than 8);</td>
</tr>

<tr>
<td class="Regular"><tt>b</tt> </td>
<td class="Regular">the byte corresponding to x in the previous scanline;</td>
</tr>

<tr>
<td class="Regular"><tt>c</tt> </td>
<td class="Regular">the byte corresponding to b in the pixel immediately before the pixel containing b (or the byte immediately before b, when the bit depth is less than 8).</td>
</tr>
</table>

<p><a href="#paethpredictor-function"></a> shows the relative positions of the bytes <tt>x</tt>,
<tt>a</tt>, <tt>b</tt>,
and <tt>c</tt>.</p>

<p>PNG filter method 0 defines five basic filter types as listed
in <a href="#9-table91"><span class="tabref">Table
9.1</span></a>. <tt>Orig(y)</tt> denotes the original (unfiltered)
value of byte <tt>y</tt>. <tt>Filt(y)</tt> denotes the value
after a filter has been applied. <tt>Recon(y)</tt> denotes the
value after the corresponding reconstruction function has been
applied. The filter function for the Paeth type
<tt>PaethPredictor</tt> is defined below.</p>

<p>Filter method 0 specifies exactly this set of five filter
types and this shall not be extended.
This ensures that decoders need not decompress the data
to determine whether it contains unsupported filter types:
it is sufficient to check the filter method in <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a>.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<table class="Regular" summary=
"This table lists the filter types">
<caption><a name="9-table91"><b>Table 9.1 &mdash; Filter
types</b></a></caption>

<tr>
<th>Type</th>
<th>Name</th>
<th>Filter Function</th>
<th>Reconstruction Function</th>
</tr>

<tr>
<td class="Regular" align="center">0</td>
<td class="Regular">None</td>
<td class="Regular"><tt>Filt(x) = Orig(x)</tt> </td>
<td class="Regular"><tt>Recon(x) = Filt(x)</tt> </td>
</tr>

<tr>
<td class="Regular" align="center">1</td>
<td class="Regular">Sub</td>
<td class="Regular"><tt>Filt(x) = Orig(x) - Orig(a)</tt> </td>
<td class="Regular"><tt>Recon(x) = Filt(x) + Recon(a)</tt> </td>
</tr>

<tr>
<td class="Regular" align="center">2</td>
<td class="Regular">Up</td>
<td class="Regular"><tt>Filt(x) = Orig(x) - Orig(b)</tt> </td>
<td class="Regular"><tt>Recon(x) = Filt(x) + Recon(b)</tt> </td>
</tr>

<tr>
<td class="Regular" align="center">3</td>
<td class="Regular">Average</td>
<td class="Regular"><tt>Filt(x) = Orig(x) - floor((Orig(a) + Orig(b)) /
2)</tt> </td>
<td class="Regular"><tt>Recon(x) = Filt(x) + floor((Recon(a) + Recon(b)) /
2)</tt> </td>
</tr>

<tr>
<td class="Regular" align="center">4</td>
<td class="Regular">Paeth</td>
<td class="Regular"><tt>Filt(x) = Orig(x) - PaethPredictor(Orig(a),
Orig(b), Orig(c))</tt> </td>
<td class="Regular"><tt>Recon(x) = Filt(x) + PaethPredictor(Recon(a), Recon(b),
Recon(c))</tt> </td>
</tr>
</table>

<p>For all filters, the bytes "to the left of" the first pixel in
a scanline shall be treated as being zero. For filters that refer
to the prior scanline, the entire prior scanline and bytes "to
the left of" the first pixel in the prior scanline shall be
treated as being zeroes for the first scanline of a reduced
image.</p>

<p>To reverse the effect of a filter requires the decoded values
of the prior pixel on the same scanline, the pixel immediately
above the current pixel on the prior scanline, and the pixel just
to the left of the pixel above.</p>

<p>Unsigned arithmetic modulo 256 is used, so that both the
inputs and outputs fit into bytes. Filters are applied to each
byte regardless of bit depth. The sequence of <tt>Filt</tt>
values is transmitted as the filtered scanline.</p>
</section>

<!-- Maintain a fragment named "9Filter-type-3-Average" to preserve incoming links to it -->
<section id="9Filter-type-3-Average">
<h2>Filter type 3:
Average</h2>

<p>The sum <tt>Orig(a) + Orig(b)</tt> shall be performed without
overflow (using at least nine-bit arithmetic). <tt>floor()</tt>
indicates that the result of the division is rounded to the next
lower integer if fractional; in other words, it is an integer
division or right shift operation.</p>
</section>

<!-- Maintain a fragment named "9Filter-type-4-Paeth" to preserve incoming links to it -->
<section id="9Filter-type-4-Paeth">
<h2>Filter type 4:
Paeth</h2>

<p>The Paeth filter function computes a simple linear function of
the three neighbouring pixels (left, above, upper left), then
chooses as predictor the neighbouring pixel closest to the
computed value. The algorithm used in this specification
is an adaptation of the technique due to Alan W. Paeth
[[Paeth]].</p>

<p>The PaethPredictor function is defined in the code below. The
logic of the function and the locations of the bytes <tt>a</tt>,
<tt>b</tt>, <tt>c</tt>, and <tt>x</tt> are shown in <a href=
"#paethpredictor-function"></a>.
<tt>Pr</tt> is the predictor for byte <tt>x</tt>.</p>

<pre>
    p = a + b - c
    pa = abs(p - a)
    pb = abs(p - b)
    pc = abs(p - c)
    if pa &lt;= pb and pa &lt;= pc then Pr = a
    else if pb &lt;= pc then Pr = b
    else Pr = c
    return Pr
</pre>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<figure id="paethpredictor-function">
<!-- Maintain a fragment named "9-figure91" to preserve incoming links to it -->
<a name="9-figure91"></a>
<object height="360" width="640" data="figures/paethpredictor-function.svg" type="image/svg+xml">
  <img height="360" width="640" src="png-figures/paethpredictor-function.png" alt="The PaethPredictor
function" />
</object>
<figcaption>The PaethPredictor function</figcaption>
</figure>


<p>The calculations within the PaethPredictor function shall be
performed exactly, without overflow.</p>

<p><strong>The order in which the comparisons are performed is
critical and shall not be altered.</strong> The function tries to
establish in which of the three directions (vertical, horizontal,
or diagonal) the gradient of the image is smallest.</p>

<p>Exactly the same PaethPredictor function is used by both
encoder and decoder.</p>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "10Compression" to preserve incoming links to it -->
<section id="10Compression">
<h2>Compression</h2>

<!-- Maintain a fragment named "10CompressionCM0" to preserve incoming links to it -->
<section id="10CompressionCM0">
<h2>Compression method 0</h2>

<p>Only PNG compression method 0 is defined by this International
Standard. Other values of compression method are reserved for
future standardization (see 4.9: <a href=
"#extension-and-registration"><span class="xref">Extension and
registration</span></a>). PNG compression method 0 is
deflate/inflate compression with a sliding window
(which is an upper bound on the distances appearing in the
deflate stream) of at most
32768 bytes. Deflate compression is an LZ77 derivative
[[Ziv-Lempel]].</p>

<p>Deflate-compressed datastreams within PNG are stored in the
"zlib" format, which has the structure:</p>

<table class="Regular"  summary=
"This table gives the structure of the zlib format">
<tr>
<td class="Regular">zlib compression method/flags code</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Additional flags/check bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Compressed data blocks</td>
<td class="Regular">n bytes</td>
</tr>

<tr>
<td class="Regular">Check value</td>
<td class="Regular">4 bytes</td>
</tr>
</table>

<p>Further details on this format are given in the zlib
specification [[rfc1950]].</p>

<p>For PNG compression method 0, the zlib compression
method/flags code shall specify method code 8 (deflate
compression) and an LZ77 window size of not more than 32768
bytes. The zlib compression method number is not the same as the
PNG compression method number in the <a href=
"#ihdr-image-header"><span class="chunk">IHDR</span></a> chunk (see 11.2.2
<a href="#ihdr-image-header"><span class="xref"><span class=
"chunk">IHDR</span> Image header</span></a>). The additional
flags shall not specify a preset dictionary.</p>

<p>If the data to be compressed contain 16384 bytes or fewer, the
PNG encoder may set the window size by rounding up to a power of
2 (256 minimum). This decreases the memory required for both
encoding and decoding, without adversely affecting the
compression ratio.</p>

<p>The compressed data within the zlib datastream are stored as a
series of blocks, each of which can represent raw (uncompressed)
data, LZ77-compressed data encoded with fixed Huffman codes, or
LZ77-compressed data encoded with custom Huffman codes. A marker
bit in the final block identifies it as the last block, allowing
the decoder to recognize the end of the compressed datastream.
Further details on the compression algorithm and the encoding are
given in the deflate specification [[rfc1951]].</p>

<p>The check value stored at the end of the zlib datastream is
calculated on the uncompressed data represented by the
datastream. The algorithm used to calculate this is not the same
as the CRC calculation used for PNG chunk CRC field values. The
zlib check value is useful mainly as a cross-check that the
deflate and inflate algorithms are implemented correctly.
Verifying the individual PNG chunk CRCs provides confidence that
the PNG datastream has been transmitted undamaged.</p>
</section>

<!-- Maintain a fragment named "10CompressionFSL" to preserve incoming links to it -->
<section id="10CompressionFSL">
<h2>Compression of the sequence
of filtered scanlines</h2>

<p>The sequence of filtered scanlines is compressed and the
resulting data stream is split into <a href="#idat-image-data"><span
class="chunk">IDAT</span></a> chunks. The concatenation of the
contents of all the <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks makes up a zlib datastream. This
datastream decompresses to filtered image data.</p>

<p>It is important to emphasize that the boundaries between <a
href="#idat-image-data"><span class="chunk">IDAT</span></a> chunks are
arbitrary and can fall anywhere in the zlib datastream. There is
not necessarily any correlation between <a href="#idat-image-data"><span
class="chunk">IDAT</span></a> chunk boundaries and deflate block
boundaries or any other feature of the zlib data. For example, it
is entirely possible for the terminating zlib check value to be
split across <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks.</p>

<p>Similarly, there is no required correlation between the
structure of the image data (i.e., scanline boundaries) and
deflate block boundaries or <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunk boundaries. The complete filtered
PNG image is represented by a single zlib datastream that is
stored in a number of <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "9Filters" to preserve incoming links to it -->
<section id="10CompressionOtherUses">
<h2>Other uses of
compression</h2>

<p>PNG also uses compression method 0 in <a href="#itxt-international-textual-data"><span
class="chunk">iTXt</span></a>, <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a>, and <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a> chunks. Unlike the image data, such
datastreams are not split across chunks; each such chunk contains
an independent zlib datastream (see 10.1: <a href=
"#compression-method-0"><span class="xref">Compression method
0</span></a>).</p>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "11Chunks" to preserve incoming links to it -->
<section id="11Chunks">
<h2>Chunk specifications</h2>

<!-- Maintain a fragment named "11Introduction" to preserve incoming links to it -->
<section class="introductory" id="11Introduction">
<p>The PNG datastream consists of a PNG signature (see 5.2: <a
href="#png-signature"><span class="xref">PNG
signature</span></a>) followed by a sequence of chunks. Each
chunk has a chunk type which specifies its function. This clause
defines the PNG chunk types standardized in this International
Standard. The PNG datastream structure is defined in clause&#160;5: <a
href="#datastream-structure"><span class="xref">Datastream
structure</span></a>. This also defines the order in which chunks
may appear. For details specific to encoders see 12.11: <a href=
"#chunking-1"><span class="xref">Chunking</span></a>.
For details specific to decoders see 13.5: <a href=
"#chunking-2"><span class="xref">Chunking</span></a>.</p>
</section>

<!-- Maintain a fragment named "11Critical-chunks" to preserve incoming links to it -->
<section id="11Critical-chunks">
<h2>Critical chunks</h2>

<!-- Maintain a fragment named "11CcGen" to preserve incoming links to it -->
<section class="introductory" id="11CcGen">
<p>Critical chunks are those chunks that are absolutely required
in order to successfully decode a PNG image from a PNG
datastream. Extension chunks may be defined as critical chunks
(see clause&#160;14: <a href="#editors-and-extensions"><span class=
"xref">Editors and extensions</span></a>), though this practice
is strongly discouraged.</p>

<p>A valid PNG datastream shall begin with a PNG signature,
immediately followed by an <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> chunk, then one or more <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a> chunks, and shall
end with an <a href="#iend-image-trailer"><span class="chunk">IEND</span></a>
chunk. Only one <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> chunk and one <a href="#iend-image-trailer"><span
class="chunk">IEND</span></a> chunk are allowed in a PNG
datastream.</p>
</section>

<!-- Maintain a fragment named "11IHDR" to preserve incoming links to it -->
<section id="11IHDR">
<h2><span class="chunk">IHDR</span> Image
header</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
73 72 68 82
</pre>

<p>The <span class="chunk">IHDR</span> chunk shall be the first
chunk in the PNG datastream. It contains:</p>

<table class="Regular"  summary=
"This table defines the IHDR chunk">
<tr>
<td class="Regular">Width</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Height</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Bit depth</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Colour type</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Compression method</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Filter method</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Interlace method</td>
<td class="Regular">1 byte</td>
</tr>
</table>

<p>Width and height give the image dimensions in pixels. They are
PNG four-byte unsigned integers. Zero is an invalid
value.</p>

<p>Bit depth is a single-byte integer giving the number of bits
per sample or per palette index (not per pixel). Valid values are
1, 2, 4, 8, and 16, although not all values are allowed for all
colour types. See 6.1: <a href="#colour-types-and-values"><span class=
"xref">Colour types and values</span></a>.</p>

<p>Colour type is a single-byte integer that defines the PNG
image type. Valid values are 0, 2, 3, 4, and 6.</p>

<p>Bit depth restrictions for each colour type are imposed to
simplify implementations and to prohibit combinations that do not
compress well. The allowed combinations are defined in <a href=
"#table111"><span class="tabref">Table 11.1</span></a>.</p>

<table class="Regular" summary=
"This table defines the colour types">
<caption><a name="table111"><b>Table 11.1 &mdash; Allowed
combinations of colour type and bit depth</b></a></caption>

<tr>
<th>PNG image type</th>
<th>Colour type</th>
<th>Allowed bit depths</th>
<th>Interpretation</th>
</tr>

<tr>
<td class="Regular">Greyscale</td>
<td class="Regular" align="center">0</td>
<td class="Regular">1, 2, 4, 8, 16</td>
<td class="Regular">Each pixel is a greyscale sample</td>
</tr>

<tr>
<td class="Regular">Truecolour</td>
<td class="Regular" align="center">2</td>
<td class="Regular">8, 16</td>
<td class="Regular">Each pixel is an R,G,B triple</td>
</tr>

<tr>
<td class="Regular">Indexed-colour</td>
<td class="Regular" align="center">3</td>
<td class="Regular">1, 2, 4, 8</td>
<td class="Regular">Each pixel is a palette index; a <a href="#plte-palette"><span
class="chunk">PLTE</span></a> chunk shall appear.</td>
</tr>

<tr>
<td class="Regular">Greyscale with alpha</td>
<td class="Regular" align="center">4</td>
<td class="Regular">8, 16</td>
<td class="Regular">Each pixel is a greyscale sample followed by an alpha
sample.</td>
</tr>

<tr>
<td class="Regular">Truecolour with alpha</td>
<td class="Regular" align="center">6</td>
<td class="Regular">8, 16</td>
<td class="Regular">Each pixel is an R,G,B triple followed by an alpha
sample.</td>
</tr>
</table>

<p>The sample depth is the same as the bit depth except in the
case of indexed-colour PNG images (colour type 3), in which the
sample depth is always 8 bits (see 4.4: <a href=
"#png-image"><span class="xref">PNG image</span></a>).</p>

<p>Compression method is a single-byte integer that indicates the
method used to compress the image data. Only compression method 0
(deflate/inflate compression with a sliding window of at most
32768 bytes) is defined in this specification. All
conforming PNG images shall be compressed with this scheme.</p>

<p>Filter method is a single-byte integer that indicates the
preprocessing method applied to the image data before
compression. Only filter method 0 (adaptive filtering with five
basic filter types) is defined in this specification.
See clause&#160;9: <a href="#filtering-2"><span class=
"xref">Filtering</span></a> for details.</p>

<p>Interlace method is a single-byte integer that indicates the
transmission order of the image data. Two values are defined in
this specification: 0 (no interlace) or 1 (Adam7
interlace). See clause&#160;8: <a href="#interlacing-and-pass-extraction"><span class=
"xref">Interlacing and pass extraction</span></a> for
details.</p>
</section>

<!-- Maintain a fragment named "11PLTE" to preserve incoming links to it -->
<section id="11PLTE">
<h2><span class="chunk">PLTE</span>
Palette</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
80 76 84 69
</pre>

<p>The <span class="chunk">PLTE</span> chunk contains from 1 to
256 palette entries, each a three-byte series of the form:</p>

<table class="Regular" summary=
"This table defines the PLTE palette table entries">
<tr>
<td class="Regular">Red</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Green</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Blue</td>
<td class="Regular">1 byte</td>
</tr>
</table>

<p>The number of entries is determined from the chunk length. A
chunk length not divisible by 3 is an error.</p>

<p>This chunk shall appear for colour type 3, and may appear for
colour types 2 and 6; it shall not appear for colour types 0 and
4. There shall not be more than one <span class=
"chunk">PLTE</span> chunk.</p>

<p>For colour type 3 (indexed-colour), the <span class=
"chunk">PLTE</span> chunk is required. The first entry in <span
class="chunk">PLTE</span> is referenced by pixel value 0, the
second by pixel value 1, etc. The number of palette entries shall
not exceed the range that can be represented in the image bit
depth (for example, 2<sup>4</sup> = 16 for a bit depth of 4). It
is permissible to have fewer entries than the bit depth would
allow. In that case, any out-of-range pixel value found in the
image data is an error.</p>

<p>For colour types 2 and 6 (truecolour and truecolour with
alpha), the <span class="chunk">PLTE</span> chunk is optional. If
present, it provides a suggested set of colours (from 1 to 256)
to which the truecolour image can be quantized if it cannot be
displayed directly. It is, however, recommended that the <a href=
"#splt-suggested-palette"><span class="chunk">sPLT</span></a> chunk be used for
this purpose, rather than the <span class="chunk">PLTE</span>
chunk. If neither <span class="chunk">PLTE</span> nor <a href=
"#splt-suggested-palette"><span class="chunk">sPLT</span></a> chunks are present
and the image cannot be displayed directly, quantization has to
be done by the viewing system. However, it is often preferable
for the selection of colours to be done once by the PNG encoder.
(See 12.6: <a href="#suggested-palettes"><span class=
"xref">Suggested palettes</span></a>.)</p>

<p>Note that the palette uses 8 bits (1 byte) per sample
regardless of the image bit depth. In particular,
the palette is 8 bits deep even when it is a suggested
quantization of a 16-bit truecolour image.</p>

<p>There is no requirement that the palette entries all be used
by the image, nor that they all be different.</p>
</section>

<!-- Maintain a fragment named "11IDAT" to preserve incoming links to it -->
<section id="11IDAT">
<h2><span class="chunk">IDAT</span> Image
data</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
73 68 65 84
</pre>

<p>The <span class="chunk">IDAT</span> chunk contains the actual
image data which is the output stream of the compression
algorithm. See clause&#160;9: <a href="#filtering-2"><span class=
"xref">Filtering</span></a> and clause&#160;10: <a href=
"#compression-1"><span class="xref">Compression</span></a> for
details.</p>

<p>There may be multiple <span class="chunk">IDAT</span> chunks;
if so, they shall appear consecutively with no other intervening
chunks. The compressed datastream is then the concatenation of
the contents of the data fields of all the <span class=
"chunk">IDAT</span> chunks.</p>
</section>

<!-- Maintain a fragment named "11IEND" to preserve incoming links to it -->
<section id="11IEND">
<h2><span class="chunk">IEND</span> Image
trailer</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
73 69 78 68
</pre>

<p>The <span class="chunk">IEND</span> chunk marks the end of the
PNG datastream. The chunk's data field is empty.</p>
</section>
</section>

<!-- Maintain a fragment named "11Ancillary-chunks" to preserve incoming links to it -->
<section id="11Ancillary-chunks">
<h2><a name="ancillary-chunks">Ancillary chunks</a></h2>

<!-- Maintain a fragment named "11AcGen" to preserve incoming links to it -->
<section class="introductory" id="11AcGen">
<p>The ancillary chunks defined in this specification
are listed in the order in 4.7.2: <a href=
"#chunk-types"><span class="xref">Chunk
types</span></a>. This is not the order in which they appear in a
PNG datastream. Ancillary chunks may be ignored by a decoder. For
each ancillary chunk, the actions described are under the
assumption that the decoder is not ignoring the chunk.</p>
</section>

<!-- Maintain a fragment named "11transinfo" to preserve incoming links to it -->
<section id="11transinfo">
<h2>Transparency
information</h2>

<!-- Maintain a fragment named "11tRNS" to preserve incoming links to it -->
<section id="11tRNS">
<h2><span class="chunk">tRNS</span>
Transparency</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
116 82 78 83
</pre>

<p>The <span class="chunk">tRNS</span> chunk specifies either
alpha values that are associated with palette entries (for
indexed-colour images) or a single transparent colour (for
greyscale and truecolour images). The <span class=
"chunk">tRNS</span> chunk contains:
<!-- ************Page Break******************* -->
</p>

<!-- ************Page Break******************* -->
<table class="Regular" summary=
"This table defines the tRNS chunk">
<tr>
<th colspan="2">Colour type 0</th>
</tr>

<tr>
<td class="Regular">Grey sample value</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<th colspan="2">Colour type 2</th>
</tr>

<tr>
<td class="Regular">Red sample value</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
  <td class="Regular">Green sample value</td>
  <td class="Regular">2 bytes</td>
</tr>

<tr>
<td class="Regular">Blue sample value</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<th colspan="2">Colour type 3</th>
</tr>

<tr>
<td class="Regular">Alpha for palette index 0</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Alpha for palette index 1</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">...etc...</td>
<td class="Regular">1 byte</td>
</tr>
</table>

<p>For colour type 3 (indexed-colour), the <span class=
"chunk">tRNS</span> chunk contains a series of one-byte alpha
values, corresponding to entries in the <a href="#plte-palette"><span
class="chunk">PLTE</span></a> chunk. Each entry indicates that
pixels of the corresponding palette index shall be treated as
having the specified alpha value. Alpha values have the same
interpretation as in an 8-bit full alpha channel: 0 is fully
transparent, 255 is fully opaque, regardless of image bit depth.
The <span class="chunk">tRNS</span> chunk shall not contain more
alpha values than there are palette entries, but a <span class=
"chunk">tRNS</span> chunk may contain fewer values than there are
palette entries. In this case, the alpha value for all remaining
palette entries is assumed to be 255. In the common case in which
only palette index 0 need be made transparent, only a one-byte
<span class="chunk">tRNS</span> chunk is needed, and when all
palette indices are opaque, the <span class="chunk">tRNS</span>
chunk may be omitted.</p>

<p>For colour types 0 or 2, two bytes per sample are used
regardless of the image bit depth (see 7.1: <a href=
"#integers-and-byte-order"><span class="xref">Integers and byte
order</span></a>). Pixels of the specified grey sample value or
RGB sample values are treated as transparent (equivalent to alpha
value 0); all other pixels are to be treated as fully opaque
(alpha value 2<sup>bitdepth</sup>-1). If the image bit depth is
less than 16, the least significant bits are used and the others
are 0.</p>

<p>A <span class="chunk">tRNS</span> chunk shall not appear for
colour types 4 and 6, since a full alpha channel is already
present in those cases.</p>

<p class="Note">NOTE For 16-bit greyscale or truecolour data,
only pixels matching the entire 16-bit values in <span class=
"chunk">tRNS</span> chunks are transparent. Decoders have to
postpone any sample depth rescaling until after the pixels have
been tested for transparency.</p>
</section>
</section>

<!-- Maintain a fragment named "11addnlcolinfo" to preserve incoming links to it -->
<section id="11addnlcolinfo">
<h2>Colour space
information</h2>

<!-- Maintain a fragment named "11cHRM" to preserve incoming links to it -->
<section id="11cHRM">
<h2><span class="chunk">cHRM</span>
Primary chromaticities and white point</h2>

<p>The four decimal values below correspond to the four-byte cHRM chunk type field:</p>

<pre>
99 72 82 77
</pre>

<p>The <span class="chunk">cHRM</span> chunk may be used to
specify the 1931 CIE <i>x,y</i> chromaticities of the red,
green, and blue display primaries used in the image, and the referenced
white point. See Annex C: <a href="#C-GammaAppendix"><span class=
"xref">Gamma and chromaticity</span></a> for more information.
The <a href="#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> and <a
href="#srgb-standard-rgb-colour-space"><span class="chunk">sRGB</span></a> chunks provide
more sophisticated support for colour management and control.</p>

<p>The <span class="chunk">cHRM</span> chunk contains:</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<table class="Regular" summary=
"This table defines the cHRM chunk">
<tr>
<td class="Regular">White point x</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">White point y</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Red x</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Red y</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Green x</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Green y</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Blue x</td>
<td class="Regular">4 bytes</td>
</tr>

<tr>
<td class="Regular">Blue y</td>
<td class="Regular">4 bytes</td>
</tr>
</table>

<p>Each value is encoded as a four-byte PNG unsigned integer,
representing the <i>x</i> or <i>y</i> value times 100000.</p>

<p>EXAMPLE A value of 0.3127 would be stored as the integer
31270.</p>

<p>The <span class="chunk">cHRM</span> chunk is allowed in all
PNG datastreams, although it is of little value for greyscale
images.</p>

<p>An <a href="#srgb-standard-rgb-colour-space"><span class="chunk">sRGB</span></a> chunk
or <a href="#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> chunk,
when present and recognized, overrides the <span class=
"chunk">cHRM</span> chunk.</p>
</section>

<!-- Maintain a fragment named "11gAMA" to preserve incoming links to it -->
<section id="11gAMA">
<h2><span class="chunk">gAMA</span>
Image gamma</h2>

<p>The four decimal values below correspond to the four-byte gAMA chunk type field:</p>

<pre>
103 65 77 65
</pre>

<p>The <span class="chunk">gAMA</span> chunk specifies the
relationship between the image samples and the desired display
output intensity. Gamma is defined in <a href=
"#3gamma">gamma</a>.</p>

<p>In fact specifying the desired display output intensity is
insufficient. It is also necessary to specify the viewing
conditions under which the output is desired. For <span class=
"chunk">gAMA</span> these are the reference viewing conditions of
the sRGB specification [[SRGB]].
Adjustment for different viewing conditions is normally handled
by a Colour Management System. If the adjustment is not
performed, the error is usually small. Applications desiring high
colour fidelity may wish to use an <a href="#srgb-standard-rgb-colour-space"><span class=
"chunk">sRGB</span></a> chunk or <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a> chunk.</p>

<p>The <span class="chunk">gAMA</span> chunk contains:</p>

<table class="Regular" summary=
"This table defines the gAMA chunk">
<tr>
<td class="Regular">Image gamma</td>
<td class="Regular">4 bytes</td>
</tr>
</table>

<p>The value is encoded as a four-byte PNG unsigned integer,
representing gamma times 100000.</p>

<p>EXAMPLE A gamma of 1/2.2 would be stored as the integer
45455.</p>

<p>See 12.2: <a href="#encoder-gamma-handling"><span class=
"xref">Encoder gamma handling</span></a> and 13.13: <a href=
"#decoder-gamma-handling"><span class="xref">Decoder gamma
handling</span></a> for more information.</p>

<p>An <a href="#srgb-standard-colour-space"><span class="chunk">sRGB</span></a> chunk
or <a href="#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> chunk,
when present and recognized, overrides the <span class=
"chunk">gAMA</span> chunk.</p>
</section>

<!-- Maintain a fragment named "11iCCP" to preserve incoming links to it -->
<section id="11iCCP">
<h2><span class="chunk">iCCP</span>
Embedded ICC profile</h2>

<p>The four decimal values below correspond to the four-byte iCCP chunk type field:</p>

<pre>
105 67 67 80
</pre>

<p>The <span class="chunk">iCCP</span> chunk contains:</p>

<table class="Regular" summary=
"This table defines the iCCP chunk">
<tr>
<td class="Regular">Profile name</td>
<td class="Regular">1-79 bytes (character string)</td>
</tr>

<tr>
<td class="Regular">Null separator</td>
<td class="Regular">1 byte (null character)</td>
</tr>

<tr>
<td class="Regular">Compression method</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Compressed profile</td>
<td class="Regular">n bytes</td>
</tr>
</table>

<p>The profile name may be any convenient name for referring to
the profile. It is case-sensitive. Profile names shall contain
only printable Latin-1 characters and spaces (only character
codes 32-126 and 161-255 decimal are allowed). Leading, trailing,
and consecutive spaces are not permitted. The only compression
method defined in this specification is method 0 (zlib
datastream with deflate compression, see 10.3: <a href=
'#other-uses-of-compression'><span class="xref">Other uses of
compression</span></a>). The compression method entry is followed
by a compressed profile that makes up the remainder of the chunk.
Decompression of this datastream yields the embedded ICC
profile.</p>

<p>If the <span class="chunk">iCCP</span> chunk is present, the
image samples conform to the colour space represented by the
embedded ICC profile as defined by the International Color
Consortium [[ICC]][[ISO 15076-1]] or [[ICC-2]][[ISO 20677-1]].
The colour space of the ICC profile
shall be an RGB colour space for colour images (PNG colour types
2, 3, and 6), or a greyscale colour space for greyscale images
(PNG colour types 0 and 4). A PNG encoder that writes the <span
class="chunk">iCCP</span> chunk is encouraged to also write <a
href="#gama-image-gamma"><span class="chunk">gAMA</span></a> and <a href=
"#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> chunks that
approximate the ICC profile, to provide compatibility with
applications that do not use the <span class="chunk">iCCP</span>
chunk. When the <span class="chunk">iCCP</span> chunk is present,
PNG decoders that recognize it and are capable of colour
management
shall ignore the <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> and <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunks and use the <span class=
"chunk">iCCP</span> chunk instead and interpret it according to
[[ICC]] or [[ICC-2]].
PNG decoders that are used in an environment that is incapable of
full-fledged colour management should use the <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> and <a href=
"#chrm-primary-chromaticitieis-and-white-point"><span class="chunk">cHRM</span></a> chunks if
present.</p>

<p>A PNG datastream should contain at most one embedded profile,
whether specified explicitly with an <span class=
"chunk">iCCP</span> chunk or implicitly with an <a href=
"#srgb-standard-colour-space"><span class="chunk">sRGB</span></a> chunk.</p>
</section>

<!-- Maintain a fragment named "11sBIT" to preserve incoming links to it -->
<section id="11sBIT">
<h2><span class="chunk">sBIT</span>
Significant bits</h2>


<p>The four decimal values below correspond to the four-byte sBIT chunk type field:</p>

<pre>
115 66 73 84
</pre>

<p>To simplify decoders, PNG specifies that only certain sample
depths may be used, and further specifies that sample values
should be scaled to the full range of possible values at the
sample depth. The <a href="#sbit-significant-bits"><span class=
"chunk">sBIT</span></a> chunk defines the original number of
significant bits (which can be less than or equal to the sample
depth). This allows PNG decoders to recover the original data
losslessly even if the data had a sample depth not directly
supported by PNG.</p>

<p>The <span class="chunk">sBIT</span> chunk contains:</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<table class="Regular" summary=
"This table defines the sBIT chunk">
<tr>
<th colspan="2">Colour type 0</th>
</tr>

<tr>
<td class="Regular">significant greyscale bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<th colspan="2">Colour types 2 and 3</th>
</tr>

<tr>
<td class="Regular">significant red bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">significant green bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">significant blue bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<th colspan="2">Colour type 4</th>
</tr>

<tr>
<td class="Regular">significant greyscale bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">significant alpha bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<th colspan="2">Colour type 6</th>
</tr>

<tr>
<td class="Regular">significant red bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">significant green bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">significant blue bits</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">significant alpha bits</td>
<td class="Regular">1 byte</td>
</tr>
</table>

<p>Each depth specified in <span class="chunk">sBIT</span> shall
be greater than zero and less than or equal to the sample depth
(which is 8 for indexed-colour images, and the bit depth given in
<a href="#ihdr-image-header"><span class="chunk">IHDR</span></a> for other
colour types).
Note that <span class="chunk">sBIT</span> does not provide a sample depth
for the alpha channel that is implied by a
<a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> chunk; in that case, all of the sample bits of
the alpha channel are to be treated as significant. If the <span
class="chunk">sBIT</span> chunk is not present, then all of the
sample bits of all channels are to be treated as significant.</p>
</section>

<!-- Maintain a fragment named "11sRGB" to preserve incoming links to it -->
<section id="11sRGB">
<h2><a name="srgb-standard-colour-space"><span class="chunk">sRGB</span>
Standard RGB colour space</a></h2>

<p>The four decimal values below correspond to the four-byte sRGB chunk type field:</p>

<pre>
115 82 71 66
</pre>

<p>If the <span class="chunk">sRGB</span> chunk is present, the
image samples conform to the sRGB colour space [[SRGB]]
and should be displayed using the specified
rendering intent defined by the International Color Consortium
[[ICC]] or [[ICC-2]].</p>

<p>The <span class="chunk">sRGB</span> chunk contains:</p>

<table class="Regular" summary=
"This table defines the sRGB chunk">
<tr>
<td class="Regular">Rendering intent</td>
<td class="Regular">1 byte</td>
</tr>
</table>

<p>The following values are defined for rendering intent:</p>

<table class="Regular" summary=
"This table defines the values of rendering intent in the sRGB chunk">
<tr>
<td class="Regular">0</td>
<td class="Regular">Perceptual</td>
<td class="Regular">for images preferring good adaptation to the output device
gamut at the expense of colorimetric accuracy, such as
photographs.</td>
</tr>

<tr>
<td class="Regular">1</td>
<td class="Regular">Relative colorimetric</td>
<td class="Regular">for images requiring colour appearance matching (relative to
the output device white point), such as logos.</td>
</tr>

<tr>
<td class="Regular">2</td>
<td class="Regular">Saturation</td>
<td class="Regular">for images preferring preservation of saturation at the
expense of hue and lightness, such as charts and graphs.</td>
</tr>

<tr>
<td class="Regular">3</td>
<td class="Regular">Absolute colorimetric</td>
<td class="Regular">for images requiring preservation of absolute colorimetry,
such as previews of images destined for a different output device
(proofs).</td>
</tr>
</table>

<p>It is recommended that a PNG encoder that writes the <span
class="chunk">sRGB</span> chunk also write a <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> chunk (and
optionally a <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk) for compatibility with decoders
that do not use the <span class="chunk">sRGB</span> chunk. Only
the following values shall be used.</p>

<table class="Regular" summary=
"This table defines the gAMA and cHRM values for sRGB">
<tr>
<th colspan="2"><a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> </th>
</tr>

<tr>
<td class="Regular">Gamma</td>
<td class="Regular">45455</td>
</tr>

<tr>
<th colspan="2"><a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> </th>
</tr>

<tr>
<td class="Regular">White point x</td>
<td class="Regular">31270</td>
</tr>

<tr>
<td class="Regular">White point y</td>
<td class="Regular">32900</td>
</tr>

<tr>
<td class="Regular">Red x</td>
<td class="Regular">64000</td>
</tr>

<tr>
<td class="Regular">Red y</td>
<td class="Regular">33000</td>
</tr>

<tr>
<td class="Regular">Green x</td>
<td class="Regular">30000</td>
</tr>

<tr>
<td class="Regular">Green y</td>
<td class="Regular">60000</td>
</tr>

<tr>
<td class="Regular">Blue x</td>
<td class="Regular">15000</td>
</tr>

<tr>
<td class="Regular">Blue y</td>
<td class="Regular">6000</td>
</tr>
</table>

<p>When the <span class="chunk">sRGB</span> chunk is present, it
is recommended that decoders that recognize it and are capable of
colour management
ignore the <a href="#gama-image-gamma"><span
class="chunk">gAMA</span></a> and <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunks and use the <span class=
"chunk">sRGB</span> chunk instead. Decoders that recognize the
<span class="chunk">sRGB</span> chunk but are not capable of
colour management
are recommended to ignore the <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> and <a href=
"#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> chunks, and use the
values given above as if they had appeared in <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> and <a href=
"#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> chunks.</p>

<p>It is recommended that the <span class="chunk">sRGB</span> and
<a href="#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> chunks do
not both appear in a PNG datastream.</p>
</section>

<!-- Maintain a fragment named "11cICP" to preserve incoming links to it -->
<section id="11cICP">
<h2><span class="chunk">cICP</span>
Coding-independent code points for video signal type identification</h2>

<p>The four decimal values below correspond to the four-byte cICP chunk type field:</p>

<pre>
99 73 67 80
</pre>

<p>If the <span class="chunk">cICP</span> chunk is present, the
  image samples have a specifically defined colour space, transfer function, and signal
  range that should be displayed using the specified rendering intent defined in
  [[ITU-T H.273]].
</p>

<p>The cICP chunk contains:</p>

<table class="Regular" summary=
"This table defines the cICP chunk">
<tr>
<td class="Regular">Colour Primaries</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<td class="Regular">Transfer Function</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<td class="Regular">Matrix Coefficients</td>
<td class="Regular">2 bytes</td>
</tr>


<tr>
<td class="Regular">Full Range Flag</td>
<td class="Regular">1 byte</td>
</tr>

</table>


<p>Coding-Independent Code Points are defined in [[ITU-T H.273]] and
  are typically embedded in video content and streams to define an explicit
  video rendering. The most common renderings for video imagery are defined in
  [[ITU-R BT.709]] and
  and [[ITU-R BT.2100]].</p>

  <p>The cICP chunk contains four decimal values corresponding to
  the colour primaries, transfer function, matrix coefficients and video signal
  range flag for the source imagery. </p>

  <p>Note: In Coding-Independent Code Points
    [[ITU-T H.273]], the
    third video coding point defines matrix coefficients which are used to describe
    conversions from other colour representations to RGB. PNG image samples are
    explicitly RGB, so the matrix coefficients value must be set to "0" which is
    labeled in [[ITU-T H.273]]
    as "RGB Identity". With PNG, decoders will always assume a matrix coefficient
    value of "0" but this value will remain in PNG for forward compatibility.</p>


<table class="Regular" summary=
"This table defines the values in the cICP chunk that allow for an accurate rendering
of source content with a video rendering intent">
<tr>
<td class="Regular">0</td>
<td class="Regular">Colour Primaries</td>
<td class="Regular">Identifies the colour primaries of the source picture as
  defined in [[ITU-T H.273]]</td>
</tr>

<tr>
<td class="Regular">1</td>
<td class="Regular">Transfer Characteristics</td>
<td class="Regular">Identifies the reference opto-electronic transfer
characteristic function or inverse reference electro-optical transfer
characteristic function as defined in [[ITU-T H.273]]</td>
</tr>

<tr>
<td class="Regular">2</td>
<td class="Regular">Matrix Coefficients</td>

<td class="Regular">Identifies the matrix coefficients used in deriving luma and
chroma signals from the green, blue and red as defined in [[ITU-T H.273]]</td>.
As noted earlier, since PNG is explicitly RGB, this value must always be set to
"0" which is labeled as "RGB Identity" in [[ITU-T H.273]].

</td>
</tr>

<tr>
<td class="Regular">3</td>
<td class="Regular">Full Range Flag</td>
<td class="Regular">Identifies a Full-Range scaling when this value is "1" as defined in
  [[ITU-T H.273]].</td>
Currently, PNG is "RGB ONLY" and typically lossless and therefore a value of "1"
is the default to indicate the the use of full-range signal scaling. There are
some use-cases where levels below or above nominal signal level (0 or 100%)
should be preserved, and therefore the signal range would be defined as "narrow
range" which is typically used in YC<sub>B</sub>C<sub>R</sub> video imagery. For
"narrow range" the Full-Range Flag would be set to "0". In the future, if PNG is
updated to include the YC<sub>B</sub>C<sub>R</sub> colour representation,
narrow-range signal scaling would be the default.  In the future, if PNG is
updated to include IC<sub>T</sub>C<sub>P</sub> the full-range flag would be set
to a value of "1" since it uses the PQ transfer function and therefore doesn't
benefit from the existence of sub-blacks or super-whites.
</td>
</tr>


</table>
<p>The cICP chunk must come before the IDAT chunk.</p>

<p>When the cICP chunk is present, PNG decoders that recognize it shall ignore
the following chunks:</p>
<ul>
  <li>iCCP</li>
  <li>gAMA </li>
  <li>cHRM </li>
  <li>sRGB </li>
</ul>


<table class="Regular" summary=
"The table below provides an example of the COLPRIMS, TRANSFC, MATCOEFFS, VIDFRNG
values for cICP">

<p>Below is an example for the use of the cICP:</p>

<tr>
<th colspan="2"><a href="#11COLPRIMS"><span class=
"chunk">COLPRIMS</span></a> </th>
</tr>

<tr>
<td class="Regular">COLPRIMS</td>
<td class="Regular">9</td>
</tr>

<tr>
<th colspan="2"><a href="#11TRANSFC"><span class=
"chunk">TRANSFC</span></a> </th>
</tr>

<tr>
<td class="Regular">TRANSFC</td>
<td class="Regular">16</td>
</tr>

<tr>
<th colspan="2"><a href="#11MATCOEFFS"><span class=
"chunk">MATCOEFFS</span></a> </th>
</tr>

<tr>
<td class="Regular">MATCOEFFS</td>
<td class="Regular">0</td>
</tr>

<tr>
<th colspan="2"><a href="#11VIDFRNG"><span class=
"chunk">TRANSFC</span></a> </th>
</tr>

<tr>
<td class="Regular">VIDFRNG</td>
<td class="Regular">1</td>
</tr>

</table>



<p>Here is an example of source content that uses the BT.2100 colour primaries,
with the PQ transfer function, Matrix Coefficients (using RGB Identity)and Full-Range signal scaling</p>

<pre>
9 16 0 1
</pre>

<p>Here is an example of source content that uses the BT.2100 colour primaries,
with the HLG transfer function, Matrix Coefficients (using RGB Identity)and Full-Range signal scaling</p>

<pre>
9 18 0 1
</pre>

<p>Here is an example of source content that uses BT.709 colour primaries,
with the BT.709 transfer function, Matrix Coefficients (using RGB Identity)and Full-Range signal scaling</p>

<pre>
1 1 0 1
</pre>


<p>When the <span class="chunk">cICP</span> chunk is used, a
decoder should be capable of producing the proper rendering intent as described in
[[ITU-T H.273]] and
it's associated recommendations.</p>
</section>
</section>

<!-- Maintain a fragment named "11textinfo" to preserve incoming links to it -->
<section id="11textinfo">
<h2>Textual information</h2>

<!-- Maintain a fragment named "11textIntro" to preserve incoming links to it -->
<section class="introductory" id="11textIntro">
<p>PNG provides the <a href="#text-textual-data"><span class=
"chunk">tEXt</span></a>, <a href="#itxt-international-textual-data"><span class=
"chunk">iTXt</span></a>, and <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a> chunks for storing text strings
associated with the image, such as an image description or
copyright notice. Keywords are used to indicate what each text
string represents. Any number of such text chunks may appear, and
more than one with the same keyword is permitted.</p>
</section>

<!-- Maintain a fragment named "11keywords" to preserve incoming links to it -->
<section id="11keywords">
<h2>Keywords and text
strings</h2>

<p>The following keywords are predefined and should be used where
appropriate.</p>

<table class="Regular" summary=
"This table defines the keywords defined for tEXt, iTXt and zTXt chunks">
<tr>
<td class="Regular">Title</td>
<td class="Regular">Short (one line) title or caption for image</td>
</tr>

<tr>
<td class="Regular">Author</td>
<td class="Regular">Name of image's creator</td>
</tr>

<tr>
<td class="Regular">Description</td>
<td class="Regular">Description of image (possibly long)</td>
</tr>

<tr>
<td class="Regular">Copyright</td>
<td class="Regular">Copyright notice</td>
</tr>

<tr>
<td class="Regular">Creation Time</td>
<td class="Regular">Time of original image creation</td>
</tr>

<tr>
<td class="Regular">Software</td>
<td class="Regular">Software used to create the image</td>
</tr>

<tr>
<td class="Regular">Disclaimer</td>
<td class="Regular">Legal disclaimer</td>
</tr>

<tr>
<td class="Regular">Warning</td>
<td class="Regular">Warning of nature of content</td>
</tr>

<tr>
<td class="Regular">Source</td>
<td class="Regular">Device used to create the image</td>
</tr>

<tr>
<td class="Regular">Comment</td>
<td class="Regular">Miscellaneous comment</td>
</tr>

<tr>
  <td class="Regular">XML:com.adobe.xmp</td>
  <td class="Regular">Extensible Metadata Platform (XMP) information,
    formatted as required by the XMP specification [[XMP]].
    The use of <span class="chunk">iTXt</span>,
    with Compression Flag set to 0,
    and both Language Tag and
    Translated Keyword set to the null string,
    are recommended
    for XMP compliance.</td>
</tr>
</table>

<p>Other keywords may be defined for other purposes. Keywords of
general interest can be registered with the PNG Registration
Authority (see 4.9 <a href="#extension-and-registration"><span class=
"xref">Extension and registration</span></a>). It is also
permitted to use private unregistered keywords. (Private keywords
should be reasonably self-explanatory, in order to minimize the
chance that the same keyword is used for incompatible purposes by
different people.)</p>

<p>Keywords shall contain only printable Latin-1 [[ISO 8859-1]]
characters and spaces; that is, only character codes 32-126 and
161-255 decimal are allowed. To reduce the chances for human
misreading of a keyword, leading spaces, trailing spaces,
and consecutive spaces are not permitted in keywords, nor is the
non-breaking space (code 160) since it is visually
indistinguishable from an ordinary space.</p>

<p>Keywords shall be spelled exactly as registered, so that
decoders can use simple literal comparisons when looking for
particular keywords. In particular, keywords are considered
case-sensitive. Keywords are restricted to 1 to 79 bytes in
length.</p>

<p>For the Creation Time keyword, the date format defined in
section&#160;5.2.14 of RFC 1123 is suggested, but not required [[rfc1123]].</p>

<p>In the <a href="#text-textual-data"><span class="chunk">tEXt</span></a>
and <a href="#ztxt-compressed-textual-data"><span class="chunk">zTXt</span></a> chunks,
the text string associated with a keyword is restricted to the
Latin-1 character set plus the linefeed character. Text strings
in <a href="#ztxt-compressed-textual-data"><span class="chunk">zTXt</span></a> are
compressed into zlib datastreams using deflate compression (see
10.3: <a href='#other-uses-of-compression'><span class="xref">Other
uses of compression</span></a>). The <a href="#itxt-international-textual-data"><span
class="chunk">iTXt</span></a> chunk can be used to convey
characters outside the Latin-1 set. It uses the UTF-8 encoding [[rfc3629]].
There is an option to compress text strings
in the <a href="#itxt-international-textual-data"><span class="chunk">iTXt</span></a>
chunk.</p>
</section>

<!-- Maintain a fragment named "11tEXt" to preserve incoming links to it -->
<section id="11tEXt">
<h2><a name="text-textual-data"><span class="chunk">tEXt</span>
Textual data</a></h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
116 69 88 116
</pre>

<p>Each <span class="chunk">tEXt</span> chunk contains a keyword
and a text string, in the format:</p>

<table class="Regular" summary=
"This table defines the tEXt chunk">
<tr>
<td class="Regular">Keyword</td>
<td class="Regular">1-79 bytes (character string)</td>
</tr>

<tr>
<td class="Regular">Null separator</td>
<td class="Regular">1 byte (null character)</td>
</tr>

<tr>
<td class="Regular">Text string</td>
<td class="Regular">0 or more bytes (character string)</td>
</tr>
</table>

<p>
The keyword and text string are separated by a zero byte (null
character). Neither the keyword nor the text string may contain a
null character.
The text string is <strong>not</strong> null-terminated (the length of
the chunk defines the ending). The text string may be of any
length from zero bytes up to the maximum permissible chunk size
less the length of the keyword and null character separator.</p>

<p>The keyword indicates the type of information represented by
the text string as described in 11.3.4.2: <a href=
"#keywords-and-text-strings"><span class="xref">Keywords and text
strings</span></a>.</p>

<p>Text is interpreted according to the Latin-1 character set [[ISO 8859-1]].
The text string may contain
any Latin-1 character. Newlines in the text string should be
represented by a single linefeed character (decimal 10).
Characters other than those defined in Latin-1 plus the linefeed
character have no defined meaning in <span class="chunk">tEXt</span> chunks.
Text containing characters outside the repertoire of ISO/IEC
8859-1 should be encoded using the <a href="#itxt-international-textual-data"><span class=
"chunk">iTXt</span></a> chunk.</p>
</section>

<!-- Maintain a fragment named "11zTXt" to preserve incoming links to it -->
<section id="11zTXt">
<h2><span class="chunk">zTXt</span>
Compressed textual data</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
122 84 88 116
</pre>

<p>The <span class="chunk">zTXt</span> and <a href=
"#text-textual-data"><span class="chunk">tEXt</span></a> chunks are
semantically equivalent, but the <span class="chunk">zTXt</span>
chunk is recommended for storing large blocks of text.</p>

<p>A <span class="chunk">zTXt</span> chunk contains:</p>

<table class="Regular" summary=
"This table defines the zTXt chunk">
<tr>
<td class="Regular">Keyword</td>
<td class="Regular">1-79 bytes (character string)</td>
</tr>

<tr>
<td class="Regular">Null separator</td>
<td class="Regular">1 byte (null character)</td>
</tr>

<tr>
<td class="Regular">Compression method</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Compressed text datastream</td>
<td class="Regular">n bytes</td>
</tr>
</table>

<p>The keyword and null character are the same as in the <a href=
"#text-textual-data"><span class="chunk">tEXt</span></a> chunk (see
11.3.4.3: <a href="#text-textual-data"><span class="xref"><span class=
"chunk">tEXt</span> Textual data</span></a>). The keyword is not
compressed. The compression method entry defines the compression
method used. The only value defined in this International
Standard is 0 (deflate/inflate compression). Other values are
reserved for future standardization (see 4.9 <a href=
"#extension-and-registration"><span class="xref">Extension and
registration</span></a>). The compression method entry is
followed by the compressed text datastream that makes up the
remainder of the chunk. For compression method 0, this datastream
is a zlib datastream with deflate compression (see 10.3: <a href=
"#other-uses-of-compression"><span class="xref">Other uses of
compression</span></a>). Decompression of this datastream yields
Latin-1 text that is identical to the text that would be stored
in an equivalent <a href="#text-textual-data"><span class=
"chunk">tEXt</span></a> chunk.</p>
</section>

<!-- Maintain a fragment named "11iTXt" to preserve incoming links to it -->
<section id="11iTXt">
<h2><span class="chunk">iTXt</span>
International textual data</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
105 84 88 116
</pre>

<p>An <span class="chunk">iTXt</span> chunk contains:</p>

<table class="Regular" summary=
"This table defines the iTXt chunk">
<tr>
<td class="Regular">Keyword</td>
<td class="Regular">1-79 bytes (character string)</td>
</tr>

<tr>
<td class="Regular">Null separator</td>
<td class="Regular">1 byte (null character)</td>
</tr>

<tr>
<td class="Regular">Compression flag</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Compression method</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Language tag</td>
<td class="Regular">0 or more bytes (character string)</td>
</tr>

<tr>
<td class="Regular">Null separator</td>
<td class="Regular">1 byte (null character)</td>
</tr>

<tr>
<td class="Regular">Translated keyword</td>
<td class="Regular">0 or more bytes</td>
</tr>

<tr>
<td class="Regular">Null separator</td>
<td class="Regular">1 byte (null character)</td>
</tr>

<tr>
<td class="Regular">Text</td>
<td class="Regular">0 or more bytes</td>
</tr>
</table>

<p>The keyword is described in 11.3.4.2: <a href=
"#keywords-and-text-strings"><span class="xref">Keywords and text
strings</span></a>.</p>

<p>The compression flag is 0 for uncompressed text, 1 for
compressed text. Only the text field may be compressed. The
compression method entry defines the compression method used. The
only compression method defined in this specification is
0 (zlib datastream with deflate compression, see 10.3: <a href=
'#other-uses-of-compression'><span class="xref">Other uses of
compression</span></a>). For uncompressed text, encoders shall
set the compression method to 0, and decoders shall ignore
it.</p>

<p>The language tag defined in [[rfc3066]]
indicates the human language used by the translated keyword and
the text. Unlike the keyword, the language tag is
case-insensitive. It is an ISO 646.IRV:1991 [[ISO 646]] string consisting of
hyphen-separated words of 1-8 alphanumeric characters each (for example cn,
en-uk, no-bok, x-klingon, x-KlInGoN). If the first word is two or three
letters long, it is an ISO language code [[ISO 639]]. If the
language tag is empty, the language is unspecified.</p>

<p>The translated keyword and text both use the UTF-8 encoding [[rfc3629]],
and neither shall contain a zero byte (null
character). The text, unlike other textual data in this chunk, is
not null-terminated; its length is derived from the chunk
length.</p>

<p>Line breaks should not appear in the translated keyword. In
the text, a newline should be represented by a single linefeed
character (decimal 10). The remaining control characters (1-9,
11-31, 127-159) are discouraged in both the translated keyword
and text. In UTF-8 there is a difference between the characters
128-159 (which are discouraged) and the bytes 128-159 (which are
often necessary).</p>

<p>The translated keyword, if not empty, should contain a
translation of the keyword into the language indicated by the
language tag, and applications displaying the keyword should
display the translated keyword in addition.</p>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "11addnlsiinfo" to preserve incoming links to it -->
<section id="11addnlsiinfo">
<h2>Miscellaneous
information</h2>

<!-- Maintain a fragment named "11bKGD" to preserve incoming links to it -->
<section id="11bKGD">
<h2><span class="chunk">bKGD</span>
Background colour</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
98 75 71 68
</pre>

<p>The <span class="chunk">bKGD</span> chunk specifies a default
background colour to present the image against. If there is any
other preferred background, either user-specified or part of a
larger page (as in a browser), the <span class=
"chunk">bKGD</span> chunk should be ignored. The <span class=
"chunk">bKGD</span> chunk contains:</p>

<table class="Regular" summary=
"This table defines the bKGD chunk">
<tr>
<th colspan="2">Colour types 0 and 4</th>
</tr>

<tr>
<td class="Regular">Greyscale</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<th colspan="2">Colour types 2 and 6</th>
</tr>

<tr>
<td class="Regular">Red</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<td class="Regular">Green</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<td class="Regular">Blue</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<th colspan="2">Colour type 3</th>
</tr>

<tr>
<td class="Regular">Palette index</td>
<td class="Regular">1 byte</td>
</tr>
</table>

<p>For colour type 3 (indexed-colour), the value is the palette
index of the colour to be used as background.</p>

<p>For colour types 0 and 4 (greyscale, greyscale with alpha),
the value is the grey level to be used as background in the range
0 to (2<sup>bitdepth</sup>)-1. For colour types 2 and 6
(truecolour, truecolour with alpha), the values are the colour to be
used as background, given as RGB
samples in the range 0 to (2<sup>bitdepth</sup>)-1. In each case,
for consistency, two bytes per sample are used regardless of the
image bit depth. If the image bit depth is less than 16, the
least significant bits are used and the others are 0.</p>
</section>

<!-- Maintain a fragment named "11hIST" to preserve incoming links to it -->
<section id="11hIST">
<h2><span class="chunk">hIST</span>
Image histogram</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
104 73 83 84
</pre>

<p>The <span class="chunk">hIST</span> chunk contains a series of
two-byte (16-bit) unsigned integers:</p>

<table class="Regular" summary=
"This table defines the hIST chunk">
<tr>
<td class="Regular">Frequency</td>
<td class="Regular">2 bytes (unsigned integer)</td>
</tr>
<tr>
<td class="Regular">...etc...</td>
<td class="Regular">&nbsp;</td>
</tr>
</table>

<p>The <span class="chunk">hIST</span> chunk gives the
approximate usage frequency of each colour in the palette. A
histogram chunk can appear only when a <a href="#plte-palette"><span
class="chunk">PLTE</span></a> chunk appears. If a viewer is
unable to provide all the colours listed in the palette, the
histogram may help it decide how to choose a subset of the
colours for display.</p>

<p>There shall be exactly one
entry for each entry in the <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk. Each entry is proportional to the
fraction of pixels in the image that have that palette index; the
exact scale factor is chosen by the encoder.</p>

<p>Histogram entries are approximate, with the exception that a
zero entry specifies that the corresponding palette entry is not
used at all in the image. A histogram entry shall be nonzero if
there are any pixels of that colour.</p>

<p class="Note">NOTE When the palette is a suggested quantization
of a truecolour image, the histogram is necessarily approximate,
since a decoder may map pixels to palette entries differently
than the encoder did. In this situation, zero entries should not
normally appear, because any entry might be used.</p>
</section>

<!-- Maintain a fragment named "11pHYs" to preserve incoming links to it -->
<section id="11pHYs">
<h2><span class="chunk">pHYs</span>
Physical pixel dimensions</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
112 72 89 115
</pre>

<p>The <span class="chunk">pHYs</span> chunk specifies the
intended pixel size or aspect ratio for display of the image. It
contains:</p>

<table class="Regular" summary=
"This table defines the pHYs chunk">
<tr>
<td class="Regular">Pixels per unit, X axis</td>
<td class="Regular">4 bytes (PNG unsigned integer)</td>
</tr>

<tr>
<td class="Regular">Pixels per unit, Y axis</td>
<td class="Regular">4 bytes (PNG unsigned integer)</td>
</tr>

<tr>
<td class="Regular">Unit specifier</td>
<td class="Regular">1 byte</td>
</tr>
</table>

<p>The following values are defined for the unit specifier:</p>

<table class="Regular" summary=
"This table defines the allowed values for the unit specifier in the pHYs chunk">
<tr>
<td class="Regular">0</td>
<td class="Regular">unit is unknown</td>
</tr>

<tr>
<td class="Regular">1</td>
<td class="Regular">unit is the metre</td>
</tr>
</table>

<p>When the unit specifier is 0, the <span class=
"chunk">pHYs</span> chunk defines pixel aspect ratio only; the
actual size of the pixels remains unspecified.</p>

<p>If the <span class="chunk">pHYs</span> chunk is not present,
pixels are assumed to be square, and the physical size of each
pixel is unspecified.</p>
</section>

<!-- Maintain a fragment named "11sPLT" to preserve incoming links to it -->
<section id="11sPLT">
<h2><span class="chunk">sPLT</span>
Suggested palette</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
115 80 76 84
</pre>

<p>The <span class="chunk">sPLT</span> chunk contains:</p>

<table class="Regular" summary=
"This table defines the sPLT chunk">
<tr>
<td class="Regular">Palette name</td>
<td class="Regular">1-79 bytes (character string)</td>
</tr>

<tr>
<td class="Regular">Null separator</td>
<td class="Regular">1 byte (null character)</td>
</tr>

<tr>
<td class="Regular">Sample depth</td>
<td class="Regular">1 byte</td>
</tr>

<tr>
<td class="Regular">Red</td>
<td class="Regular">1 or 2 bytes</td>
</tr>

<tr>
<td class="Regular">Green</td>
<td class="Regular">1 or 2 bytes</td>
</tr>

<tr>
<td class="Regular">Blue</td>
<td class="Regular">1 or 2 bytes</td>
</tr>

<tr>
<td class="Regular">Alpha</td>
<td class="Regular">1 or 2 bytes</td>
</tr>

<tr>
<td class="Regular">Frequency</td>
<td class="Regular">2 bytes</td>
</tr>

<tr>
<td class="Regular">...etc...</td>
<td class="Regular">&nbsp;</td>
</tr>
</table>

<p>Each palette entry is six bytes or ten bytes containing five
unsigned integers (red, blue, green, alpha, and frequency).</p>

<p>There may be any number of entries. A PNG decoder determines
the number of entries from the length of the chunk remaining
after the sample depth byte. This shall be divisible by 6 if the
<span class="chunk">sPLT</span> sample depth is 8, or by 10 if
the <span class="chunk">sPLT</span> sample depth is 16. Entries
shall appear in decreasing order of frequency. There is no
requirement that the entries all be used by the image, nor that
they all be different.</p>

<p>The palette name can be any convenient name for referring to
the palette (for example "256 colour including Macintosh
default", "256 colour including Windows-3.1 default", "Optimal
512"). The palette name may aid the choice of the appropriate
suggested palette when more than one appears in a PNG
datastream.</p>

<p>The palette name is case-sensitive, and subject to the same
restrictions as the keyword parameter for the <a href=
"#text-textual-data"><span class="chunk">tEXt</span></a> chunk. Palette
names shall contain only printable Latin-1 characters and spaces
(only character codes 32-126 and 161-255 decimal are allowed).
Leading, trailing, and consecutive spaces are not permitted.</p>

<p>The <span class="chunk">sPLT</span> sample depth shall be 8 or
16.</p>

<p>The red, green, blue, and alpha samples are either one or two
bytes each, depending on the <span class="chunk">sPLT</span>
sample depth, regardless of the image bit depth. The colour
samples are not premultiplied by alpha, nor are they
precomposited against any background. An alpha value of 0 means
fully transparent. An alpha value of 255 (when the <span class=
"chunk">sPLT</span> sample depth is 8) or 65535 (when the <span
class="chunk">sPLT</span> sample depth is 16) means fully opaque.
The <span class="chunk">sPLT</span> chunk may appear for any PNG
colour type. Entries in <span class="chunk">sPLT</span> use the
same gamma and chromaticity values as the PNG image, but may fall
outside the range of values used in the colour space of the PNG
image; for example, in a greyscale PNG image, each <span class=
"chunk">sPLT</span> entry would typically have equal red, green,
and blue values, but this is not required. Similarly, <span
class="chunk">sPLT</span> entries can have non-opaque alpha
values even when the PNG image does not use transparency.</p>

<p>Each frequency value is proportional to the fraction of
the pixels in the image for which that palette entry
is the closest match in RGBA space, before the image has been composited against any
background. The exact scale factor is chosen by the PNG encoder;
it is recommended that the resulting range of individual values
reasonably fills the range 0 to 65535. A PNG encoder may
artificially inflate the frequencies for colours considered to be
"important", for example the colours used in a logo or the facial
features of a portrait. Zero is a valid frequency meaning that
the colour is "least important" or that it is rarely, if ever,
used. When all the frequencies are zero, they are meaningless,
that is to say, nothing may be inferred about the actual
frequencies with which the colours appear in the PNG image.</p>

<p>Multiple <span class="chunk">sPLT</span> chunks are permitted,
but each shall have a different palette name.</p>
</section>

  <!-- Maintain a fragment named "eXIf" to preserve incoming links to it -->
<section id="eXIf">
  <h2><span class="chunk">eXIf</span>
    Exchangeable Image File (Exif) Profile</h2>

  <p>The four-byte chunk type field contains the decimal values</p>

  <pre>
  101 88 73 102
  </pre>

  <p>The data segment of the <span class="chunk">eXIf</span> chunk
    contains an Exif profile in the format specified in
    "4.7.2 Interoperability Structure of APP1 in Compressed Data"
    of [[CIPA DC-008]]
    except that the JPEG APP1 marker, length, and the "Exif ID code"
    described in 4.7.2(C), i.e., "Exif", NULL, and padding byte,
    are not included.</p>

  <p>The <span class="chunk">eXIf</span> chunk
    may appear anywhere between the <span class="chunk">IHDR</span>
    and <span class="chunk">IEND<span class="chunk"> chunks
    except between <span class="chunk">IDAT</span> chunks.
    The <span class="chunk">eXIf</ chunk size is constrained
    only by the maximum of 2<sup>31</sup>-1 bytes
    imposed by the PNG specification.
    Only one <span class="chunk">eXIf</span> chunk is allowed in a PNG datastream.</p>

  <p>The <span class="chunk">eXIf</span> chunk contains
    metadata concerning the original image data.
    If the image has been edited subsequent to creation of the Exif profile,
    this data might no longer apply to the PNG image data.
    It is recommended that unless a decoder has independent knowledge
    of the validity of the Exif data,
    the data should be considered to be of historical value only.
    It is beyond the scope of this specification
    to resolve potential conflicts
    between data in the eXIf chunk and in other PNG chunks. </p>

    <section>
      <h3><span class="chunk">eXIf</span> General Recommendations</h3>

      <p>While the PNG specification allows the chunk size
        to be as large as 2<sup>31</sup>-1 bytes,
        application authors should be aware that,
        if the Exif profile is going to be written to a JPEG [[JPEG]] datastream,
        the total length of the <span class="chunk">eXIf</span> chunk data
        may need to be adjusted to not exceed 2<sup>16</sup>-9 bytes,
        so it can fit into a JPEG APP1 marker (Exif) segment. </p>
    </section>

    <section>
      <h3><span class="chunk">eXIf</span> Recommendations for Decoders</h3>

      <p>The first two bytes of data are either "II" for little-endian (Intel) or "MM" for big-endian (Motorola) byte order. Decoders should check the first four bytes to ensure that they have the following decimal values: </p>

      <pre>73 73 42 0 (ASCII "II", 16-bit little-endian integer 42)</pre>

      <p>or</p>

      <pre>77 77 0 42 (ASCII "MM", 16-bit big-endian integer 42)</pre>

      <p>All other values are reserved for possible future definition. </p>
    </section>

    <section>
      <h3><span class="chunk">eXIf</span> Recommendations for Encoders</h3>

      <p>Image editing applications should consider
        Paragraph E.3 of the Exif Specification [[CIPA DC-008]],
        which discusses requirements for updating Exif data
        when the image is changed.
        Encoders should follow those requirements,
        but decoders should not assume that it has been accomplished. </p>

      <p>While encoders may choose to update them,
        there is no expectation that any thumbnails present
        in the Exif profile have (or have not) been updated
        if the main image was changed.
      </p>

    </section>


</section>


</section>

<!-- Maintain a fragment named "11timestampinfo" to preserve incoming links to it -->
<section id="11timestampinfo">
<h2>Time stamp
information</h2>

<!-- Maintain a fragment named "11tIME" to preserve incoming links to it -->
<section id="11tIME">
<h2><span class="chunk">tIME</span>
Image last-modification time</h2>

<p>The four-byte chunk type field contains the decimal values</p>

<pre>
116 73 77 69
</pre>

<p>The <span class="chunk">tIME</span> chunk gives the time of
the last image modification (<strong>not</strong> the time of initial
image creation). It contains:</p>

<table class="Regular" summary=
"This table defines the tIME chunk">
<tr>
<td class="Regular">Year</td>
<td class="Regular">2 bytes (complete; for example, 1995, <strong>not</strong> 95)</td>
</tr>

<tr>
<td class="Regular">Month</td>
<td class="Regular">1 byte (1-12)</td>
</tr>

<tr>
<td class="Regular">Day</td>
<td class="Regular">1 byte (1-31)</td>
</tr>

<tr>
<td class="Regular">Hour</td>
<td class="Regular">1 byte (0-23)</td>
</tr>

<tr>
<td class="Regular">Minute</td>
<td class="Regular">1 byte (0-59)</td>
</tr>

<tr>
<td class="Regular">Second</td>
<td class="Regular">1 byte (0-60) (to allow for leap seconds)</td>
</tr>
</table>

<p>Universal Time (UTC) should be specified rather than local
time.</p>

<p>The <span class="chunk">tIME</span> chunk is intended for use
as an automatically-applied time stamp that is updated whenever
the image data are changed.</p>
</section>
</section>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "12Encoders" to preserve incoming links to it -->
<section id="12Encoders">
<h2>PNG Encoders</h2>

<!-- Maintain a fragment named "12Introduction" to preserve incoming links to it -->
<section class="introductory" id="12Introduction">
<p>This clause gives requirements and recommendations for encoder
behaviour. A PNG encoder shall produce a PNG datastream from a
PNG image that conforms to the format specified in the preceding
clauses. Best results will usually be achieved by following the
additional recommendations given here.</p>
</section>

<!-- Maintain a fragment named "12Encoder-gamma-handling" to preserve incoming links to it -->
<section id="12Encoder-gamma-handling">
<h2>Encoder gamma
handling</h2>

<p>See Annex C: <a href="#C-GammaAppendix"><span class=
"xref">Gamma and chromaticity</span></a> for a brief introduction
to gamma issues.</p>

<p>PNG encoders capable of full colour management will perform more
sophisticated calculations than those described here and may
choose to use the <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a> chunk. If it is known that the image
samples conform to the sRGB specification [[SRGB]], encoders are strongly encouraged to write
the <a href="#srgb-standard-colour-space"><span class="chunk">sRGB</span></a> chunk
without performing additional gamma handling. In both cases it is
recommended that an appropriate <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunk be generated for use by PNG
decoders that do not recognize the <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a> chunk or <a href="#srgb-standard-colour-space"><span class=
"chunk">sRGB</span></a> chunk.</p>

<p>A PNG encoder has to determine:</p>

<!-- <ol start="1"> --><ol>
<li>what value to write in the <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunk;</li>

<li>how to transform the provided image samples  into the values
to be written in the PNG datastream.</li>
</ol>

<p>The value to write in the <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunk is that value which causes a PNG
decoder to behave in the desired way. See 13.13: <a class='Href'
href='#decoder-gamma-handling'>Decoder gamma handling</a>.</p>

<p>The transform to be applied depends on the nature of the image
samples and their precision. If the samples represent light
intensity in floating-point or high precision integer form
(perhaps from a computer graphics renderer), the encoder may
perform "gamma encoding" (applying a power function with exponent
less than 1) before quantizing the data to integer values for
inclusion in the PNG datastream. This results in fewer banding
artifacts at a given sample depth, or allows smaller samples
while retaining the same visual quality. An intensity level
expressed as a floating-point value in the range 0 to 1 can be
converted to a datastream image sample by:</p>

<p><tt>integer_sample =
floor((2<sup>sampledepth</sup>-1) * intensity<sup>encoding_exponent</sup>
+ 0.5)</tt></p>

<p>If the intensity in the equation is the desired output
intensity, the encoding exponent is the gamma value to be used in
the <a href="#gama-image-gamma"><span class="chunk">gAMA</span></a>
chunk.</p>

<p>If the intensity available to the PNG encoder is the original
scene intensity, another transformation may be needed. There is
sometimes a requirement for the displayed image to have higher
contrast than the original source image. This corresponds to an
end-to-end transfer function from original scene to display
output with an exponent greater than 1. In this case:</p>

<pre>
gamma = encoding_exponent/end_to_end_exponent
</pre>

<p>If it is not known whether the conditions under which the
original image was captured or calculated warrant such a contrast
change, it may be assumed that the display intensities are
proportional to original scene intensities, i.e. the end-to-end
exponent is 1 and hence:</p>

<pre>
gamma = encoding_exponent
</pre>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<p>If the image is being written to a datastream only, the
encoder is free to choose the encoding exponent. Choosing a value
that causes the gamma value in the <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunk to be 1/2.2 is often a reasonable
choice because it minimizes the work for a PNG decoder displaying
on a typical video monitor.</p>

<p>Some image renderers may simultaneously write the image to a
PNG datastream and display it on-screen. The displayed pixels
should be gamma corrected for the display system and viewing
conditions in use, so that the user sees a proper representation
of the intended scene.</p>

<p>If the renderer wants to write the displayed sample values to
the PNG datastream, avoiding a separate gamma encoding step for
the datastream, the renderer should approximate the transfer
function of the display system by a power function, and write the
reciprocal of the exponent into the <a href="#gama-image-gamma"><span
class="chunk">gAMA</span></a> chunk. This will allow a PNG
decoder to reproduce what was displayed on screen for the
originator during rendering.</p>

<p>However, it is equally reasonable for a renderer to compute
displayed pixels appropriate for the display device, and to
perform separate gamma encoding for data storage and
transmission, arranging to have a value in the <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> chunk more
appropriate to the future use of the image.</p>

<p>Computer graphics renderers often do not perform gamma
encoding, instead making sample values directly proportional to
scene light intensity. If the PNG encoder receives sample values
that have already been quantized into integer values, there is no
point in doing gamma encoding on them; that would just result in
further loss of information. The encoder should just write the
sample values to the PNG datastream. This does not imply that the
<a href="#gama-image-gamma"><span class="chunk">gAMA</span></a> chunk
should contain a gamma value of 1.0 because the desired
end-to-end transfer function from scene intensity to display
output intensity is not necessarily linear. However, the desired
gamma value is probably not far from 1.0. It may depend on
whether the scene being rendered is a daylight scene or an indoor
scene, etc.</p>

<p>When the sample values come directly from a piece of hardware,
the correct <a href="#gama-image-gamma"><span class="chunk">gAMA</span></a>
value can, in principle, be inferred from the transfer function
of the hardware and lighting conditions of the scene. In the case
of video digitizers ("frame grabbers"), the samples are probably
in the sRGB colour space, because the sRGB specification was
designed to be compatible with modern video standards. Image
scanners are less predictable. Their output samples may be
proportional to the input light intensity since CCD sensors
themselves are linear, or the scanner hardware may have already
applied a power function designed to compensate for dot gain in
subsequent printing (an exponent of about 0.57), or the scanner
may have corrected the samples for display on a monitor. It may
be necessary to refer to the scanner's manual or to scan a
calibrated target in order to determine the characteristics of a
particular scanner. It should be remembered that gamma relates
samples to desired display output, not to scanner input.</p>

<p>Datastream format converters generally should not attempt to
convert supplied images to a different gamma. The data should be
stored in the PNG datastream without conversion, and the gamma
value should be deduced from information in the source datastream
if possible. Gamma alteration at datastream conversion time
causes re-quantization of the set of intensity levels that are
represented, introducing further roundoff error with little
benefit. It is almost always better to just copy the sample
values intact from the input to the output file.</p>

<p>If the source datastream describes the gamma characteristics
of the image, a datastream converter is strongly encouraged to
write a <a href="#gama-image-gamma"><span class="chunk">gAMA</span></a>
chunk. Some datastream formats specify the display exponent (the
exponent of the function which maps image samples to display
output rather than the other direction). If the source file's
gamma value is greater than 1.0, it is probably a display
exponent, and the reciprocal of this value should be used for the
PNG gamma value. If the source file format records the
relationship between image samples and a quantity other than
display output, it will be more complex than this to deduce the
PNG gamma value.</p>

<p>If a PNG encoder or datastream converter knows that the image
has been displayed satisfactorily using a display system whose
transfer function can be approximated by a power function with
exponent <tt>display_exponent</tt>, the image can be marked as
having the gamma value:</p>

<pre>
gamma = 1/display_exponent
</pre>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<p>It is better to write a <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunk with a value that is approximately
correct than to omit the chunk and force PNG decoders to guess an
approximate gamma. If a PNG encoder is unable to infer the gamma
value, it is preferable to omit the <a href="#gama-image-gamma"><span
class="chunk">gAMA</span></a> chunk. If a guess has to be made
this should be left to the PNG decoder.</p>

<p>Gamma does not apply to alpha samples; alpha is always
represented linearly.</p>

<p>See also 13.13: <a href="#decoder-gamma-handling"><span
class="xref">Decoder gamma handling</span></a>.</p>
</section>

<!-- Maintain a fragment named "12Encoder-colour-handling" to preserve incoming links to it -->
<section id="12Encoder-colour-handling">
<h2>Encoder colour
handling</h2>

<p>See Annex C: <a href="#C-GammaAppendix"><span class=
"xref">Gamma and chromaticity</span></a> for references to colour
issues.</p>

<p>PNG encoders capable of full colour management will perform more
sophisticated calculations than those described here and may
choose to use the <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a> chunk. If it is known that the image
samples conform to the sRGB specification [[SRGB]], PNG encoders are strongly encouraged to
use the <a href="#srgb-standard-colour-space"><span class="chunk">sRGB</span></a>
chunk.</p>

<p>If it is possible for the encoder to determine the
chromaticities of the source display primaries, or to make a
strong guess based on the origin of the image, or the hardware
running it, the encoder is strongly encouraged to output the <a
href="#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> chunk. If this
is done, the <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunk should also be written; decoders
can do little with a <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk if the <a href="#gama-image-gamma"><span
class="chunk">gAMA</span></a> chunk is missing.</p>

<p>There are a number of recommendations and standards for
primaries and white points, some of which are linked to
particular technologies, for example the CCIR 709 standard [[ITU-R BT.709]]
and the SMPTE-C standard [[SMPTE 170M]].</p>

<p>There are three cases that need to be considered:</p>

<ol>
<li>the encoder is part of the generation system;</li>

<li>the source image is captured by a camera or scanner;</li>

<li>the PNG datastream was generated by translation from some
other format.</li>
</ol>

<!--  deleted - comment PDG 31<p>Scanners that produce PNG datastreams as output should insert
the filter chromaticities into a <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk.</p>-->

<p>In the case of hand-drawn or digitally edited images, it is
necessary to determine what monitor they were viewed on when
being produced. Many image editing programs allow the type of
monitor being used to be specified. This is often because they
are working in some device-independent space internally. Such
programs have enough information to write valid <a href=
"#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> and <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> chunks, and are
strongly encouraged to do so automatically.</p>

<p>If the encoder is compiled as a portion of a computer image
renderer that performs full-spectral rendering, the monitor
values that were used to convert from the internal
device-independent colour space to RGB should be written into the
<a href="#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> chunk. Any
colours that are outside the gamut of the chosen RGB device
should be mapped to be within the gamut; PNG does not store
out-of-gamut colours.</p>

<p>If the computer image renderer performs calculations directly
in device-dependent RGB space, a <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk should not be written unless the
scene description and rendering parameters have been adjusted for
a particular monitor. In that case, the data for that monitor
should be used to construct a <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk.</p>

<p>A few image formats store calibration information, which can
be used to fill in the <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk. For example, TIFF 6.0 files [[?TIFF 6.0]] can
optionally store calibration information, which if present should
be used to construct the <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk.</p>

<p>Video created with recent video equipment probably uses the
CCIR 709 primaries and D65 white point [[ITU-R BT.709]],
which are given in <a href="#12-table121"><span class=
"tabref">Table 12.1</span></a>.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<table class="Regular" summary=
"CCIR 709 primaries and D65 whitepoint">
<caption><a name="12-table121"><b>Table 12.1 &mdash; CCIR 709
primaries and D65 whitepoint</b></a></caption>

<tr>
<th>&nbsp;</th>
<th>R</th>
<th>G</th>
<th>B</th>
<th>White</th>
</tr>

<tr>
<td class="Regular">x</td>
<td class="Regular">0.640</td>
<td class="Regular">0.300</td>
<td class="Regular">0.150</td>
<td class="Regular">0.3127</td>
</tr>

<tr>
<td class="Regular">y</td>
<td class="Regular">0.330</td>
<td class="Regular">0.600</td>
<td class="Regular">0.060</td>
<td class="Regular">0.3290</td>
</tr>
</table>

<p>An older but still very popular video standard is SMPTE-C [[SMPTE 170M]]
given in <a href="#12-table122"><span class="tabref">Table
12.2</span></a>.</p>

<table class="Regular" summary=
"CSMPTE-C video standard">
<caption><a name="12-table122"><b>Table 12.2 &mdash; SMPTE-C
video standard</b></a></caption>

<tr>
<th>&nbsp;</th>
<th>R</th>
<th>G</th>
<th>B</th>
<th>White</th>
</tr>

<tr>
<td class="Regular">x</td>
<td class="Regular">0.630</td>
<td class="Regular">0.310</td>
<td class="Regular">0.155</td>
<td class="Regular">0.3127</td>
</tr>

<tr>
<td class="Regular">y</td>
<td class="Regular">0.340</td>
<td class="Regular">0.595</td>
<td class="Regular">0.070</td>
<td class="Regular">0.3290</td>
</tr>
</table>

<p>It is <strong>not</strong> recommended that datastream format
converters attempt to convert supplied images to a different RGB
colour space. The data should be stored in the PNG datastream
without conversion, and the source primary chromaticities should
be recorded if they are known. Colour space transformation at
datastream conversion time is a bad idea because of gamut
mismatches and rounding errors. As with gamma conversions, it is
better to store the data losslessly and incur at most one
conversion when the image is finally displayed.</p>

<p>See also 13.14: <a href="#decoder-colour-handling"><span
class="xref">Decoder colour handling</span></a>.</p>
</section>

<!-- Maintain a fragment named "12Alpha-channel-creation" to preserve incoming links to it -->
<section id="12Alpha-channel-creation">
<h2>Alpha channel
creation</h2>

<p>The alpha channel can be regarded either as a mask that
temporarily hides transparent parts of the image, or as a means
for constructing a non-rectangular image. In the first case, the
colour values of fully transparent pixels should be preserved for
future use. In the second case, the transparent pixels carry no
useful data and are simply there to fill out the rectangular
image area required by PNG. In this case, fully transparent
pixels should all be assigned the same colour value for best
compression.</p>

<p>Image authors should keep in mind the possibility that a
decoder will not support transparency control in full (see 13.16:
<a href="#alpha-channel-processing"><span class="xref">Alpha
channel processing</span></a>). Hence, the colours assigned to
transparent pixels should be reasonable background colours
whenever feasible.</p>

<p>For applications that do not require a full alpha channel, or
cannot afford the price in compression efficiency, the <a href=
"#trns-transparency"><span class="chunk">tRNS</span></a> transparency chunk
is also available.</p>

<p>If the image has a known background colour, this colour should
be written in the <a href="#bkgd-background-colour"><span class=
"chunk">bKGD</span></a> chunk. Even decoders that ignore
transparency may use the <a href="#bkgd-background-colour"><span class=
"chunk">bKGD</span></a> colour to fill unused screen area.</p>

<p>If the original image has premultiplied (also called
"associated") alpha data, it can be converted to PNG's
non-premultiplied format by dividing each sample value by the
corresponding alpha value, then multiplying by the maximum value
for the image bit depth, and rounding to the nearest integer. In
valid premultiplied data, the sample values never exceed their
corresponding alpha values, so the result of the division should
always be in the range 0 to 1. If the alpha value is zero, output
black (zeroes).</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "12Sample-depth-scaling" to preserve incoming links to it -->
<section id="12Sample-depth-scaling">
<h2>Sample depth
scaling</h2>

<p>When encoding input samples that have a sample depth that
cannot be directly represented in PNG, the encoder shall scale
the samples up to a sample depth that is allowed by PNG. The most
accurate scaling method is the linear equation:</p>

<pre>
output = floor((input * MAXOUTSAMPLE / MAXINSAMPLE) + 0.5)
</pre>

<p>where the input samples range from 0 to <tt>MAXINSAMPLE</tt>
and the outputs range from 0 to <tt>MAXOUTSAMPLE</tt> (which is
2<sup>sampledepth</sup>-1).</p>

<p>A close approximation to the linear scaling method is achieved
by "left bit replication", which is shifting the valid bits to
begin in the most significant bit and repeating the most
significant bits into the open bits. This method is often faster
to compute than linear scaling.</p>

<p>EXAMPLE Assume that 5-bit samples are being scaled up to 8
bits. If the source sample value is 27 (in the range from 0-31),
then the original bits are:</p>

<pre>
   4 3 2 1 0
   ---------
   1 1 0 1 1
</pre>

<p>Left bit replication gives a value of 222:</p>

<pre>
   7 6 5 4 3  2 1 0
   ----------------
   1 1 0 1 1  1 1 0
   |=======|  |===|
       |      Leftmost Bits Repeated to Fill Open Bits
       |
   Original Bits
</pre>

<p>which matches the value computed by the linear equation. Left
bit replication usually gives the same value as linear scaling,
and is never off by more than one.</p>

<p>A distinctly less accurate approximation is obtained by simply
left-shifting the input value and filling the low order bits with
zeroes. This scheme cannot reproduce white exactly, since it does
not generate an all-ones maximum value; the net effect is to
darken the image slightly. This method is not recommended in
general, but it does have the effect of improving compression,
particularly when dealing with greater-than-8-bit sample depths.
Since the relative error introduced by zero-fill scaling is small
at high sample depths, some encoders may choose to use it.
Zero-fill shall <strong>not</strong> be used for alpha channel
data, however, since many decoders will treat alpha values of all
zeroes and all ones as special cases. It is important to
represent both those values exactly in the scaled data.</p>

<p>When the encoder writes an <a href="#sbit-significant-bits"><span class=
"chunk">sBIT</span></a> chunk, it is required to do the scaling
in such a way that the high-order bits of the stored samples
match the original data. That is, if the <a href="#sbit-significant-bits"><span
class="chunk">sBIT</span></a> chunk specifies a sample depth of
S, the high-order S bits of the stored data shall agree with the
original S-bit data values. This allows decoders to recover the
original data by shifting right. The added low-order bits are not
constrained. All the above scaling methods meet this
restriction.</p>

<p>When scaling up source image data, it is recommended that the
low-order bits be filled consistently for all samples; that is,
the same source value should generate the same sample value at
any pixel position. This improves compression by reducing the
number of distinct sample values. This is not a mandatory
requirement, and some encoders may choose not to follow it. For
example, an encoder might instead dither the low-order bits,
improving displayed image quality at the price of increasing file
size.</p>

<p>In some applications the original source data may have a range
that is not a power of 2. The linear scaling equation still works
for this case, although the shifting methods do not. It is
recommended that an <a href="#sbit-significant-bits"><span class=
"chunk">sBIT</span></a> chunk not be written for such images,
since <a href="#sbit-significant-bits"><span class="chunk">sBIT</span></a>
suggests that the original data range was exactly
0..2<sup>S</sup>-1.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "12Suggested-palettes" to preserve incoming links to it -->
<section id="12Suggested-palettes">
<h2>Suggested
palettes</h2>

<p>Suggested palettes may appear as <a href="#splt-suggested-palette"><span
class="chunk">sPLT</span></a> chunks in any PNG datastream, or as
a <a href="#plte-palette"><span class="chunk">PLTE</span></a> chunk in
truecolour PNG datastreams. In either case, the suggested palette
is not an essential part of the image data, but it may be used to
present the image on indexed-colour display hardware. Suggested
palettes are of no interest to viewers running on truecolour
hardware.</p>

<p>When an <a href="#splt-suggested-palette"><span class="chunk">sPLT</span></a>
chunk is used to provide a suggested palette, it is recommended
that the encoder use the frequency fields to indicate the
relative importance of the palette entries, rather than leave
them all zero (meaning undefined). The frequency values are most
easily computed as "nearest neighbour" counts, that is, the
approximate usage of each RGBA palette entry if no dithering is
applied. (These counts will often be available "for free" as a
consequence of developing the suggested palette.) Because the
suggested palette includes transparency information, it should be
computed for the uncomposited image.</p>

<p>Even for indexed-colour images, <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> can be used to define alternative reduced
palettes for viewers that are unable to display all the colours
present in the <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk.
If the <a href="#plte-palette"><span class="chunk">PLTE</span></a>
chunk appears without the <a href="#bkgd-background-colour"><span class=
"chunk">bKGD</span></a> chunk in an image of colour type 6, the
circumstances under which the palette was computed are
unspecified.</p>


<p>An older method for including a suggested palette in a
truecolour PNG datastream uses the <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk. If this method is used, the
histogram (frequencies) should appear in a separate <a href=
"#hist-image-histogram"><span class="chunk">hIST</span></a> chunk. The <a href=
"#plte-palette"><span class="chunk">PLTE</span></a> chunk does not
include transparency information. Hence for images of colour type
6 (truecolour with alpha), it is recommended that a <a href=
"#bkgd-background-colour"><span class="chunk">bKGD</span></a> chunk appear and
that the palette and histogram be computed with reference to the
image as it would appear after compositing against the specified
background colour. This definition is necessary to ensure that
useful palette entries are generated for pixels having fractional
alpha values. The resulting palette will probably be useful only
to viewers that present the image against the same background
colour. It is recommended that PNG editors delete or recompute
the palette if they alter or remove the <a href="#bkgd-background-colour"><span
class="chunk">bKGD</span></a> chunk in an image of colour type
6.</p>

<p>For images of colour type 2 (truecolour), it is recommended
that the <a href="#plte-palette"><span class="chunk">PLTE</span></a>
and <a href="#hist-image-histogram"><span class="chunk">hIST</span></a> chunks
be computed with reference to the RGB data only, ignoring any
transparent-colour specification. If the datastream uses
transparency (has a <a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> chunk), viewers can easily adapt the
resulting palette for use with their intended background colour
(see 13.17: <a href=
"#histogram-and-suggested-palette-usage"><span class="xref">
Histogram and suggested palette usage</span></a>).
</p>

<p>For providing suggested palettes,
the <a href="#splt-suggested-palette"><span class="chunk">sPLT</span></a>
chunk is more flexible than the <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk in
the following ways:</p>

<!-- <ol start="1"> --><ol>
<li>With <a href="#splt-suggested-palette"><span class="chunk">sPLT</span></a>
multiple suggested palettes may be provided. A PNG decoder may
choose an appropriate palette based on name or number of
entries.</li>

<li>In a PNG datastream of colour type 6 (truecolour with alpha
channel), the <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk represents a palette already
composited against the <a href="#bkgd-background-colour"><span class=
"chunk">bKGD</span></a> colour, so it is useful only for display
against that background colour. The <a href="#splt-suggested-palette"><span
class="chunk">sPLT</span></a> chunk provides an uncomposited
palette, which is useful for display against backgrounds chosen
by the PNG decoder.</li>

<li>Since the <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> chunk is an ancillary chunk, a PNG editor
may add or modify suggested palettes without being forced to
discard unknown unsafe-to-copy chunks.</li>

<li>Whereas the <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> chunk is allowed in PNG datastreams for
colour types 0, 3, and 4 (greyscale and indexed), the <a href=
"#plte-palette"><span class="chunk">PLTE</span></a> chunk cannot be
used to provide reduced palettes in these cases.</li>

<li>More than 256 entries may appear in the <a href=
"#splt-suggested-palette"><span class="chunk">sPLT</span></a> chunk.</li>
</ol>

<p>A PNG encoder that uses the <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> chunk may choose to write a suggested
palette represented by <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> and <a href="#hist-image-histogram"><span class=
"chunk">hIST</span></a> chunks as well, for compatibility with
decoders that do not recognize the <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> chunk.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "12Interlacing" to preserve incoming links to it -->
<section id="12Interlacing">
<h2>Interlacing</h2>

<p>This specification defines two interlace methods,
one of which is no interlacing. Interlacing provides a convenient
basis from which decoders can progressively display an image, as
described in 13.8: <a href="#interlacing-and-progressive-display"><span class=
"xref">Interlacing and progressive display</span></a>.</p>
</section>

<!-- Maintain a fragment named "12Filter-selection" to preserve incoming links to it -->
<section id="12Filter-selection">
<h2>Filter selection</h2>

<p>For images of colour type 3 (indexed-colour), filter type 0
(None) is usually the most effective. Colour images with 256 or
fewer colours should almost always be stored in indexed-colour
format; truecolour format is likely to be much larger.</p>

<p>Filter type 0 is also recommended for images of bit depths
less than 8. For low-bit-depth greyscale images, in rare cases,
better compression may be obtained by first expanding the image
to 8-bit representation and then applying filtering.</p>

<p>For truecolour and greyscale images, any of the five filters
may prove the most effective. If an encoder uses a fixed filter,
the Paeth filter is most likely to be the best.</p>

<p>For best compression of truecolour and greyscale images,
the recommended approach is
adaptive filtering in which a filter is
chosen for each scanline. The following simple heuristic has
performed well in early tests: compute the output scanline using
all five filters, and select the filter that gives the smallest
sum of absolute values of outputs. (Consider the output bytes as
signed differences for this test.) This method usually
outperforms any single fixed filter choice. However, it is likely
that better heuristics will be found as more experience is
gained with PNG.</p>

<p>Filtering according to these recommendations is effective in
conjunction with either of the two interlace methods defined in
this specification.</p>
</section>

<!-- Maintain a fragment named "12Compression" to preserve incoming links to it -->
<section id="12Compression">
<h2>Compression</h2>

<p>The encoder may divide the compressed datastream into <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a> chunks however it
wishes. (Multiple <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks are allowed so that encoders may
work in a fixed amount of memory; typically the chunk size will
correspond to the encoder's buffer size.) A PNG datastream in
which each <a href="#idat-image-data"><span class="chunk">IDAT</span></a>
chunk contains only one data byte is valid, though remarkably
wasteful of space. (Zero-length <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks are also valid, though even more
wasteful.)</p>
</section>

<!-- Maintain a fragment named "12Text-chunk-processing" to preserve incoming links to it -->
<section id="12Text-chunk-processing">
<h2>Text chunk
processing</h2>

<p>A nonempty keyword shall be provided for each text chunk. The
generic keyword "Comment" can be used if no better description of
the text is available. If a user-supplied keyword is used,
encoders should check that it meets the restrictions on
keywords.</p>

<p>For the <a href="#text-textual-data"><span class="chunk">tEXt</span></a>
and <a href="#ztxt-compressed-textual-data"><span class="chunk">zTXt</span></a> chunks,
PNG text strings are expected to use the Latin-1 character set.
Encoders should avoid storing characters that are not defined in
Latin-1, and should provide character code remapping if the local
system's character set is not Latin-1. The <a href=
"#itxt-international-textual-data"><span class="chunk">iTXt</span></a> chunk provides
support for international text, represented using the UTF-8
encoding of UCS. Encoders should discourage the creation of
single lines of text longer than 79 characters, in order to
facilitate easy reading. It is recommended that text items less
than 1024 bytes in size should be output using uncompressed
text chunks. It is
recommended that the basic title and author keywords be output
using uncompressed text chunks.
Placing large text chunks after the
image data (after the <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks) can speed up image display in
some situations, as the decoder will decode the image data first.
It is recommended that small text chunks, such as the image
title, appear before the <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "12Chunk-processing" to preserve incoming links to it -->
<section id="12Chunk-processing">
<h2>Chunking</h2>

<!-- Maintain a fragment named "12Use-of-private-chunks" to preserve incoming links to it -->
<section id="12Use-of-private-chunks">
<h2>Use of private
chunks</h2>

<p>
Chunk types are classified as public or private depending on bit 5
of the second byte (the private bit), and classified as critical or
ancillary depending on bit 5 of the first byte (the ancillary bit).
See 5.4: <a href=
"#chunk-naming-conventions"><span class="xref">Chunk naming
conventions</span></a>.
</p>

<p>Applications can use PNG private chunks to carry information
that need not be understood by other applications. Such chunks
shall be given private chunk types,
to ensure that they can never conflict
with any future public chunk definition. However, there is no
guarantee that some other application will not use the same
private chunk type. If a private chunk type is used, it is
prudent to store additional identifying information at the
beginning of the chunk data.</p>

<p>An ancillary chunk type, not a critical chunk type, should be
used for all private chunks that store information that is not
absolutely essential to view the image. Creation of private
critical chunks is discouraged because PNG datastreams containing
such chunks are not portable. Such chunks should not be used in
publicly available software or datastreams. If private critical
chunks are essential for an application, it is recommended that
one appear near the start of the datastream, so that a standard
decoder need not read very far before discovering that it cannot
handle the datastream.</p>

<p>If other organizations need to understand a new chunk type, it
should be submitted to the Registration Authority (see 4.9: <a
href="#extension-and-registration"><span class="xref">Extension and
registration</span></a>). A proposed public chunk type
shall not be used in publicly available software or
datastreams until registration has been approved.</p>

<p>If an ancillary chunk contains textual information that might
be of interest to a human user, a special chunk type should not
be defined for it. Instead a <a href="#text-textual-data"><span class=
"chunk">tEXt</span></a> chunk should be used and a suitable
keyword defined. The information will then be available to other
users.</p>

<p>Keywords in <a href="#text-textual-data"><span class=
"chunk">tEXt</span></a> chunks should be reasonably
self-explanatory, since the aim is to let other users understand
what the chunk contains. If generally useful, new keywords should
be registered with the Registration Authority (see 4.9: <a href=
"#extension-and-registration"><span class="xref">Extension and
registration</span></a>). However, it is permissible to use
keywords without registering them first.</p>
</section>

<!-- Maintain a fragment named "12Private-type-and-method-codes" to preserve incoming links to it -->
<section id="12Private-type-and-method-codes">
<h2>Private
type and method codes</h2>

<p>This specification defines the meaning of only some of the
possible values of some fields. For example, only compression
method 0 and filter types 0 through 4 are defined in this
International Standard. Numbers greater than 127 shall be used
when inventing experimental or private definitions of values for
any of these fields. Numbers below 128 are reserved for possible
public extensions of this specification through future
standardization (see 4.9 <a href="#extension-and-registration"><span
class="xref">Extension and registration</span></a>). The use of
private type codes may render a datastream unreadable by standard
decoders. Such codes are strongly discouraged except for
experimental purposes, and should not appear in publicly
available software or datastreams.</p>
</section>

<!-- Maintain a fragment named "12Ancillary" to preserve incoming links to it -->
<section id="12Ancillary">
<h2>Ancillary chunks</h2>

<p>All ancillary chunks are optional, encoders need not write
them. However, encoders are encouraged to write the standard
ancillary chunks when the information is available.</p>
</section>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "13Decoders" to preserve incoming links to it -->
<section id="13Decoders">
<h2>PNG decoders and viewers</h2>

<!-- Maintain a fragment named "13Introduction" to preserve incoming links to it -->
<section class="introductory" id="13Introduction">
<p>This clause gives some requirements and recommendations for PNG
decoder behaviour and viewer behaviour. A viewer presents the
decoded PNG image to the user. Since viewer and decoder behaviour
are closely connected, decoders and viewers are treated together
here. The only absolute requirement on a PNG decoder is that it
successfully reads any datastream conforming to the format
specified in the preceding chapters. However, best results will
usually be achieved by following these additional
recommendations.</p>

<p>PNG decoders shall support all valid combinations of bit
depth, colour type, compression method, filter method, and
interlace method that are explicitly defined in this
International Standard.</p>

<p>All ancillary chunks are optional; decoders may ignore them.
However, decoders are encouraged to interpret these chunks when
appropriate and feasible.</p>
</section>

<section>

<!-- Maintain a fragment named "13Decoders.Errors" to preserve incoming links to it -->
<h2 name="13Decoders.Errors">Error handling</h2>
<p>Errors in a PNG datastream will fall into two general classes,
transmission errors and syntax errors (see <a href=
"#error-handling"><span class="xref">4.8 Error
handling</span></a>).</p>

<p>Examples of transmission errors are transmission in "text" or
"ascii" mode, in which byte codes 13 and/or 10 may be added,
removed, or converted throughout the datastream; unexpected
termination, in which the datastream is truncated; or a physical
error on a storage device, in which one or more blocks (typically
512 bytes each) will have garbled or random values. Some examples
of syntax errors are an invalid value for a row filter, an
invalid compression method, an invalid chunk length, the absence
of a <a href="#plte-palette"><span class="chunk">PLTE</span></a> chunk
before the first <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunk in an indexed image, or the
presence of multiple <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> chunks. A PNG decoder should handle
errors as follows:</p>

<!-- <ol start="1"> --><ol>
<li>Detect errors as early as possible using the PNG signature
bytes and CRCs on each chunk. Decoders should verify that all
eight bytes of the PNG signature are correct. A decoder can
have additional confidence in the datastream's integrity if the
next eight bytes begin an <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> chunk with the correct chunk length. A
CRC should be checked before processing the chunk data. Sometimes
this is impractical, for example when a streaming PNG decoder is
processing a large <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunk. In this case the CRC should be
checked when the end of the chunk is reached.</li>

<li>Recover from an error, if possible; otherwise fail
gracefully. Errors that have little or no effect on the
processing of the image may be ignored, while those that affect
critical data shall be dealt with in a manner appropriate to the
application.</li>

<li>Provide helpful messages describing errors, including
recoverable errors.</li>
</ol>

<p>Three classes of PNG chunks are relevant to this philosophy.
For the purposes of this classification, an "unknown chunk" is
either one whose type was genuinely unknown to the decoder's
author, or one that the author chose to treat as unknown, because
default handling of that chunk type would be sufficient for the
program's purposes. Other chunks are called "known chunks". Given
this definition, the three classes are as follows:</p>

<!-- <ol start="4"> --><ol>
<li>known chunks, which necessarily includes all of the critical
chunks defined in this specification (<a href=
"#ihdr-image-header"><span class="chunk">IHDR</span></a>, <a href=
"#plte-palette"><span class="chunk">PLTE</span></a>, <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a>, <a href=
"#iend-image-trailer"><span class="chunk">IEND</span></a>)</li>

<li>unknown critical chunks (bit 5 of the first byte of the chunk
type is 0)</li>

<li>unknown ancillary chunks (bit 5 of the first byte of the
chunk type is 1)</li>
</ol>

<p>See 5.4: <a href="#chunk-naming-conventions"><span class=
"xref">Chunk naming conventions</span></a> for a full description
of chunk naming conventions.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<p>PNG chunk types are marked "critical" or "ancillary" according
to whether the chunks are critical for the purpose of extracting
a viewable image (as with <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a>, <a href="#plte-palette"><span class=
"chunk">PLTE</span></a>, and <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a>) or critical to understanding the
datastream structure (as with <a href="#iend-image-trailer"><span class=
"chunk">IEND</span></a>). This is a specific kind of criticality
and one that is not necessarily relevant to every conceivable
decoder. For example, a program whose sole purpose is to extract
text annotations (for example, copyright information) does not
require a viewable image. Another decoder might consider the <a
href="#trns-transparency"><span class="chunk">tRNS</span></a> and <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> chunks essential to
its proper execution.</p>

<p>Syntax errors always involve known chunks because syntax
errors in unknown chunks cannot be detected. The PNG decoder has
to determine whether a syntax error is fatal (unrecoverable) or
not, depending on its requirements and the situation. For
example, most decoders can ignore an invalid <a href=
"#iend-image-trailer"><span class="chunk">IEND</span></a> chunk; a
text-extraction program can ignore the absence of <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a>; an image viewer
cannot recover from an empty <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk in an indexed image but it can
ignore an invalid <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk in a truecolour image; and a
program that extracts the alpha channel can ignore an invalid <a
href="#gama-image-gamma"><span class="chunk">gAMA</span></a> chunk, but may
consider the presence of two <a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> chunks to be a fatal error. Anomalous
situations other than syntax errors shall be treated as
follows:</p>

<!-- <ol start="7"> --><ol>
<li>Encountering an unknown ancillary chunk is never an error.
The chunk can simply be ignored.</li>

<li>Encountering an unknown critical chunk is a fatal condition
for any decoder trying to extract the image from the datastream.
A decoder that ignored a critical chunk could not know whether
the image it extracted was the one intended by the encoder.</li>

<li>A PNG signature mismatch, a CRC mismatch, or an unexpected
end-of-stream indicates a corrupted datastream, and may be
regarded as a fatal error. A decoder could try to salvage
something from the datastream, but the extent of the damage will
not be known.</li>
</ol>

<p>When a fatal condition occurs, the decoder should fail
immediately, signal an error to the user if appropriate, and
optionally continue displaying any image data already visible to
the user (i.e. "fail gracefully"). The application as a whole
need not terminate.</p>

<p>When a non-fatal error occurs, the decoder should signal a
warning to the user if appropriate, recover from the error, and
continue processing normally.</p>

<p>Decoders that do not compute CRCs should interpret apparent
syntax errors as indications of corruption (see also 13.3: <a
href="#error-checking"><span class="xref">Error
checking</span></a>).</p>

<p>Errors in compressed chunks (<a href="#idat-image-data"><span class=
"chunk">IDAT</span></a>, <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a>, <a href="#itxt-international-textual-data"><span class=
"chunk">iTXt</span></a>, <a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a>) could lead to buffer overruns.
Implementors of deflate decompressors should guard against this
possibility.</p>
</section>

<!-- Maintain a fragment named "13Error-checking" to preserve incoming links to it -->
<section id="13Error-checking">
<h2>Error checking</h2>

<p>The PNG error handling philosophy is described in 13.2: <a
href="#error-handling-1"><span class="xref">Error
handling</span></a>.</p>

<p>Unknown chunk types shall be handled as described in 5.4: <a
href="#chunk-naming-conventions"><span class="xref">Chunk naming
conventions</span></a>. An unknown chunk type is <strong>not</strong> to
be treated as an error unless it is a critical chunk.</p>

<p>The chunk type can be checked for plausibility by seeing
whether all four bytes are in the range codes 65-90 and 97-122
(decimal); note that this need be done only for unrecognized
chunk types. If the total datastream size is known (from file
system information, HTTP protocol, etc), the chunk length can be
checked for plausibility as well. If CRCs are not checked,
dropped/added data bytes or an erroneous chunk length can cause
the decoder to get out of step and misinterpret subsequent data
as a chunk header.</p>

<p>For known-length chunks, such as <a href="#ihdr-image-header"><span
class="chunk">IHDR</span></a>, decoders should treat an
unexpected chunk length as an error. Future extensions to this
specification will not add new fields to existing chunks;
instead, new chunk types will be added to carry new
information.</p>

<p>Unexpected values in fields of known chunks (for example, an
unexpected compression method in the <a href="#ihdr-image-header"><span
class="chunk">IHDR</span></a> chunk) shall be checked for and
treated as errors. However, it is recommended that unexpected
field values be treated as fatal errors only in <strong>critical</strong>
chunks. An unexpected value in an ancillary chunk can be handled
by ignoring the whole chunk as though it were an unknown chunk
type. (This recommendation assumes that the chunk's CRC has been
verified. In decoders that do not check CRCs, it is safer to
treat any unexpected value as indicating a corrupted
datastream.)</p>

<p>Standard PNG images shall be compressed with compression
method 0. The compression method field of the <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> chunk is
provided for possible future standardization or proprietary
variants. Decoders shall check this byte and report an error if
it holds an unrecognized code. See clause&#160;10: <a href=
"#compression-1"><span class="xref">Compression</span></a> for
details.</p>
</section>

<!-- Maintain a fragment named "13Security-considerations" to preserve incoming links to it -->
<section id="13Security-considerations">
<h2>Security
considerations</h2>

<p>A PNG datastream is composed of a collection of explicitly
typed chunks. Chunks whose contents are defined by the
specification could actually contain anything, including
malicious code. But there is no known risk that such malicious
code could be executed on the recipient's computer as a result of
decoding the PNG image.</p>

<p>The possible security risks associated with future chunk types
cannot be specified at this time. Security issues will be
considered by the Registration Authority when evaluating chunks
proposed for registration as public chunks. There is no
additional security risk associated with unknown or unimplemented
chunk types, because such chunks will be ignored, or at most be
copied into another PNG datastream.</p>

<p>The <a href="#itxt-international-textual-data"><span class="chunk">iTXt</span></a>, <a
href="#text-textual-data"><span class="chunk">tEXt</span></a>, and <a href=
"#ztxt-compressed-textual-data"><span class="chunk">zTXt</span></a> chunks contain keywords
and data
that are meant to be displayed as plain text. The <a href=
"#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> and <a href=
"#splt-suggested-palette"><span class="chunk">sPLT</span></a> chunks contain
keywords that are meant to be displayed as plain text. It is
possible that if the decoder displays such text without filtering
out control characters, especially the ESC (escape) character,
certain systems or terminals could behave in undesirable and
insecure ways. It is recommended that decoders filter out control
characters to avoid this risk; see 13.5.3: <a href=
"#text-chunk-processing-1"><span class="xref">Text chunk
processing</span></a>.</p>

<p>Every chunk begins with a length field, which makes it easier
to write decoders that are invulnerable to fraudulent chunks that
attempt to overflow buffers. The CRC at the end of every chunk
provides a robust defence against accidentally corrupted data.
The PNG signature bytes provide early detection of common file
transmission errors.</p>

<p>A decoder that fails to check CRCs could be subject to data
corruption. The only likely consequence of such corruption is
incorrectly displayed pixels within the image. Worse things might
happen if the CRC of the <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> chunk is not checked and the width or
height fields are corrupted. See 13.3: <a href=
"#error-checking"><span class="xref">Error
checking</span></a>.</p>

<p>A poorly written decoder might be subject to buffer overflow,
because chunks can be extremely large, up to 2<sup>31</sup>-1
bytes long. But properly written decoders will handle large
chunks without difficulty.</p>
</section>

<!-- Maintain a fragment named "13Chunking" to preserve incoming links to it -->
<section id="13Chunking">
<h2>Chunking</h2>

<p>Decoders shall recognize chunk types by a simple four-byte
literal comparison; it is incorrect to perform case conversion on
chunk types. A decoder encountering an unknown chunk in which the
ancillary bit is 1 may safely ignore the chunk and proceed to
display the image. A decoder trying to extract the image, upon
encountering an unknown chunk in which the ancillary bit is 0,
indicating a critical chunk, shall indicate to the user that the
image contains information it cannot safely interpret.</p>

<p>(Decoders should not flag an error if the reserved bit is set
to 1, however, as some future version of the PNG specification
could define a meaning for this bit. It is sufficient to treat a
chunk with this bit set in the same way as any other unknown
chunk type.)</p>
</section>

<!-- Maintain a fragment named "13Pixel-dimensions" to preserve incoming links to it -->
<section id="13Pixel-dimensions">
<h2>Pixel dimensions</h2>

<p>Non-square pixels can be represented (see 11.3.5.3: <a href=
"#phys-physical-pixel-dimensions"><span class="xref"><span class="chunk">pHYs</span>
Physical pixel dimensions</span></a>), but viewers are not
required to account for them; a viewer can present any PNG
datastream as though its pixels are square.</p>

<p>Where the pixel aspect ratio of the display differs from the
aspect ratio of the physical pixel dimensions defined in the PNG
datastream, viewers are strongly encouraged to rescale images for
proper display.</p>

<p>When the <a href="#phys-physical-pixel-dimensions"><span class="xref"><span class=
"chunk">pHYs</span></span></a> chunk has a unit specifier of 0
(unit is unknown), the behaviour of a decoder may depend on the
ratio of the two pixels-per-unit values, but should not depend on
their magnitudes. For example, a <a href="#phys-physical-pixel-dimensions"><span class=
"xref"><span class="chunk">pHYs</span></span></a> chunk
containing <tt>(ppuX, ppuY, unit) = (2, 1, 0)</tt> is equivalent
to one containing <tt>(1000, 500, 0)</tt>; both are equally valid
indications that the image pixels are twice as tall as they are
wide.</p>

<p>One reasonable way for viewers to handle a difference between
the pixel aspect ratios of the image and the display is to expand
the image either horizontally or vertically, but not both. The
scale factors could be obtained using the following
floating-point calculations:</p>

<pre>
<tt>image_ratio = pHYs_ppuY / pHYs_ppuX
display_ratio = display_ppuY / display_ppuX
scale_factor_X = max(1.0, image_ratio/display_ratio)
scale_factor_Y = max(1.0, display_ratio/image_ratio)</tt>
</pre>

<p>Because other methods such as maintaining the image area are
also reasonable, and because ignoring the <a href="#phys-physical-pixel-dimensions"><span
class="xref"><span class="chunk">pHYs</span></span></a> chunk is
permissible, authors should not assume that all viewing
applications will use this scaling method.</p>

<p>As well as making corrections for pixel aspect ratio, a viewer
may have reasons to perform additional scaling both horizontally
and vertically. For example, a viewer might want to shrink an
image that is too large to fit on the display, or to expand
images sent to a high-resolution printer so that they appear the
same size as they did on the display.</p>
</section>

<!-- Maintain a fragment named "13Text-chunk-processing" to preserve incoming links to it -->
<section id="13Text-chunk-processing">
<h2>Text chunk
processing</h2>

<p>If practical, PNG decoders should have a way to display to the
user all the <a href="#itxt-international-textual-data"><span class=
"chunk">iTXt</span></a>, <a href="#text-textual-data"><span class=
"chunk">tEXt</span></a>, and <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a> chunks found in the datastream. Even if
the decoder does not recognize a particular text keyword, the
user might be able to understand it.</p>

<p>When processing <a href="#text-textual-data"><span class=
"chunk">tEXt</span></a> and <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a> chunks, decoders could encounter
characters other than those permitted. Some can be safely
displayed (e.g., TAB, FF, and CR, decimal 9, 12, and 13,
respectively), but others, especially the ESC character (decimal
27), could pose a security hazard (because unexpected actions may
be taken by display hardware or software). Decoders should not
attempt to directly display any non-Latin-1 characters (except
for newline and perhaps TAB, FF, CR) encountered in a <a href=
"#text-textual-data"><span class="chunk">tEXt</span></a> or <a href=
"#ztxt-compressed-textual-data"><span class="chunk">zTXt</span></a> chunk. Instead,
they should be ignored or displayed in a visible notation such as
"<tt>\</tt>nnn". See 13.4: <a href=
"#security-considerations"><span class="xref">Security
considerations</span></a>.</p>

<p>Even though encoders are recommended to represent newlines as
linefeed (decimal 10), it is recommended that decoders not rely
on this; it is best to recognize all the common newline
combinations (CR, LF, and CR-LF) and display each as a single
newline. TAB can be expanded to the proper number of spaces
needed to arrive at a column multiple of 8.</p>

<p>Decoders running on systems with non-Latin-1 character set
encoding should provide character code remapping so that Latin-1
characters are displayed correctly. Some systems may not provide
all the characters defined in Latin-1. Mapping unavailable
characters to a visible notation such as "<tt>\</tt>nnn" is a
good fallback. Character codes 127-255 should be displayed only
if they are printable characters on the decoding system. Some
systems may interpret such codes as control characters; for
security, decoders running on such systems should not display
such characters literally.</p>

<p>Decoders should be prepared to display text chunks that
contain any number of printing characters between newline
characters, even though it is recommended that encoders avoid
creating lines in excess of 79 characters.</p>
</section>

<!-- Maintain a fragment named "13Decompression" to preserve incoming links to it -->
<section id="13Decompression">
<h2>Decompression</h2>

<p>The compression technique used in this specification
does not require the entire compressed datastream to be available
before decompression can start. Display can therefore commence
before the entire decompressed datastream is available. It is
extremely unlikely that any general purpose compression methods
in future versions of this specification will not have
this property.</p>

<p>It is important to emphasize that <a href="#idat-image-data"><span
class="chunk">IDAT</span></a> chunk boundaries have no semantic
significance and can occur at any point in the compressed
datastream. There is no required correlation between the
structure of the image data (for example, scanline boundaries) and
deflate block boundaries or <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunk boundaries. The complete image data
is represented by a single zlib datastream that is stored in some
number of <a href="#idat-image-data"><span class="chunk">IDAT</span></a>
chunks; a decoder that assumes any more than this is incorrect.
Some encoder implementations may emit datastreams in which some
of these structures are indeed related, but decoders cannot rely
on this.</p>
</section>

<!-- Maintain a fragment named "13Filtering" to preserve incoming links to it -->
<section id="13Filtering">
<h2>Filtering</h2>

<p>To reverse the effect of a filter, the decoder may need
to use the decoded values of the prior pixel on the same line,
the pixel immediately above the current pixel on the prior line,
and the pixel just to the left of the pixel above. This implies
that at least one scanline's worth of image data needs to be
stored by the decoder at all times. Even though some filter types
do not refer to the prior scanline, the decoder will always need
to store each scanline as it is decoded, since the next scanline
might use a filter type that refers to it.</p>
</section>

<!-- Maintain a fragment named "13Progressive-display" to preserve incoming links to it -->
<section id="13Progressive-display">
<h2>Interlacing and
progressive display</h2>

<p>Decoders are required to be able to read interlaced images. If
the reference image contains fewer than five columns or fewer
than five rows, some passes will be empty. Encoders and decoders
shall handle this case correctly. In particular, filter type
bytes are associated only with nonempty scanlines; no filter type
bytes are present in an empty reduced image.</p>

<p>When receiving images over slow transmission links, viewers
can improve perceived performance by displaying interlaced images
progressively. This means that as each reduced image is received,
an approximation to the complete image is displayed based on the
data received so far. One simple yet pleasing effect can be
obtained by expanding each received pixel to fill a rectangle
covering the yet-to-be-transmitted pixel positions below and to
the right of the received pixel. This process can be described by
the following ISO C code [[ISO 9899]]:</p>

<pre>
/*
    variables declared and initialized elsewhere in the code:
        height, width
    functions or macros defined elsewhere in the code:
        visit(), min()
 */

int starting_row[7]  = { 0, 0, 4, 0, 2, 0, 1 };
int starting_col[7]  = { 0, 4, 0, 2, 0, 1, 0 };
int row_increment[7] = { 8, 8, 8, 4, 4, 2, 2 };
int col_increment[7] = { 8, 8, 4, 4, 2, 2, 1 };
int block_height[7]  = { 8, 8, 4, 4, 2, 2, 1 };
int block_width[7]   = { 8, 4, 4, 2, 2, 1, 1 };

int pass;
long row, col;

pass = 0;
while (pass &lt; 7)
{
    row = starting_row[pass];
    while (row &lt; height)
    {
        col = starting_col[pass];
        while (col &lt; width)
        {
            visit(row, col,
                  min(block_height[pass], height - row),
                  min(block_width[pass], width - col));
            col = col + col_increment[pass];
        }
        row = row + row_increment[pass];
    }
    pass = pass + 1;
}
</pre>

<p>The function <tt>visit(row,column,height,width)</tt> obtains
the next transmitted pixel and paints a rectangle of the
specified height and width, whose upper-left corner is at the
specified row and column, using the colour indicated by the
pixel. Note that row and column are measured from 0,0 at the
upper left corner.</p>

<p>If the viewer is merging the received image with a background
image, it may be more convenient just to paint the received pixel
positions (the <tt>visit()</tt> function sets only the pixel at the
specified row and column, not the whole rectangle). This produces
a "fade-in" effect as the new image gradually replaces the old.
An advantage of this approach is that proper alpha or
transparency processing can be done as each pixel is replaced.
Painting a rectangle as described above will overwrite
background-image pixels that may be needed later, if the pixels
eventually received for those positions turn out to be wholly or
partially transparent. This is a problem only if the background
image is not stored anywhere offscreen.</p>
</section>

<!-- Maintain a fragment named "13Truecolour-image-handling" to preserve incoming links to it -->
<section id="13Truecolour-image-handling">
<h2>Truecolour image
handling</h2>

<p>To achieve PNG's goal of universal interchangeability,
decoders shall accept all types of PNG image: indexed-colour,
truecolour, and greyscale. Viewers running on indexed-colour
display hardware need to be able to reduce truecolour images to
indexed-colour for viewing. This process is called "colour
quantization".</p>

<p>A simple, fast method for colour quantization is to reduce the
image to a fixed palette. Palettes with uniform colour spacing
("colour cubes") are usually used to minimize the per-pixel
computation. For photograph-like images, dithering is recommended
to avoid ugly contours in what should be smooth gradients;
however, dithering introduces graininess that can be
objectionable.</p>

<p>The quality of rendering can be improved substantially by
using a palette chosen specifically for the image, since a colour
cube usually has numerous entries that are unused in any
particular image. This approach requires more work, first in
choosing the palette, and second in mapping individual pixels to
the closest available colour. PNG allows the encoder to supply
suggested palettes, but not all encoders will do so, and the
suggested palettes may be unsuitable in any case (they may have
too many or too few colours). Therefore, high-quality viewers
will need to have a palette selection routine at hand. A large
lookup table is usually the most feasible way of mapping
individual pixels to palette entries with adequate speed.</p>

<p>Numerous implementations of colour quantization are available.
The PNG sample implementation, libpng (<a href=
"http://www.libpng.org/pub/png/libpng.html"><code>http://www.libpng.org/pub/png/libpng.html</code></a>),
includes code for the purpose.</p>
</section>

<!-- Maintain a fragment named "13Sample-depth-rescaling" to preserve incoming links to it -->
<section id="13Sample-depth-rescaling">
<h2>Sample depth
rescaling</h2>

<p>Decoders may wish to scale PNG data to a lesser sample depth
(data precision) for display. For example, 16-bit data will need
to be reduced to 8-bit depth for use on most present-day display
hardware. Reduction of 8-bit data to 5-bit depth is also
common.</p>

<p>The most accurate scaling is achieved by the linear
equation</p>

<p><tt>output = floor((input * MAXOUTSAMPLE / MAXINSAMPLE) +
0.5)</tt></p>

<p>where</p>

<p><tt>MAXINSAMPLE = (2<sup>sampledepth</sup>)-1</tt><br class="xhtml" />
 <tt>MAXOUTSAMPLE = (2<sup>desired_sampledepth</sup>)-1</tt></p>

<p>A slightly less accurate conversion is achieved by simply
shifting right by <tt>(sampledepth - desired_sampledepth)</tt>
places. For example, to reduce 16-bit samples to 8-bit, the
low-order byte can be discarded. In many situations the shift
method is sufficiently accurate for display purposes, and it is
certainly much faster. (But if gamma correction is being done,
sample rescaling can be merged into the gamma correction lookup
table, as is illustrated in 13.13: <a href=
"#decoder-gamma-handling"><span class="xref">Decoder gamma
handling</span></a>.)</p>

<p>If the decoder needs to scale samples up (for example, if the
frame buffer has a greater sample depth than the PNG image), it
should use linear scaling or left-bit-replication as described in
12.5: <a href="#sample-depth-scaling-1"><span class="xref">Sample
depth scaling</span></a>.</p>

<p>When an <a href="#sbit-significant-bits"><span class="chunk">sBIT</span></a>
chunk is present, the reference image data can be recovered by
shifting right to the sample depth specified by <a href=
"#sbit-significant-bits"><span class="chunk">sBIT</span></a>. Note that linear
scaling will not necessarily reproduce the original data, because
the encoder is not required to have used linear scaling to scale
the data up. However, the encoder is required to have used a
method that preserves the high-order bits, so shifting always
works. This is the only case in which shifting might be said to
be more accurate than linear scaling. A decoder need not pay
attention to the <a href="#sbit-significant-bits"><span class=
"chunk">sBIT</span></a> chunk; the stored image is a valid PNG
datastream of the sample depth indicated by the <a href=
"#ihdr-image-header"><span class="chunk">IHDR</span></a> chunk; however,
using <a href="#sbit-significant-bits"><span class="chunk">sBIT</span></a> to
recover the original samples before scaling them to suit the
display often yields a more accurate display than ignoring <a
href="#sbit-significant-bits"><span class="chunk">sBIT</span></a>.</p>

<p>When comparing pixel values to <a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> chunk values to detect transparent
pixels, the comparison shall be done exactly. Therefore,
transparent pixel detection shall be done before reducing sample
precision.</p>
</section>

<!-- Maintain a fragment named "13Decoder-gamma-handling" to preserve incoming links to it -->
<section id="13Decoder-gamma-handling">
<h2>Decoder gamma
handling</h2>

<p>See Annex C: <a href="#C-GammaAppendix"><span class=
"xref">Gamma and chromaticity</span></a> for a brief introduction
to gamma issues.</p>

<p>Viewers capable of full colour management  will perform more
sophisticated calculations than those described here.</p>

<p>For an image display program to produce correct tone
reproduction, it is necessary to take into account the
relationship between samples and display output, and the transfer
function of the display system. This can be done by
calculating:</p>

<p><tt>sample = integer_sample / (2<sup>sampledepth</sup> -
1.0)<br class="xhtml" />
 display_output = sample<sup>1.0/gamma</sup><br class="xhtml" />
 display_input = inverse_display_transfer(display_output)<br class="xhtml" />
 framebuf_sample = floor((display_input *
MAX_FRAMEBUF_SAMPLE)+0.5)</tt></p>

<p>where <tt>integer_sample</tt> is the sample value from the
datastream, <tt>framebuf_sample</tt> is the value to write into
the frame buffer, and <tt>MAX_FRAMEBUF_SAMPLE</tt> is the maximum
value of a frame buffer sample (255 for 8-bit, 31 for 5-bit,
etc). The first line converts an integer sample into a normalized
floating point value (in the range 0.0 to 1.0), the second
converts to a value proportional to the desired display output
intensity, the third accounts for the display system's transfer
function, and the fourth converts to an integer frame buffer
sample. Zero raised to any positive power is zero.</p>

<p>A step could be inserted between the second and third to
adjust <tt>display_output</tt> to account for the difference
between the actual viewing conditions and the reference viewing
conditions. However, this adjustment requires accounting for
veiling glare, black mapping, and colour appearance models, none
of which can be well approximated by power functions. Such
calculations are not described here. If viewing conditions are
ignored, the error will usually be small.</p>

<p>The display transfer function can typically be approximated by
a power function with exponent <tt>display_exponent</tt>, in
which case the second and third lines can be merged into:</p>

<p><tt>display_input = sample<sup>1.0/(gamma *
display_exponent)</sup> =
sample<sup>decoding_exponent</sup></tt></p>

<p>so as to perform only one power calculation. For colour
images, the entire calculation is performed separately for R, G,
and B values.</p>

<p>The value of gamma can be taken directly from the <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> chunk.
Alternatively, an application may wish to allow the user to
adjust the appearance of the displayed image by influencing the
value of gamma. For example, the user could manually set a
parameter <tt>user_exponent</tt> which defaults to 1.0, and the
application could set:</p>

<pre>
<tt>gamma = gamma_from_file / user_exponent
decoding_exponent = 1.0 / (gamma * display_exponent)
   = user_exponent / (gamma_from_file * display_exponent)</tt>
</pre>

<p>The user would set <tt>user_exponent</tt> greater than 1 to
darken the mid-level tones, or less than 1 to lighten them.</p>

<p>A <a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a> chunk containing zero is
meaningless but could appear by mistake.
Decoders should ignore it,
and editors may discard it and issue a warning to the user.</p>

<p>It is <strong>not</strong> necessary to perform a transcendental
mathematical computation for every pixel. Instead, a lookup table
can be computed that gives the correct output value for every
possible sample value. This requires only 256 calculations per
image (for 8-bit accuracy), not one or three calculations per
pixel. For an indexed-colour image, a one-time correction of the
palette is sufficient, unless the image uses transparency and is
being displayed against a nonuniform background.</p>

<p>If floating-point calculations are not possible, gamma
correction tables can be computed using integer arithmetic and a
precomputed table of logarithms. Example code appears in [[PNG-EXTENSIONS]].</p>

<p>When the incoming image has unknown gamma (<a href=
"#gama-image-gamma"><span class="chunk">gAMA</span></a>, <a href=
"#srgb-standard-colour-space"><span class="chunk">sRGB</span></a>, and <a href=
"#iccp-embedded-icc-profile"><span class="chunk">iCCP</span></a> all absent),
standalone image viewers should
choose
a likely default gamma value, but allow the user to select a new
one if the result proves too dark or too light. The default gamma
may depend on other knowledge about the image, for example
whether it came from the Internet or from the local system.
For consistency, viewers for document formats such as HTML,
or vector graphics such as SVG, should treat embedded or
linked PNG images with unknown gamma in the same way
that they treat other untagged images.
</p>

<p>In practice, it is often difficult to determine what value of
display exponent should be used. In systems with no built-in
gamma correction, the display exponent is determined entirely by
the CRT. A display exponent of 2.2 should be used unless detailed
calibration measurements are available for the particular CRT
used.</p>

<p>Many modern frame buffers have lookup tables that are used to
perform gamma correction, and on these systems the display
exponent value should be the exponent of the lookup table and CRT
combined. It may not be possible to find out what the lookup
table contains from within the viewer application, in which case
it may be necessary to ask the user to supply the display
system's exponent value. Unfortunately, different manufacturers
use different ways of specifying what should go into the lookup
table, so interpretation of the system "gamma" value is
system-dependent.</p>

<p>The response of real displays is actually more complex than
can be described by a single number (the display exponent). If
actual measurements of the monitor's light output as a function
of voltage input are available, the third and fourth lines of the
computation above can be replaced by a lookup in these
measurements, to find the actual frame buffer value that most
nearly gives the desired brightness.</p>
</section>

<!-- Maintain a fragment named "13Decoder-colour-handling" to preserve incoming links to it -->
<section id="13Decoder-colour-handling">
<h2>Decoder colour
handling</h2>

<p>See Annex C: <a href="#C-GammaAppendix"><span class=
"xref">Gamma and chromaticity</span></a> for references to colour
issues.</p>

<p>In many cases, the image data in PNG datastreams will be
treated as device-dependent RGB values and displayed without
modification (except for appropriate gamma correction). This
provides the fastest display of PNG images. But unless the viewer
uses exactly the same display hardware as that used by the author
of the original image, the colours will not be exactly the same
as those seen by the original author, particularly for darker or
near-neutral colours. The <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk provides information that allows
closer colour matching than that provided by gamma correction
alone.</p>

<p>The <a href="#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> data
can be used to transform the image data from RGB to XYZ and
thence into a perceptually linear colour space such as CIE LAB.
The colours can be partitioned to generate an optimal palette,
because the geometric distance between two colours in CIE LAB is
strongly related to how different those colours appear (unlike,
for example, RGB or XYZ spaces). The resulting palette of
colours, once transformed back into RGB colour space, could be
used for display or written into a <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk.</p>

<p>Decoders that are part of image processing applications might
also transform image data into CIE LAB space for analysis.</p>

<p>In applications where colour fidelity is critical, such as
product design, scientific visualization, medicine, architecture,
or advertising, PNG decoders can transform the image data from
source RGB to the display RGB space of the monitor used to view
the image. This involves calculating the matrix to go from source
RGB to XYZ and the matrix to go from XYZ to display RGB, then
combining them to produce the overall transformation. The PNG
decoder is responsible for implementing gamut mapping.</p>

<p>Decoders running on platforms that have a Colour Management
System (CMS) can pass the image data, <a href="#gama-image-gamma"><span
class="chunk">gAMA</span></a>, and <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> values to the CMS for display or further
processing.</p>

<p>PNG decoders that provide colour printing facilities can use
the facilities in Level 2 PostScript to specify image data in
calibrated RGB space or in a device-independent colour space such
as XYZ. This will provide better colour fidelity than a simple
RGB to CMYK conversion. The PostScript Language Reference manual
[[?POSTSCRIPT]] gives examples. Such decoders
are responsible for implementing gamut mapping between source RGB
(specified in the <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> chunk) and the target printer. The
PostScript interpreter is then responsible for producing the
required colours.</p>

<p>PNG decoders can use the <a href="#chrm-primary-chromaticities-and-white-point"><span class=
"chunk">cHRM</span></a> data to calculate an accurate greyscale
representation of a colour image. Conversion from RGB to grey is
simply a case of calculating the Y (luminance) component of XYZ,
which is a weighted sum of R, G, and B values. The weights depend
upon the monitor type, i.e. the values in the <a href=
"#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> chunk. PNG decoders
may wish to do this for PNG datastreams with no <a href=
"#chrm-primary-chromaticities-and-white-point"><span class="chunk">cHRM</span></a> chunk. In this
case, a reasonable default would be the CCIR 709 primaries [[ITU-R BT.709]]. The original NTSC primaries
should <strong>not</strong> be used unless the PNG image really
was colour-balanced for such a monitor.</p>
</section>

<!-- Maintain a fragment named "13Background-colour" to preserve incoming links to it -->
<section id="13Background-colour">
<h2>Background
colour</h2>

<p>The background colour given by the <a href="#bkgd-background-colour"><span
class="chunk">bKGD</span></a> chunk will typically be used to
fill unused screen space around the image, as well as any
transparent pixels within the image. (Thus, <a href=
"#bkgd-background-colour"><span class="chunk">bKGD</span></a> is valid and useful
even when the image does not use transparency.) If no <a href=
"#bkgd-background-colour"><span class="chunk">bKGD</span></a> chunk is present,
the viewer will need to decide upon a suitable background colour.
When no other information is available, a medium grey such as 153
in the 8-bit sRGB colour space would be a reasonable choice.
Transparent black or white text and dark drop shadows, which are
common, would all be legible against this background.</p>

<p>Viewers that have a specific background against which to
present the image (such as web browsers) should ignore the <a
href="#bkgd-background-colour"><span class="chunk">bKGD</span></a> chunk, in
effect overriding <a href="#bkgd-background-colour"><span class=
"chunk">bKGD</span></a> with their preferred background colour or
background image.</p>

<p>The background colour given by the <a href="#bkgd-background-colour"><span
class="chunk">bKGD</span></a> chunk is not to be considered
transparent, even if it happens to match the colour given by the
<a href="#trns-transparency"><span class="chunk">tRNS</span></a> chunk (or,
in the case of an indexed-colour image, refers to a palette index
that is marked as transparent by the <a href="#trns-transparency"><span
class="chunk">tRNS</span></a> chunk). Otherwise one would have to
imagine something "behind the background" to composite against.
The background colour is either used as background or ignored; it
is not an intermediate layer between the PNG image and some other
background.</p>

<p>Indeed, it will be common that the <a href="#bkgd-background-colour"><span
class="chunk">bKGD</span></a> and <a href="#trns-transparency"><span class=
"chunk">tRNS</span></a> chunks specify the same colour, since
then a decoder that does not implement transparency processing
will give the intended display, at least when no
partially-transparent pixels are present.</p>
</section>

<!-- Maintain a fragment named "13Alpha-channel-processing" to preserve incoming links to it -->
<section id="13Alpha-channel-processing">
<h2>Alpha channel
processing</h2>

<p>The alpha channel can be used to composite a foreground image
against a background image. The PNG datastream defines the
foreground image and the transparency mask, but not the
background image. PNG decoders are <strong>not</strong> required to
support this most general case. It is expected that most will be
able to support compositing against a single background
colour.</p>

<p>The equation for computing a composited sample value is:</p>

<pre>
output = alpha * foreground + (1-alpha) * background
</pre>

<p>where alpha and the input and output sample values are
expressed as fractions in the range 0 to 1. This computation
should be performed with intensity samples (not gamma-encoded
samples). For colour images, the computation is done separately
for R, G, and B samples.</p>

<p>The following code illustrates the general case of compositing
a foreground image against a background image. It assumes that
the original pixel data are available for the background image,
and that output is to a frame buffer for display. Other variants
are possible; see the comments below the code. The code allows
the sample depths and gamma values of foreground image and
background image all to be different and not necessarily suited
to the display system. In practice no assumptions about equality
should be made without first checking.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<p>This code is ISO C [[ISO-9899]], with line numbers added for
reference in the comments below.</p>

<pre>
   01  int foreground[4];  /* image pixel: R, G, B, A */
   02  int background[3];  /* background pixel: R, G, B */
   03  int fbpix[3];       /* frame buffer pixel */
   04  int fg_maxsample;   /* foreground max sample */
   05  int bg_maxsample;   /* background max sample */
   06  int fb_maxsample;   /* frame buffer max sample */
   07  int ialpha;
   08  float alpha, compalpha;
   09  float gamfg, linfg, gambg, linbg, comppix, gcvideo;

       /* Get max sample values in data and frame buffer */
   10  fg_maxsample = (1 &lt;&lt; fg_sample_depth) - 1;
   11  bg_maxsample = (1 &lt;&lt; bg_sample_depth) - 1;
   12  fb_maxsample = (1 &lt;&lt; frame_buffer_sample_depth) - 1;
       /*
        * Get integer version of alpha.
        * Check for opaque and transparent special cases;
        * no compositing needed if so.
        *
        * We show the whole gamma decode/correct process in
        * floating point, but it would more likely be done
        * with lookup tables.
        */
   13  ialpha = foreground[3];

   14  if (ialpha == 0) {
           /*
            * Foreground image is transparent here.
            * If the background image is already in the frame
            * buffer, there is nothing to do.
            */
   15      ;
   16  } else if (ialpha == fg_maxsample) {
           /*
            * Copy foreground pixel to frame buffer.
            */
   17      for (i = 0; i &lt; 3; i++) {
   18          gamfg = (float) foreground[i] / fg_maxsample;
   19          linfg = pow(gamfg, 1.0 / fg_gamma);
   20          comppix = linfg;
   21          gcvideo = pow(comppix, 1.0 / display_exponent);
   22          fbpix[i] = (int) (gcvideo * fb_maxsample + 0.5);
   23      }
   24  } else {
           /*
            * Compositing is necessary.
            * Get floating-point alpha and its complement.
            * Note: alpha is always linear; gamma does not
            * affect it.
            */
   25      alpha = (float) ialpha / fg_maxsample;
   26      compalpha = 1.0 - alpha;

   27      for (i = 0; i &lt; 3; i++) {
               /*
                * Convert foreground and background to floating
                * point, then undo gamma encoding.
                */
   28          gamfg = (float) foreground[i] / fg_maxsample;
   29          linfg = pow(gamfg, 1.0 / fg_gamma);
   30          gambg = (float) background[i] / bg_maxsample;
</pre>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<pre>
   31          linbg = pow(gambg, 1.0 / bg_gamma);
               /*
                * Composite.
                */
   32          comppix = linfg * alpha + linbg * compalpha;
               /*
                * Gamma correct for display.
                * Convert to integer frame buffer pixel.
                */
   33          gcvideo = pow(comppix, 1.0 / display_exponent);
   34          fbpix[i] = (int) (gcvideo * fb_maxsample + 0.5);
   35      }
   36  }
</pre>

<p>Variations:</p>

<!-- <ol start="1"> --><ol>
<li>If output is to another PNG datastream instead of a frame
buffer, lines 21, 22, 33, and 34 should be changed along the
following lines

<pre>
   /*
    * Gamma encode for storage in output datastream.
    * Convert to integer sample value.
    */
   gamout = pow(comppix, outfile_gamma);
   outpix[i] = (int) (gamout * out_maxsample + 0.5);
</pre>

Also, it becomes necessary to process background pixels when
alpha is zero, rather than just skipping pixels. Thus, line 15
will need to be replaced by copies of lines 17-23, but processing
background instead of foreground pixel values.</li>

<li>If the sample depths of the output file, foreground file, and
background file are all the same, and the three gamma values also
match, then the no-compositing code in lines 14-23 reduces to
copying pixel values from the input file to the output file if
alpha is one, or copying pixel values from background to output
file if alpha is zero. Since alpha is typically either zero or
one for the vast majority of pixels in an image, this is a
significant saving. No gamma computations are needed for most
pixels.</li>

<li>When the sample depths and gamma values all match, it may
appear attractive to skip the gamma decoding and encoding (lines
28-31, 33-34) and just perform line 32 using gamma-encoded sample
values. Although this does not have too bad an effect on image
quality, the time savings are small if alpha values of zero and
one are treated as special cases as recommended here.</li>

<li>If the original pixel values of the background image are no
longer available, only processed frame buffer pixels left by
display of the background image, then lines 30 and 31 need to
extract intensity from the frame buffer pixel values using code
such as

<pre>
   /*
    * Convert frame buffer value into intensity sample.
    */
   gcvideo = (float) fbpix[i] / fb_maxsample;
   linbg = pow(gcvideo, display_exponent);
</pre>

However, some roundoff error can result, so it is better to have
the original background pixels available if at all possible.</li>

<li>Note that lines 18-22 are performing exactly the same gamma
computation that is done when no alpha channel is present. If the
no-alpha case is handled with a lookup table, the same lookup
table can be used here. Lines 28-31 and 33-34 can also be done
with (different) lookup tables.</li>

<li>Integer arithmetic can be used instead of floating point,
providing care is taken to maintain sufficient precision
throughout.</li>
</ol>

<p class="Note">NOTE In floating point, no overflow or underflow
checks are needed, because the input sample values are guaranteed
to be between 0 and 1, and compositing always yields a result
that is in between the input values (inclusive). With integer
arithmetic, some roundoff-error analysis might be needed to
guarantee no overflow or underflow.</p>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<p>When displaying a PNG image with full alpha channel, it is
important to be able to composite the image against some
background, even if it is only black. Ignoring the alpha channel
will cause PNG images that have been converted from an
associated-alpha representation to look wrong. (Of course, if the
alpha channel is a separate transparency mask, then ignoring
alpha is a useful option: it allows the hidden parts of the image
to be recovered.)</p>

<p>Even if the decoder does not implement true compositing logic,
it is simple to deal with images that contain only zero and one
alpha values. (This is implicitly true for greyscale and
truecolour PNG datastreams that use a <a href="#trns-transparency"><span
class="chunk">tRNS</span></a> chunk; for indexed-colour PNG
datastreams it is easy to check whether the <a href=
"#trns-transparency"><span class="chunk">tRNS</span></a> chunk contains any
values other than 0 and 255.) In this simple case, transparent
pixels are replaced by the background colour, while others are
unchanged.</p>

<p>If a decoder contains only this much transparency capability,
it should deal with a full alpha channel by treating all nonzero
alpha values as fully opaque or by dithering. Neither approach
will yield very good results for images converted from
associated-alpha formats, but this is preferable to doing
nothing. Dithering full alpha to binary alpha is very much like
dithering greyscale to black-and-white, except that all fully
transparent and fully opaque pixels should be left unchanged by
the dither.</p>
</section>

<!-- Maintain a fragment named "13Histogram-and-suggested-palette-usage" to preserve incoming links to it -->
<section id="13Histogram-and-suggested-palette-usage">
<h2>Histogram and suggested palette usage</h2>

<p>For viewers running on indexed-colour hardware attempting to
display a truecolour image, or an indexed-colour image whose
palette is too large for the frame buffer, the encoder may have
provided one or more suggested palettes in <a href=
"#splt-suggested-palette"><span class="chunk">sPLT</span></a> chunks. If one of
these is found to be suitable, based on size and perhaps name,
the PNG decoder can use that palette. Suggested palettes with a
sample depth different from what the decoder needs can be
converted using sample depth rescaling (see 13.12: <a href=
"#sample-depth-rescaling"><span class="xref">Sample depth
rescaling</span></a>).</p>

<p>When the background is a solid colour, the viewer should
composite the image and the suggested palette against that
colour, then quantize the resulting image to the resulting RGB
palette. When the image uses transparency and the background is
not a solid colour, no suggested palette is likely to be
useful.</p>

<p>For truecolour images, a suggested palette might also be
provided in a <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk. If the image has a <a href=
"#trns-transparency"><span class="chunk">tRNS</span></a> chunk and the
background is a solid colour, the viewer will need to adapt the
suggested palette for use with its desired background colour. To
do this, the palette entry closest to the <a href="#trns-transparency"><span
class="chunk">tRNS</span></a> colour should be replaced with the
desired background colour; or alternatively a palette entry for
the background colour can be added, if the viewer can handle more
colours than there are <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> entries.</p>

<p>For images of colour type 6 (truecolour with alpha), any <a
href="#plte-palette"><span class="chunk">PLTE</span></a> chunk should
have been designed for display of the image against a uniform
background of the colour specified by the <a href="#bkgd-background-colour"><span
class="chunk">bKGD</span></a> chunk. Viewers should probably
ignore the palette if they intend to use a different background,
or if the <a href="#bkgd-background-colour"><span class="chunk">bKGD</span></a>
chunk is missing. Viewers can use a suggested palette for display
against a different background than it was intended for, but the
results may not be very good.</p>

<p>If the viewer presents a transparent truecolour image against
a background that is more complex than a uniform colour, it is
unlikely that the suggested palette will be optimal for the
composite image. In this case it is best to perform a truecolour
compositing step on the truecolour PNG image and background
image, then colour-quantize the resulting image.</p>

<p>In truecolour PNG datastreams, if both <a href="#plte-palette"><span
class="chunk">PLTE</span></a> and <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> chunks appear, the PNG decoder may choose
from among the palettes suggested by both, bearing in mind the
different transparency semantics described above.</p>

<p>The frequencies in the <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> and <a href="#hist-image-histogram"><span class=
"chunk">hIST</span></a> chunks are useful when the viewer cannot
provide as many colours as are used in the palette in the PNG
datastream. If the viewer has a shortfall of only a few colours,
it is usually adequate to drop the least-used colours from the
palette. To reduce the number of colours substantially, it is
best to choose entirely new representative colours, rather than
trying to use a subset of the existing palette. This amounts to
performing a new colour quantization step; however, the existing
palette and histogram can be used as the input data, thus
avoiding a scan of the image data in the <a href="#idat-image-data"><span
class="chunk">IDAT</span></a> chunks.</p>

<p>If no suggested palette is provided, a decoder can develop its
own, at the cost of an extra pass over the image data in the <a
href="#idat-image-data"><span class="chunk">IDAT</span></a> chunks.
Alternatively, a default palette (probably a colour cube) can be
used.</p>

<p>See also 12.6: <a href="#suggested-palettes"><span class=
"xref">Suggested palettes</span></a>.</p>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "14EditorsExt" to preserve incoming links to it -->
<section id="14EditorsExt">
<h2>Editors and extensions</h2>

<!-- Maintain a fragment named "14Additional-chunk-types" to preserve incoming links to it -->
<section id="14Additional-chunk-types">
<h2>Additional chunk
types</h2>

<p>The provisions of this specification may be extended
by adding new chunk types, which may be either private or public.
Applications can use private chunk types to carry data that is
not of interest to other people's applications.</p>

<p>Decoders shall be prepared to encounter unrecognized public or
private chunk types. The chunk naming conventions (see 5.4:
<a href="#chunk-naming-conventions"><span class="xref">Chunk
naming conventions</span></a>) enable critical/ancillary,
public/private, and safe/unsafe to copy chunks to be
distinguished.</p>

<p>Additional public PNG chunk types are defined in the document
Register of PNG Public Chunks and Keywords <a href=
"#PNG-EXTENSIONS"><span class=
"bibref">[PNG-EXTENSIONS]</span></a>. Chunks described there are
expected to be less widely supported than those defined in this
International Standard. However, application authors are
encouraged to use those chunk types whenever appropriate for
their applications. Additional chunk types can be proposed for
inclusion in that list by contacting the PNG Registration
Authority (see 4.9: <a href="#extension-and-registration"><span
class="xref">Extension and registration</span></a>).</p>

<p>New public chunks will be registered only if they are of use
to others and do not violate the design philosophy of PNG. Chunk
registration is not automatic, although it is the intent of the
Registration Authority that it be straightforward when a new
chunk of potentially wide application is needed. The creation of
new critical chunk types is discouraged unless absolutely
necessary.</p>
</section>

<!-- Maintain a fragment named "14Ordering" to preserve incoming links to it -->
<section id="14Ordering">
<h2>Behaviour of PNG editors</h2>

<p>A "PNG editor" is defined as a program that reads a PNG
datastream, makes modifications, and writes a new PNG datastream
while preserving as much ancillary information as possible. Two
examples of PNG editors are a program that adds or modifies text
chunks, and a program that adds a suggested palette to a
truecolour PNG datastream. Ordinary image editors are not PNG
editors because they usually discard all unrecognized information
while reading in an image.</p>

<p>To allow new chunk types to be added to PNG, it is necessary
to establish rules about the ordering requirements for all chunk
types. Otherwise a PNG editor does not know what to do when it
encounters an unknown chunk.</p>

<p>EXAMPLE Consider a hypothetical new ancillary chunk type that
is safe-to-copy and is required to appear after <a href=
"#plte-palette"><span class="chunk">PLTE</span></a> if <a href=
"#plte-palette"><span class="chunk">PLTE</span></a> is present. If a
program attempts to add a <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk and does not recognize the new
chunk, it may insert the <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> chunk in the wrong place, namely after
the new chunk. Such problems could be prevented by requiring PNG
editors to discard all unknown chunks, but that is a very
unattractive solution. Instead, PNG requires ancillary chunks not
to have ordering restrictions like this.</p>

<p>To prevent this type of problem while allowing for future
extension, constraints are placed on both the behaviour of PNG
editors and the allowed ordering requirements for chunks. The
safe-to-copy bit defines the proper handling of unrecognized
chunks in a datastream that is being modified.</p>

<!-- <ol start="1"> --><ol>
<li>If a chunk's safe-to-copy bit is 1, the chunk may be copied
to a modified PNG datastream whether or not the PNG editor
recognizes the chunk type, and regardless of the extent of the
datastream modifications.</li>

<li>If a chunk's safe-to-copy bit is 0, it indicates that the
chunk depends on the image data. If the program has made
<strong>any</strong> changes to <strong>critical</strong> chunks, including
addition, modification, deletion, or reordering of critical
chunks, then unrecognized unsafe chunks shall
<strong>not</strong> be copied to the output PNG datastream. (Of
course, if the program <strong>does</strong> recognize the chunk,
it can choose to output an appropriately modified version.)</li>

<li>A PNG editor is always allowed to copy all unrecognized
ancillary chunks if it has only added, deleted, modified, or
reordered <strong>ancillary</strong> chunks. This implies that it is not
permissible for ancillary chunks to depend on other ancillary
chunks.</li>

<li>PNG editors shall terminate on encountering an unrecognized
critical chunk type, because there is no way to be certain that a
valid datastream will result from modifying a datastream
containing such a chunk. (Simply discarding the chunk is not good
enough, because it might have unknown implications for the
interpretation of other chunks.) The safe/unsafe mechanism is
intended for use with ancillary chunks. The safe-to-copy bit will
always be 0 for critical chunks.</li>
</ol>

<p>The rules governing ordering of chunks are as follows.</p>

<!-- <ol start="5"> --><ol>
<li>When copying an unknown <strong>unsafe-to-copy</strong> ancillary
chunk, a PNG editor shall not move the chunk relative to any
critical chunk. It may relocate the chunk freely relative to
other ancillary chunks that occur between the same pair of
critical chunks. (This is well defined since the editor shall not
add, delete, modify, or reorder critical chunks if it is
preserving unknown unsafe-to-copy chunks.)</li>

<li>When copying an unknown <strong>safe-to-copy</strong> ancillary
chunk, a PNG editor shall not move the chunk from before <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a> to after <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a> or vice versa.
(This is well defined because <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> is always present.) Any other reordering
is permitted.</li>

<li>When copying a <strong>known</strong> ancillary chunk type, an editor
need only honour the specific chunk ordering rules that exist for
that chunk type. However, it may always choose to apply the above
general rules instead.</li>
</ol>

<p>These rules are expressed in terms of copying chunks from an
input datastream to an output datastream, but they apply in the
obvious way if a PNG datastream is modified in place.</p>

<p>See also 5.4: <a href="#chunk-naming-conventions"><span
class="xref">Chunk naming conventions</span></a>.</p>

<p>PNG editors that do not change the image data should not
change the <a href="#time-image-last-modification-time"><span class="chunk">tIME</span></a>
chunk. The Creation Time keyword in the <a href="#text-textual-data"><span
class="chunk">tEXt</span></a>, <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a>, and <a href="#itxt-international-textual-data"><span class=
"chunk">iTXt</span></a> chunks may be used for a user-supplied
time.</p>
</section>

<!-- Maintain a fragment named "14Ordering-of-chunks" to preserve incoming links to it -->
<section id="14Ordering-of-chunks">
<h2>Ordering of
chunks</h2>

<!-- Maintain a fragment named "14Ordering-of-critical-chunks" to preserve incoming links to it -->
<section id="14Ordering-of-critical-chunks">
<h2>Ordering of
critical chunks</h2>

<p>Critical chunks may have arbitrary ordering requirements,
because PNG editors are required to terminate if they encounter
unknown critical chunks. For example <a href="#ihdr-image-header"><span
class="chunk">IHDR</span></a> has the specific ordering rule that
it shall always appear first. A PNG editor, or indeed any
PNG-writing program, shall know and follow the ordering rules for
any critical chunk type that it can generate.</p>
</section>

<!-- Maintain a fragment named "14Ordering-of-ancillary-chunks" to preserve incoming links to it -->
<section id="14Ordering-of-ancillary-chunks">
<h2>Ordering of
ancillary chunks</h2>

<p>The strictest ordering rules for an ancillary chunk type
are:</p>

<!-- <ol start="1"> --><ol>
<li>Unsafe-to-copy chunks may have ordering requirements relative
to critical chunks.</li>

<li>Safe-to-copy chunks may have ordering requirements relative
to <a href="#idat-image-data"><span class="chunk">IDAT</span></a>.</li>
</ol>

<p>The actual ordering rules for any particular ancillary chunk
type may be weaker. See for example the ordering rules for the
standard ancillary chunk types in 5.6: <a href=
"#chunk-ordering"><span class="xref">Chunk
ordering</span></a>.</p>

<p>Decoders shall not assume more about the positioning of any
ancillary chunk than is specified by the chunk ordering rules. In
particular, it is never valid to assume that a specific ancillary
chunk type occurs with any particular positioning relative to
other ancillary chunks.</p>

<p>EXAMPLE It is unsafe to assume that a particular private
ancillary chunk occurs immediately before <a href="#iend-image-trailer"><span
class="chunk">IEND</span></a>. Even if it is always written in
that position by a particular application, a PNG editor might
have inserted some other ancillary chunk after it. But it is safe
to assume that the chunk will remain somewhere between <a href=
"#idat-image-data"><span class="chunk">IDAT</span></a> and <a href=
"#iend-image-trailer"><span class="chunk">IEND</span></a>.</p>
</section>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<section id="conformance">
<!-- Maintain a fragment named "15Conformance" to preserve incoming links to it -->
<a name="15Conformance"></a>

<!-- Maintain a fragment named "15ConfIntro" to preserve incoming links to it -->
<section id="15ConfIntro">
<h2>Introduction</h2>

<!-- Maintain a fragment named "15ConfObjectives" to preserve incoming links to it -->
<section id="15ConfObjectives">
<h2>Objectives</h2>

<p>This clause addresses conformance of PNG datastreams, PNG
encoders, PNG decoders, and PNG editors.</p>

<p>The primary objectives of the specifications in this clause
are:</p>

<!-- <ol start="1"> --><ol>
<li>to promote interoperability by eliminating arbitrary subsets
of, or extensions to, this specification;</li>

<li>to promote uniformity in the development of conformance
tests;</li>

<li>to promote consistent results across PNG encoders, decoders,
and editors;</li>

<li>to facilitate automated test generation.</li>
</ol>
</section>

<!-- Maintain a fragment named "15ConfScope" to preserve incoming links to it -->
<section id="15ConfScope">
<h2>Scope</h2>

<p>Conformance is defined for PNG datastreams and for PNG
encoders, decoders, and editors.</p>

<p>This clause addresses the PNG datastream and implementation
requirements including the range of allowable differences for PNG
encoders, PNG decoders, and PNG editors. This clause does not
directly address the environmental, performance, or resource
requirements of the encoder, decoder, or editor.</p>

<p>The scope of this clause is limited to rules for the open
interchange of PNG datastreams.</p>
</section>
</section>

<!-- Maintain a fragment named "15ConformanceConf" to preserve incoming links to it -->
<section id="15ConformanceConf">
<h2>Conformance conditions</h2>

<!-- Maintain a fragment named "15FileConformance" to preserve incoming links to it -->
<section id="15FileConformance">
<h2>Conformance of PNG
datastreams</h2>
<p>A PNG datastream conforms to this specification if
the following conditions are met.</p>
<ol>
<li>The PNG datastream contains a PNG signature as the first
content (see 5.2: <a href="#png-signature"><span class=
"xref">PNG file signature</span></a>).</li>

<li>With respect to the chunk types defined in this International
Standard:

<ul>
<li>the PNG datastream contains as its first chunk, an <a href=
"#ihdr-image-header"><span class="chunk">IHDR</span></a> chunk, immediately
following the PNG signature;</li>

<li>the PNG datastream contains as its last chunk, an <a href=
"#iend-image-trailer"><span class="chunk">IEND</span></a> chunk.</li>
</ul>
</li>

<li>No chunks or other content follow the <a href="#iend-image-trailer"><span
class="chunk">IEND</span></a> chunk.</li>

<li>All chunks contained therein match the specification of the
corresponding chunk types of this specification.
The PNG datastream shall obey the relationships among chunk types
defined in this specification.</li>

<li>The sequence of chunks in the PNG datastream obeys the
ordering relationship specified in this International
Standard.</li>

<li>All field values in the PNG datastream obey the relationships
specified in this specification producing the structure
specified in this specification.</li>

<li>No chunks appear in the PNG datastream other than those
specified in this specification or those defined
according to the rules for creating new chunk types as defined in
this specification.</li>

<li>The PNG datastream is encoded according to the rules of this
International Standard.</li>
</ol>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "15ConformanceEncoder" to preserve incoming links to it -->
<section id="15ConformanceEncoder">
<h2>Conformance of PNG
encoders</h2>

<p>A PNG encoder conforms to this specification if it
satisfies the following conditions.</p>

<!-- <ol start="1"> --><ol>
<li>All PNG datastreams that are generated by the PNG encoder are
conforming PNG datastreams.</li>

<li>When encoding input samples that have a sample depth that
cannot be directly represented in PNG, the encoder scales the
samples up to the next higher sample depth that is allowed by
PNG. The data are scaled in such a way that the high-order bits
match the original data.</li>

<li>Numbers greater than 127 are used when encoding experimental
or private definitions of values for any of the method or type
fields.</li>
</ol>
</section>

<!-- Maintain a fragment named "15ConformanceDecoder" to preserve incoming links to it -->
<section id="15ConformanceDecoder">
<h2>Conformance of PNG
decoders</h2>

<p>A PNG decoder conforms to this specification if it
satisfies the following conditions.</p>

<!-- <ol start="1"> --><ol>
<li>It is able to read any PNG datastream that conforms to this
International Standard, including both public and private chunks
whose types may not be recognized.</li>

<li>It supports all the standardized critical chunks, and all the
standardized compression, filter, and interlace methods and types
in any PNG datastream that conforms to this International
Standard.</li>

<li>Unknown chunk types are handled as described in <a href=
"#chunk-naming-conventions"><span class="xref">5.4 Chunk naming
conventions</span></a>. An unknown chunk type is <strong>not</strong>
treated as an error unless it is a critical chunk.</li>

<li>Unexpected values in fields of known chunks (for example, an
unexpected compression method in the <a href="#ihdr-image-header"><span
class="chunk">IHDR</span></a> chunk) are treated as errors.</li>

<li>All types of PNG images (indexed-colour, truecolour,
greyscale, truecolour with alpha, and greyscale with alpha) are
processed. For example, decoders which are part of viewers
running on indexed-colour display hardware shall reduce
truecolour images to indexed format for viewing.</li>

<li>Encountering an unknown chunk in which the ancillary bit is 0
generates an error if the decoder is attempting to extract the
image.</li>

<li>A chunk type in which the reserved bit is set is treated as
an unknown chunk type.</li>

<li>All valid combinations of bit depth and colour type as
defined in 11.2.2: <a href="#ihdr-image-header"><span class="xref"><span
class="chunk">IHDR</span> Image header</span></a> are
supported.</li>

<li>An error is reported if an unrecognized value is encountered
in the bit depth, colour type, compression method, filter method,
or interlace method bytes of the <a href="#ihdr-image-header"><span class=
"chunk">IHDR</span></a> chunk.</li>

<li>When processing 16-bit greyscale or truecolour data in the <a
href="#trns-transparency"><span class="chunk">tRNS</span></a> chunk, both
bytes of the sample values are evaluated to determine whether a
pixel is transparent.</li>

<li>When processing an image compressed by compression method 0,
the decoder assumes no more than that the complete image data is
represented by a single compressed datastream that is stored in
some number of <a href="#idat-image-data"><span class=
"chunk">IDAT</span></a> chunks.</li>

<li>No assumptions are made concerning the positioning of any
ancillary chunk other than those that are specified by the chunk
ordering rules.</li>
</ol>
</section>

<!-- Maintain a fragment named "15ConformanceEditor" to preserve incoming links to it -->
<section id="15ConformanceEditor">
<h2>Conformance of PNG
editors</h2>

<p>A PNG editor conforms to this specification if it satisfies the following conditions.</p>

<ol>
<li>It conforms to the requirements for PNG encoders.</li>

<li>It conforms to the requirements for PNG decoders.</li>

<li>It is able to encode all chunks that it decodes.</li>

<li>It preserves the ordering of the chunks presented within the
rules in 5.6: <a href="#chunk-ordering"><span class="xref">Chunk
ordering</span></a>.</li>

<li>It properly processes the safe-to-copy bit information and
preserves unknown chunks when the safe-to-copy rules permit
it.</li>

<li>Unless the user specifically permits lossy operations or the
editor issues a warning, it preserves all information required to
reconstruct the reference image exactly, except that the sample
depth of the alpha channel need not be preserved if it contains
only zero and maximum values. Operations such as changing the
colour type or rearranging the palette in an indexed-colour
datastream are permitted provided that the new datastream
losslessly represents the same reference image.</li>
</ol>
</section>
</section>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "A-Conventions" to preserve incoming links to it -->
<section class="appendix" id="A-Conventions">

<!-- Maintain a fragment named "IANA-registrations" to preserve incoming links to it -->
<h2 id="IANA-registrations">Internet Media Types</h2>

<!-- Maintain a fragment named "image-png-registration" to preserve incoming links to it -->
<h2 id="image-png-registration">image/png</h2>

<p>This updates the existing
  <span class="tt">image/png</span> Internet Media type, under the
  <span class="tt">image</span> top level type.
  This appendix is in conformance with
    <a href="https://www.rfc-editor.org/info/bcp13">BCP 13</a> and
    <a href="https://www.w3.org/2020/01/registering-mediatypes.html">W3CRegMedia</a>.
  </p>

  <dl>
    <dt>Media type name:</dt>
    <dd>image</dd>

    <dt>Media subtype name:</dt>
    <dd>png</dd>

    <dt>Required parameters:</dt>
    <dd>None</dd>

    <dt>Optional parameters:</dt>
    <dd>None</dd>

    <dt>Encoding considerations:</dt>
    <dd>binary</dd>

    <dt>Security considerations:</dt>
    <dd>
      <p>A PNG document is composed of a collection of explicitly typed "chunks".
        For each of the chunk types defined in the PNG specification (except
        for "gIFx"), the only effect associated with those chunks is to cause
        an image to be rendered on the recipient's display or printer.</p>
      <p>The gIFx chunk type is used to encapsulate Application Extension
        data, and some use of that data might present security risks, though
        no risks are known.  Likewise, the security risks associated with
        future chunk types cannot be evaluated, particularly unregistered
        chunks.  However, it is the intention of the PNG group to disallow
        chunks containing "executable" data to become registered chunks.</p>
      <p>The text chunks, tEXt and zTXt, contain data that can be displayed in
        the form of comments, etc.  Some operating systems or terminals might
        allow the display of textual data with embedded control characters to
        perform operations such as re-mapping of keys, creation of files, etc.
        For this reason, the specification recommends that the text chunks be
        filtered for control characters before direct display.</p>
      <p>The PNG format is specifically designed to facilitate early detection
        of file transmission errors, and makes use of cyclical redundancy
        checks to ensure the integrity of the data contained in its chunks.</p>
    </dd>

    <dt>Interoperability considerations:</dt>
    <dd>Network byte order used throughout.</dd>

    <dt>Published specification:</dt>
    <dd><a href="https://www.w3.org/TR/PNG/
      ">Portable Network Graphics (PNG) Specification</a>,
      <a href="https://www.w3.org/TR/PNG/
      ">https://www.w3.org/TR/PNG/</a>
    </dd>

    <dt>Applications which use this media:</dt>
    <dd>PNG is widely implemented in all Web browsers, image viewers, and image creation tools
    </dd>

    <dt>Fragment identifier considerations:
    </dt>
    <dd>N/A</dd>

    <dt>Restrictions on usage:
    </dt>
    <dd>N/A</dd>

    <dt>Provisional registration? (standards tree only):</dt>
    <dd>No</dd>

    <dt>Additional information:
    </dt>
    <dd>
      <dl>
        <dt>Deprecated alias names for this type:</dt>
        <dd>N/A</dd>
        <dt>Magic number(s):</dt>
        <dd>89 50 4E 47 0D 0A 1A 0A</dd>
        <dt>File extension(s):</dt>
        <dd>.png</dd>
        <dt>Macintosh file type code:</dt>
        <dd>PNGf</dd>
        <dt>Object Identifiers:</dt>
        <dd>N/A</dd>
      </dl>
    </dd>

    <dt>General Comments:</dt>
    <dd>
      <p>This registration updates the earlier one:</p>
      <ol>
        <li>The old one points to an expired Internet Draft. This updated registration points to a W3C Recommendation.</li>
        <li>The old contact person is sadly deceased. The new contact email is a publicly archived W3C mailing list for the PNG Working Group.</li>
        <li>Change controller is W3C</li>
      </ol>
    </dd>

    <dt>Person to contact for further information:</dt>
    <dd>
      <dl>
        <dt>Name:</dt>
        <dd>PNG Working Group</dd>
        <dt>Email:</dt>
        <dd><a href="mailto:public-png@w3.org">public-png@w3.org</a></dd>
      </dl>
    </dd>

    <dt>Intended usage:</dt>
    <dd>Common</dd>

    <dt>Author/Change controller:</dt>
    <dd>W3C</dd>

  </dl>
</section>




<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "B-NewChunksAppendix" to preserve incoming links to it -->
<section class="appendix informative" id="B-NewChunksAppendix">
<!-- Maintain a fragment named "newchunks" to preserve incoming links to it -->
<h2 class="Annex" id="newchunks">Guidelines for new chunk types</h2>

<p>This specification allows extension through the
addition of new chunk types and new interlace, filter, and
compression methods. Such extensions might be made to the
standard either for experimental purposes or by organizations for
internal use.</p>

<p>Chunk types that are intended for general public use, or are
required for specific application domains, should be standardized
through registration (see 4.9 <a href=
"#extension-and-registration"><span class="xref">Extension and
registration</span></a>). The process for registration is defined
by the Registration Authority. The conventions for naming chunks
are given in 5.4: <a href="#chunk-naming-conventions"><span
class="xref">Chunk naming conventions</span></a>.</p>

<p>Some guidelines for defining private chunks are given
below.</p>

<!-- <ol start="1"> --><ol>
<li>Do not define new chunks that redefine the meaning of
existing chunks or change the interpretation of an existing
standardized chunk, e.g., do not add a new chunk to say that RGB
and alpha values actually mean CMYK.</li>

<li>Minimize the use of private chunks to aid portability.</li>

<li>Avoid defining chunks that depend on total datastream
contents. If such chunks have to be defined, make them critical
chunks.</li>

<li>For textual information that is representable in Latin-1
avoid defining a new chunk type. Use a <a href="#text-textual-data"><span
class="chunk">tEXt</span></a> or <a href="#ztxt-compressed-textual-data"><span class=
"chunk">zTXt</span></a> chunk with a suitable keyword to identify
the type of information. For textual information that is not
representable in Latin-1 but which can be represented in UTF-8,
use an <a href="#itxt-international-textual-data"><span class="chunk">iTXt</span></a>
chunk with a suitable keyword.</li>

<li>Group mutually dependent ancillary information into a single
chunk. This avoids the need to introduce chunk ordering
relationships.</li>

<li>Avoid defining private critical chunks.</li>
</ol>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "C-GammaAppendix" to preserve incoming links to it -->
<section class="appendix informative" id="C-GammaAppendix">
<!-- Maintain a fragment named "gammachromaticity" to preserve incoming links to it -->
<h2 class="Annex" id="gammachromaticity">Gamma and chromaticity</h2>

<p>Gamma is a numerical parameter used to describe approximations
to certain non-linear transfer functions encountered in image
capture and reproduction. Gamma is the exponent in a power law
function. For example the function:</p>

<p><tt>intensity = (voltage +
constant)<sup>exponent</sup></tt></p>

<p>which is used to model the non-linearity of cathode ray tube
(CRT) displays. It is often assumed, as in this International
Standard, that the constant is zero.</p>

<p>For the purposes of this specification, it is
convenient to consider five places in a general image pipeline at
which non-linear transfer functions may occur and which may be
modelled by power laws. The characteristic exponent associated
with each is given a specific name.</p>

<table class="Regular" summary=
"This table describes characteristic exponents">
<tr>
<td class="Regular"><tt>input_exponent</tt> </td>
<td class="Regular">the exponent of the image sensor.</td>
</tr>

<tr>
<td class="Regular"><tt>encoding_exponent</tt> </td>
<td class="Regular">the exponent of any transfer function performed by the
process or device writing the datastream.</td>
</tr>

<tr>
<td class="Regular"><tt>decoding_exponent</tt> </td>
<td class="Regular">the exponent of any transfer function performed by the
software reading the image datastream.</td>
</tr>

<tr>
<td class="Regular"><tt>LUT_exponent</tt> </td>
<td class="Regular">the exponent of the transfer function applied between the
frame buffer and the display device (typically this is applied by
a Look Up Table).</td>
</tr>

<tr>
<td class="Regular"><tt>output_exponent</tt> </td>
<td class="Regular">the exponent of the display device. For a CRT, this is
typically a value close to 2.2.</td>
</tr>
</table>

<p>It is convenient to define some additional entities that
describe some composite transfer functions, or combinations of
stages.</p>

<table class="Regular" summary=
"This table characterises additional entities that are used to describe transfer functions">
<tr>
<td class="Regular"><tt>display_exponent</tt> </td>
<td class="Regular">exponent of the transfer function applied between the frame
buffer and the display surface of the display device.<br class="xhtml" />
<tt>display_exponent = LUT_exponent * output_exponent</tt> </td>
</tr>

<tr>
<td class="Regular"><tt>gamma</tt> </td>
<td class="Regular">exponent of the function mapping display output intensity to
samples in the PNG datastream.<br class="xhtml" />
<tt>gamma = 1.0 / (decoding_exponent * display_exponent)</tt>
</td>
</tr>

<tr>
<td class="Regular"><tt>end_to_end_exponent</tt> </td>
<td class="Regular">the exponent of the function mapping image sensor input
intensity to display output intensity. This is generally a value
in the range 1.0 to 1.5.</td>
</tr>
</table>

<p>The PNG <a href="#gama-image-gamma"><span class="chunk">gAMA</span></a>
chunk is used to record the gamma value. This information may be
used by decoders together with additional information about the
display environment in order to achieve, or approximate, the
desired display output.</p>

<p>Additional information about this subject may be found in the
references <a href="#GAMMA-TUTORIAL"><span class=
"bibref">[GAMMA-TUTORIAL]</span></a>, <a href=
"#GAMMA-FAQ"><span class="bibref">[GAMMA-FAQ]</span></a>, and
<a href="#POYNTON"><span class="bibref">[POYNTON]</span></a>
(especially chapter 6).</p>

<p>Background information about chromaticity and colour spaces
may be found in references <a href="#COLOUR-TUTORIAL"><span
class="bibref">[COLOUR-TUTORIAL]</span></a>, <a href=
"#COLOUR-FAQ"><span class="bibref">[COLOUR-FAQ]</span></a>, <a
href="#HALL"><span class="bibref">[HALL]</span></a>, <a href=
"#KASSON"><span class="bibref">[KASSON]</span></a>, <a href=
"#LILLEY"><span class="bibref">[LILLEY]</span></a>, <a href=
"#STONE"><span class="bibref">[STONE]</span></a>, and <a href=
"#TRAVIS"><span class="bibref">[TRAVIS]</span></a>.</p>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "D-CRCAppendix" to preserve incoming links to it -->
<section class="appendix informative" id="D-CRCAppendix">
<!-- Maintain a fragment named "samplecrc" to preserve incoming links to it -->
<h2 class="Annex" id="samplecrc">Sample Cyclic Redundancy Code
implementation</h2>

<p>The following sample code represents a practical
implementation of the CRC (Cyclic Redundancy Check) employed in
PNG chunks. (See also ISO 3309 [[ISO 3309]] or ITU-T V.42 [[ITU-T-V42]] for a
formal specification.)</p>

<p>The sample code is in the ISO C [[ISO 9899]] programming language. The
hints in <a href="#D-tabled1"><span class="tabref">Table
D.1</span></a> may help non-C users to read the code more
easily.</p>

<table class="Regular" summary=
"This table gives hints for reading the CRC code">
<caption><a name="D-tabled1"><b>Table D.1 &mdash; Hints for
reading ISO C code</b></a></caption>

<tr>
<td class="Regular"><tt>&amp;</tt> </td>
<td class="Regular">Bitwise AND operator.</td>
</tr>

<tr>
<td class="Regular"><tt>^</tt> </td>
<td class="Regular">Bitwise exclusive-OR operator.</td>
</tr>

<tr>
<td class="Regular"><tt>&gt;&gt;</tt> </td>
<td class="Regular">Bitwise right shift operator. When applied to an unsigned
quantity, as here, right shift inserts zeroes at the left.</td>
</tr>

<tr>
<td class="Regular"><tt>!</tt> </td>
<td class="Regular">Logical NOT operator.</td>
</tr>

<tr>
<td class="Regular"><tt>++</tt> </td>
<td class="Regular">"<tt>n++</tt>" increments the variable <tt>n</tt>. In "for"
loops, it is applied after the variable is tested.</td>
</tr>

<tr>
<td class="Regular"><tt>0xNNN</tt> </td>
<td class="Regular"><tt>0x</tt> introduces a hexadecimal (base 16) constant.
Suffix <tt>L</tt> indicates a long value (at least 32 bits).</td>
</tr>
</table>

<hr class="xhtml" />
<pre>
   /* Table of CRCs of all 8-bit messages. */
   unsigned long crc_table[256];

   /* Flag: has the table been computed? Initially false. */
   int crc_table_computed = 0;

   /* Make the table for a fast CRC. */
   void make_crc_table(void)
   {
     unsigned long c;
     int n, k;

     for (n = 0; n &lt; 256; n++) {
       c = (unsigned long) n;
       for (k = 0; k &lt; 8; k++) {
         if (c &amp; 1)
           c = 0xedb88320L ^ (c &gt;&gt; 1);
         else
           c = c &gt;&gt; 1;
       }
       crc_table[n] = c;
     }
     crc_table_computed = 1;
   }

</pre>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<pre>
   /* Update a running CRC with the bytes buf[0..len-1]--the CRC
      should be initialized to all 1's, and the transmitted value
      is the 1's complement of the final running CRC (see the
      crc() routine below). */

   unsigned long update_crc(unsigned long crc, unsigned char *buf,
                            int len)
   {
     unsigned long c = crc;
     int n;

     if (!crc_table_computed)
       make_crc_table();
     for (n = 0; n &lt; len; n++) {
       c = crc_table[(c ^ buf[n]) &amp; 0xff] ^ (c &gt;&gt; 8);
     }
     return c;
   }

   /* Return the CRC of the bytes buf[0..len-1]. */
   unsigned long crc(unsigned char *buf, int len)
   {
     return update_crc(0xffffffffL, buf, len) ^ 0xffffffffL;
   }
</pre>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<!-- Maintain a fragment named "E-Resources" to preserve incoming links to it -->
<section class="appendix informative" id="E-Resources">
<!-- Maintain a fragment named "onlineresources" to preserve incoming links to it -->
<h2 class="Annex" id="onlineresources">Online resources</h2>

<!-- Maintain a fragment named "E-Intro" to preserve incoming links to it -->
<section class="introductory" id="E-Intro">
<p>This annex gives the locations of some Internet resources for
PNG software developers. By the nature of the Internet, the list
is incomplete and subject to change.</p>
</section>

<!-- Maintain a fragment named "E-Archive-sites" to preserve incoming links to it -->
<section id="E-Archive-sites">
<h2>Archive sites</h2>

<p>This specification can be found at
<a href="http://www.w3.org/TR/2003/REC-PNG-20031110/index.html"
><code>http://www.w3.org/TR/2003/REC-PNG-20031110/index.html</code></a>.</p>
</section>

<!-- Maintain a fragment named "E-icc-profile-specs" to preserve incoming links to it -->
<section id="E-icc-profile-specs">
<h2>ICC profile
specifications</h2>

<p>ICC profile specifications are available at: <a href=
"http://www.color.org/"><code>http://www.color.org/</code></a></p>
</section>

<!-- Maintain a fragment named "E-PNG-home-page" to preserve incoming links to it -->
<section id="E-PNG-home-page">
<h2>PNG web site</h2>

<p>There is a World Wide Web site for PNG at <a href=
"http://www.libpng.org/pub/png/"><code>http://www.libpng.org/pub/png/</code></a>.
This page is a central location for current information about PNG
and PNG-related tools.</p>

<p>Additional documentation and portable C code for deflate,
inflate, and an optimized implementation of the CRC algorithm are
available from the zlib web site,
<a href=
"http://www.zlib.org/"><code>http://www.zlib.org/</code></a>.</p>
</section>

<!-- Maintain a fragment named "E-Sample-implementation" to preserve incoming links to it -->
<section id="E-Sample-implementation">
<h2>Sample implementation and
test images</h2>

<p>A sample implementation in portable C, <strong>libpng</strong>, is
available at <a href=
"http://www.libpng.org/pub/png/libpng.html"><code>http://www.libpng.org/pub/png/libpng.html</code></a>.
Sample viewer and encoder applications of libpng are available at
<a href=
"http://www.libpng.org/pub/png/book/sources.html"><code>http://www.libpng.org/pub/png/book/sources.html</code></a>
and are described in detail in <i>PNG: The Definitive Guide</i>
<a href="#ROELOFS">[ROELOFS]</a>. Test images can also be
accessed from the PNG web site.</p>
</section>
</section>

<!-- Maintain a fragment named "F-Relationship" to preserve incoming links to it -->
<section class="appendix informative" id="F-Relationship">
<!-- Maintain a fragment named "relationshiptofirstedition" to preserve incoming links to it -->
<h2 class="Annex" id="relationshiptofirstedition">Relationship to W3C PNG</h2>

<p>This specification is strongly based on W3C
Recommendation PNG Specification Version 1.0 <a href=
"#PNG-1.0">[PNG-1.0]</a> which was reviewed by W3C members,
approved as a W3C Recommendation, and published in October 1996
according to the established W3C process. Subsequent amendments
to the PNG Specification have also been incorporated into this
International Standard <a href="#PNG-1.0">[PNG-1.1]</a>, <a
href="#PNG-1.0">[PNG-1.2]</a>.</p>

<p>A complete review of the document has been done by ISO/IEC/JTC
1/SC 24 in collaboration with W3C in order to transform this
recommendation into an ISO/IEC international standard. A major
design goal during this review was to avoid changes that will
invalidate existing files, editors, or viewers that conform to
W3C Recommendation PNG Specification Version 1.0.</p>

<p>The W3C PNG Recommendation was developed with major
contribution from the following people.</p>
<!-- Maintain a fragment named "F-Editor10" to preserve incoming links to it -->
<h2 id="F-Editor10">Editor (Version 1.0)</h2>

<p>Thomas Boutell, <span class="email">boutell @ boutell.com</span></p>

<!-- Maintain a fragment named "F-Editor12" to preserve incoming links to it -->
<h2 id="F-Editor12">Editor (Versions 1.1 and 1.2)</h2>

<p>Glenn Randers-Pehrson, <span class="email">randeg @ alum.rpi.edu</span></p>

<!-- Maintain a fragment named "F-ContribEditor10" to preserve incoming links to it -->
<h2 id="F-ContribEditor10">
Contributing Editor (Version
1.0)</h2>

<p>Tom Lane, <span class="email">tgl @ sss.pgh.pa.us</span></p>

<!-- Maintain a fragment named "F-ContribEditor12" to preserve incoming links to it -->
<h2 id="F-ContribEditor12">
Contributing Editor (Versions 1.1
and 1.2)</h2>

<p>Adam M. Costello, <span class="email">png-spec.amc @ nicemice.net</span></p>

<!-- Maintain a fragment named "F-Authors" to preserve incoming links to it -->
<h2 id="F-Authors">
Authors (Versions 1.0, 1.1, and 1.2
combined)</h2>

<p><strong>Authors' names are presented in alphabetical
order.</strong></p>

<ul>
<li><a href="http://www.alumni.caltech.edu/~madler/">Mark Adler</a>,
<span class="email">madler @ alumni.caltech.edu</span></li>

<li><a href="http://www.boutell.com/boutell/">Thomas Boutell</a>,
<span class="email">boutell @ boutell.com</span></li>

<li>John Bowler, <span class="mail">jbowler @ acm.org</span></li>

<li><a href="http://www.df.lth.se/~cb/">Christian Brunschen</a>,
<span class="email">cb @ brunschen.com</span></li>

<li><a href="http://www.nicemice.net/amc/">Adam M.
Costello</a>, <span class=
"email">png-spec.amc @ nicemice.net</span></li>

<li><a href="http://www.piclab.com/">Lee Daniel Crocker</a>,
<span class="email">lee @ piclab.com</span></li>

<li><a href=
"http://www-mddsp.enel.ucalgary.ca/People/adilger/">Andreas
Dilger</a>, <span class=
"email">adilger @ turbolabs.com</span></li>

<li><a href="http://www.fromme.com/">Oliver Fromme</a>, <span
class="email">oliver @ fromme.com</span></li>

<li><a href="http://www.teaser.fr/~jlgailly/">Jean-loup
Gailly</a>, <span class="email">jloup @ gzip.org</span></li>

<li>Chris Herborth, <span class=
"email">chrish @ pobox.com</span></li>

<li>Alex Jakulin, <span class=
"email">jakulin @ acm.org</span></li>

<li>Neal Kettler, <span class=
"email">neal @ westwood.com</span></li>

<li>Tom Lane, <span class="email">tgl @ sss.pgh.pa.us</span></li>

<li>Alexander Lehmann, <span class=
"email">lehmann @ usa.net</span></li>


<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->

<li><a href="http://www.w3.org/People/chris/">Chris Lilley</a>,
<span class="email">chris @ w3.org</span></li>

<li>Dave Martindale, <span class=
"email">davem @ cs.ubc.ca</span></li>

<li>Owen Mortensen, <span class="email">ojm @ acm.org</span></li>

<li>Keith S. Pickens, <span class=
"email">ksp @ rice.edu</span></li>

<li><a href="http://www.users.qwest.net/~lionlad/">Robert P. Poole</a>, <span class=
"email">lionlad @ qwest.net</span></li>

<li>Glenn Randers-Pehrson, <span class=
"email">randeg @ alum.rpi.edu</span></li>

<li><a href="http://pobox.com/~newt/">Greg Roelofs</a>, <span
class="email">newt @ pobox.com</span></li>

<li><a href="http://www.schaik.com/">Willem van Schaik</a>, <span
class="email">willem @ schaik.com</span></li>

<li>Guy Schalnat, <span class=
"email">gschal @ infinet.com</span></li>

<li>Paul Schmidt, <span class=
"email">pschmidt @ photodex.com</span></li>

<li>Michael Stokes, <span class=
"email">mistokes @ microsoft.com</span></li>

<li>Tim Wegner, <span class=
"email">twegner @ phoenix.net</span></li>

<li>Jeremy Wohl, <span class=
"email">jeremyw @ evantide.com</span></li>
</ul>

<!-- Maintain a fragment named "F-ChangeList" to preserve incoming links to it -->
<h2 id="F-ChangeList">
List of changes between W3C
Recommendation PNG Specification Version 1.0 and this
International Standard</h2>

<!-- Maintain a fragment named "F-EditorialChanges" to preserve incoming links to it -->
<h2 id="F-EditorialChanges">
Editorial changes</h2>

<p>The document has been reformatted according to the
requirements of ISO.</p>

<!-- <ol start="1"> --><ol>
<li>A concepts clause has been introduced.</li>

<li>Conformance for datastreams, encoders, decoders, and editors
has been defined in a conformance clause.</li>
</ol>

<!-- Maintain a fragment named "F-TechnicalChanges" to preserve incoming links to it -->
<h2 id="F-TechnicalChanges">
Technical changes</h2>

<!-- <ol start="1"> --><ol>
<li>New chunk types introduced in PNG version 1.1 and 1.2 have
been incorporated (<a href="#iccp-embedded-icc-profile"><span class=
"chunk">iCCP</span></a>, <a href="#itxt-international-textual-data"><span class=
"chunk">iTXt</span></a>, <a href="#srgb-standard-colour-space"><span class=
"chunk">sRGB</span></a>, <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a>).
In the
<a href="#itxt-international-5extual-data"><span class=
"chunk">iTXt</span></a>
chunk, the language tag has been updated from RFC 1766 to RFC 3066.</li>

<li>In accord with version 1.1, the scope of the 31-bit limit on
chunk lengths and image dimensions has been extended to apply to
all four-byte unsigned integers. The value -2<sup>31</sup> is not
allowed in signed integers.</li>

<li>The redefinition of <a href="#gama-image-gamma"><span class=
"chunk">gAMA</span></a> to be in terms of the desired display
output rather than the original scene, introduced in PNG version
1.1, has been incorporated.</li>

<li>The use of the <a href="#plte-palette"><span class=
"chunk">PLTE</span></a> and <a href="#hist-image-histogram"><span class=
"chunk">hIST</span></a> chunks in non-indexed-colour images has
been discouraged in favour of the <a href="#splt-suggested-palette"><span class=
"chunk">sPLT</span></a> chunk.</li>

<li>Some recommendations for PNG encoders, decoders, and editors
have been strengthened to requirements. These changes do not
affect the conformance of PNG datastreams, and do not compromise
interoperability.</li>

<li>The sample depth of channels not mentioned in the <a href=
"#sbit-significant-bits"><span class="chunk">sBIT</span></a> chunk has been
clarified.</li>
</ol>
</section>

<!-- ************Page Break******************* -->
<!-- ************Page Break******************* -->
<section class="appendix">
<!-- Maintain a fragment named "G-References" to preserve incoming links to it -->
<h2 class="Annex" id="G-References">
Bibliography</h2>

<dl>
<!-- Maintain a fragment named "G-COLOUR-FAQ" to preserve incoming links to it -->
<dt id="G-COLOUR-FAQ">
<a name="COLOUR-FAQ">[COLOUR-FAQ]</a></dt>

<dd>Poynton, C., "Colour FAQ".<br class="xhtml" />
 <a href=
"http://www.poynton.com/ColorFAQ.html">
<code>http://www.poynton.com/ColorFAQ.html</code></a></dd>

<!-- Maintain a fragment named "G-COLOUR-TUTORIAL" to preserve incoming links to it -->
<dt id="G-COLOUR-TUTORIAL">
<a name="COLOUR-TUTORIAL">[COLOUR-TUTORIAL]</a></dt>

<dd>PNG Group, "Colour tutorial".<br class="xhtml" />
 <a href=
"http://www.libpng.org/pub/png/spec/1.2/PNG-ColorAppendix.html"><code>
http://www.libpng.org/pub/png/spec/1.2/PNG-ColorAppendix.html</code></a></dd>

<!-- Maintain a fragment named "G-GAMMA-TUTORIAL" to preserve incoming links to it -->
<dt id="G-GAMMA-TUTORIAL">
<a name="GAMMA-TUTORIAL">[GAMMA-TUTORIAL]</a></dt>

<dd>PNG Group, "Gamma tutorial".<br class="xhtml" />
 <a href=
"http://www.libpng.org/pub/png/spec/1.2/PNG-GammaAppendix.html"><code>
http://www.libpng.org/pub/png/spec/1.2/PNG-GammaAppendix.html</code></a></dd>

<!-- Maintain a fragment named "G-GAMMA-FAQ" to preserve incoming links to it -->
<dt id="G-GAMMA-FAQ">
<a name="GAMMA-FAQ">[GAMMA-FAQ]</a></dt>

<dd>Poynton, C., "Gamma FAQ".<br class="xhtml" />
 <a href=
"http://www.poynton.com/Poynton-color.html">
<code>http://www.poynton.com/Poynton-color.html</code></a></dd>

<!-- Maintain a fragment named "G-HALL" to preserve incoming links to it -->
<dt id="G-HALL">
<a name="HALL">[HALL]</a></dt>

<dd>Hall, Roy, <i>Illumination and Color in Computer Generated
Imagery</i>. Springer-Verlag, New York, 1989. ISBN
0-387-96774-5.</dd>

<!-- Maintain a fragment named "G-ICC" to preserve incoming links to it -->
<dt id="G-ICC">
<a name="ICC">[ICC]</a></dt>

<dd>The International Color Consortium.<br class="xhtml" />
 <a href=
"http://www.color.org/"><code>http://www.color.org/</code></a></dd>

<!-- Maintain a fragment named "G-ISO-3664" to preserve incoming links to it -->
<dt id="G-ISO-3664">
<a name="ISO-3664">[ISO-3664]</a></dt>

<dd>ISO 3664:2000, <i>Viewing conditions &mdash; Graphic
technology and photography</i>.</dd>

<!-- Maintain a fragment named "G-ITU-R-BT.709" to preserve incoming links to it -->
<dt id="G-ITU-R-BT.709">
<a name="ITU-R BT.709">[ITU-R BT.709]</a></dt>

<dd>International Telecommunications Union, <i>Basic Parameter
Values for the HDTV Standard for the Studio and for International
Programme Exchange</i>, ITU-R Recommendation BT.709 (formerly CCIR
Rec. 709), 1990.</dd>

<!-- Maintain a fragment named "G-ITU-T-V42" to preserve incoming links to it -->
<dt id="G-ITU-T-V42">
<a name="ITU-T-V42">[ITU-T-V42]</a></dt>

<dd>International Telecommunications Union, <i>Error-correcting
Procedures for DCEs Using Asynchronous-to-Synchronous
Conversion</i>, ITU-T Recommendation V.42, 1994, Rev. 1.</dd>

<!-- Maintain a fragment named "G-KASSON" to preserve incoming links to it -->
<dt id="G-KASSON">
<a name="KASSON">[KASSON]</a></dt>

<dd>Kasson, J., and W. Plouffe, "An Analysis of Selected Computer
Interchange Color Spaces", <i>ACM Transactions on Graphics</i>,
vol. 11, no. 4 , pp. 373-405, 1992.</dd>

<!-- Maintain a fragment named "G-LILLEY" to preserve incoming links to it -->
<dt id="G-LILLEY">
<a name="LILLEY">[LILLEY]</a></dt>

<dd>Lilley, C., F. Lin, W.T. Hewitt, and T.L.J. Howard, <i>Colour
in Computer Graphics</i>. CVCP, Sheffield, 1993. ISBN
1-85889-022-5.<br class="xhtml" />
<!-- Also available from<br class="xhtml" />
 <a href=
"http://www.man.ac.uk/MVC/training/gravigs/colour/"><code>http://www.man.ac.uk/MVC/training/gravigs/colour/</code></a>
--></dd>

<!-- Maintain a fragment named "G-ROELOFS" to preserve incoming links to it -->
<dt id="G-ROELOFS">
<a name="ROELOFS">[ROELOFS]</a></dt>

<dd>Roelofs, G., <i>PNG: The Definitive Guide</i>, O'Reilly &amp;
Associates Inc, Sebastopol, CA, 1999. ISBN 1-56592-542-4.
See also <a href="http://www.libpng.org/pub/png/pngbook.html">
<code>http://www.libpng.org/pub/png/pngbook.html</code>
</a></dd>

<!-- Maintain a fragment named "G-PAETH" to preserve incoming links to it -->
<dt id="G-PAETH">
<a name="PAETH">[PAETH]</a></dt>

<dd>Paeth, A.W., "Image File Compression Made Easy", in
<i>Graphics Gems II</i>, James Arvo, editor. Academic Press, San
Diego, 1991. ISBN 0-12-064480-0.</dd>

<!-- Maintain a fragment named "G-PNG-1.0" to preserve incoming links to it -->
<dt id="G-PNG-1.0">
<a name="PNG-1.0">[PNG-1.0]</a></dt>

<dd>W3C Recommendation, "PNG (Portable Network Graphics)
Specification, Version 1.0", 1996. Available in several formats
from<br class="xhtml" />
 <a href=
"http://www.w3.org/TR/REC-png-961001"><code>http://www.w3.org/TR/REC-png-961001</code></a>
and from<br class="xhtml" />
 <a href=
"http://www.libpng.org/pub/png/spec/1.0/"><code>http://www.libpng.org/pub/png/spec/1.0/</code></a></dd>

<!-- Maintain a fragment named "G-PNG-1.1" to preserve incoming links to it -->
<dt id="G-PNG-1.1">
<a name="PNG-1.1">[PNG-1.1]</a></dt>

<dd>PNG Development Group, "PNG (Portable Network Graphics)
Specification, Version 1.1", 1999. Available
from<br class="xhtml" />
 <a href=
"http://www.libpng.org/pub/png/spec/1.1/"><code>http://www.libpng.org/pub/png/spec/1.1/</code></a></dd>

<!-- Maintain a fragment named "G-PNG-1.2" to preserve incoming links to it -->
<dt id="G-PNG-1.2">
<a name="PNG-1.2">[PNG-1.2]</a></dt>

<dd>PNG Development Group, "PNG (Portable Network Graphics)
Specification, Version 1.2", 1999. Available from<br class="xhtml" />
 <a href=
"http://www.libpng.org/pub/png/spec/1.2/"><code>http://www.libpng.org/pub/png/spec/1.2/</code></a></dd>

<!-- Maintain a fragment named "G-PNG-EXTENSIONS" to preserve incoming links to it -->
<dt id="G-PNG-EXTENSIONS">
<a name="PNG-EXTENSIONS">[PNG-EXTENSIONS]</a></dt>

<dd>PNG Working Group, "Register of PNG Public Chunks and Keywords".
Available  from:<br class="xhtml" />
<a href=
"https://w3c.github.io/PNG-spec/extensions/Overview.html"><code>https://w3c.github.io/PNG-spec/extensions/Overview.html</code></a></dd>

<!-- Maintain a fragment named "G-POSTSCRIPT" to preserve incoming links to it -->
<dt id="G-POSTSCRIPT">
<a name="POSTSCRIPT">[POSTSCRIPT]</a></dt>

<dd>Adobe Systems Incorporated, <i>PostScript Language Reference
Manual</i>, 2nd edition. Addison-Wesley, Reading, 1990. ISBN
0-201-18127-4.</dd>

<!-- Maintain a fragment named "G-POYNTON" to preserve incoming links to it -->
<dt id="G-POYNTON">
<a name="POYNTON">[POYNTON]</a></dt>

<dd>Poynton, Charles A., <i>A Technical Introduction to Digital
Video</i>. John Wiley and Sons, Inc., New York, 1996. ISBN
0-471-12253-X.</dd>

<!-- Maintain a fragment named "G-SMPTE-170M" to preserve incoming links to it -->
<dt id="G-SMPTE-170M">
<a name="SMPTE 170M">[SMPTE 170M]</a></dt>

<dd>Society of Motion Picture and Television Engineers,
<i>Television &mdash; Composite Analog Video Signal &mdash; NTSC
for Studio Applications</i>, SMPTE 170M, 1994.</dd>

<!-- Maintain a fragment named "G-STONE" to preserve incoming links to it -->
<dt id="G-STONE">
<a name="STONE">[STONE]</a></dt>

<dd>Stone, M.C., W.B. Cowan, and J.C. Beatty, "Color gamut
mapping and the printing of digital images", <i>ACM Transactions on
Graphics</i>, vol. 7, no. 3, pp. 249-292, 1988.</dd>

<!-- Maintain a fragment named "G-TIFF-6.0" to preserve incoming links to it -->
<dt id="G-TIFF-6.0">
<a name="TIFF 6.0">[TIFF 6.0]</a></dt>

<dd>TIFF<sup>TM</sup> Revision 6.0, Aldus Corporation, June
1992.</dd>

<!-- Maintain a fragment named "G-TRAVIS" to preserve incoming links to it -->
<dt id="G-TRAVIS">
<a name="TRAVIS">[TRAVIS]</a></dt>

<dd>Travis, David, <i>Effective Color Displays &mdash; Theory and
Practice</i>. Academic Press, London, 1991. ISBN
0-12-697690-2.</dd>

<!-- Maintain a fragment named "G-ZL" to preserve incoming links to it -->
<dt id="G-ZL">
<a name="ZL">[ZL]</a></dt>

<dd>J. Ziv and A. Lempel, "A Universal Algorithm for Sequential
Data Compression", <i>IEEE Transactions on Information
Theory</i>, vol. IT-23, no. 3, pp. 337 - 343, 1977.</dd>
</dl>

<p>Additional documentation and portable C code for deflate,
inflate, and an optimized implementation of the CRC algorithm are
available from the zlib web site,
<a href=
"http://www.zlib.org/"><code>http://www.zlib.org/</code></a>.</p>
</section>

<script type="application/javascript" src="https://www.w3.org/scripts/TR/fixup.js"></script></body>
</html>
